{
  "name": "llcuda - Tesla T4 CUDA Inference",
  "short_name": "llcuda",
  "description": "Fast LLM inference on Tesla T4 GPUs with CUDA 12, FlashAttention, and Unsloth integration. Verified 134 tokens/sec on Gemma 3-1B.",
  "start_url": "/llcuda.github.io/",
  "display": "standalone",
  "background_color": "#ffffff",
  "theme_color": "#3f51b5",
  "orientation": "any",
  "icons": [
    {
      "src": "/llcuda.github.io/assets/images/icon-192.png",
      "sizes": "192x192",
      "type": "image/png"
    },
    {
      "src": "/llcuda.github.io/assets/images/icon-512.png",
      "sizes": "512x512",
      "type": "image/png"
    }
  ],
  "categories": ["development", "productivity", "utilities"],
  "lang": "en-US",
  "dir": "ltr",
  "scope": "/llcuda.github.io/",
  "related_applications": [],
  "prefer_related_applications": false
}
