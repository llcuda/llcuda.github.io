# Default meta tags for all pages
title: llcuda v2.2.0 - Tesla T4 Multi-GPU CUDA Inference Engine
description: Fast LLM inference on Tesla T4 GPUs with CUDA 12, FlashAttention, Multi-GPU support, and Unsloth integration. Optimized for Kaggle dual T4.
keywords: llcuda, CUDA, Tesla T4, LLM inference, FlashAttention, GGUF, Unsloth, Kaggle, Multi-GPU, GPU acceleration, deep learning
author: Waqas Muhammad
robots: index, follow
og:type: website
og:site_name: llcuda Documentation
og:locale: en_US
twitter:card: summary_large_image
twitter:site: "@waqasm86"
twitter:creator: "@waqasm86"
