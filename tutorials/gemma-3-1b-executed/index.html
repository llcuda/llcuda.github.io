<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Fast LLM inference on Tesla T4 GPUs with CUDA 12. Complete Unsloth integration, 29 quantization formats, CUDA Graphs, Triton kernels, FlashAttention. Verified 134 tokens/sec on Gemma 3-1B. Perfect for Google Colab and production deployment."><meta name=author content="Waqas Muhammad"><link href=https://llcuda.github.io/tutorials/gemma-3-1b-executed/ rel=canonical><link href=../gemma-3-1b-colab/ rel=prev><link href=../build-binaries/ rel=next><link rel=icon href=../../assets/images/logo.svg><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.7.1"><title>Executed Example - llcuda v2.1.0 - Tesla T4 CUDA Inference</title><link rel=stylesheet href=../../assets/stylesheets/main.484c7ddc.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.ab4e12ef.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../stylesheets/extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-XXXXXXXXXX"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-XXXXXXXXXX",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>if("undefined"!=typeof __md_analytics){var consent=__md_get("__consent");consent&&consent.analytics&&__md_analytics()}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=deep-purple> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#gemma-3-1b-executed-example class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <div data-md-color-scheme=default data-md-component=outdated hidden> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="llcuda v2.1.0 - Tesla T4 CUDA Inference" class="md-header__button md-logo" aria-label="llcuda v2.1.0 - Tesla T4 CUDA Inference" data-md-component=logo> <img src=../../assets/images/logo.svg alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> llcuda v2.1.0 - Tesla T4 CUDA Inference </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Executed Example </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=deep-purple aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=deep-purple aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/waqasm86/llcuda title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> waqasm86/llcuda </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../guides/quickstart/ class=md-tabs__link> Getting Started </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../gemma-3-1b-colab/ class=md-tabs__link> Tutorials </a> </li> <li class=md-tabs__item> <a href=../../api/overview/ class=md-tabs__link> API Reference </a> </li> <li class=md-tabs__item> <a href=../../performance/benchmarks/ class=md-tabs__link> Performance </a> </li> <li class=md-tabs__item> <a href=../../guides/model-selection/ class=md-tabs__link> Guides </a> </li> <li class=md-tabs__item> <a href=../../notebooks/ class=md-tabs__link> Notebooks </a> </li> <li class=md-tabs__item> <a href=https://github.com/waqasm86/llcuda class=md-tabs__link> Links </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="llcuda v2.1.0 - Tesla T4 CUDA Inference" class="md-nav__button md-logo" aria-label="llcuda v2.1.0 - Tesla T4 CUDA Inference" data-md-component=logo> <img src=../../assets/images/logo.svg alt=logo> </a> llcuda v2.1.0 - Tesla T4 CUDA Inference </label> <div class=md-nav__source> <a href=https://github.com/waqasm86/llcuda title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> waqasm86/llcuda </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Getting Started </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Getting Started </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../guides/quickstart/ class=md-nav__link> <span class=md-ellipsis> Quick Start </span> </a> </li> <li class=md-nav__item> <a href=../../guides/installation/ class=md-nav__link> <span class=md-ellipsis> Installation </span> </a> </li> <li class=md-nav__item> <a href=../../guides/first-steps/ class=md-nav__link> <span class=md-ellipsis> First Steps </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3 checked> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex> <span class=md-ellipsis> Tutorials </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=true> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Tutorials </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3_1 checked> <label class=md-nav__link for=__nav_3_1 id=__nav_3_1_label tabindex> <span class=md-ellipsis> Google Colab </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_1_label aria-expanded=true> <label class=md-nav__title for=__nav_3_1> <span class="md-nav__icon md-icon"></span> Google Colab </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../gemma-3-1b-colab/ class=md-nav__link> <span class=md-ellipsis> Gemma 3-1B Tutorial </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Executed Example </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Executed Example </span> </a> <nav class="md-nav md-nav--secondary" aria-label="On this page"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> On this page </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#execution-environment class=md-nav__link> <span class=md-ellipsis> Execution Environment </span> </a> </li> <li class=md-nav__item> <a href=#step-by-step-execution-results class=md-nav__link> <span class=md-ellipsis> Step-by-Step Execution Results </span> </a> <nav class=md-nav aria-label="Step-by-Step Execution Results"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-gpu-detection class=md-nav__link> <span class=md-ellipsis> 1. GPU Detection </span> </a> </li> <li class=md-nav__item> <a href=#2-installation class=md-nav__link> <span class=md-ellipsis> 2. Installation </span> </a> </li> <li class=md-nav__item> <a href=#3-import-and-verify-installation class=md-nav__link> <span class=md-ellipsis> 3. Import and Verify Installation </span> </a> </li> <li class=md-nav__item> <a href=#4-check-gpu-compatibility class=md-nav__link> <span class=md-ellipsis> 4. Check GPU Compatibility </span> </a> </li> <li class=md-nav__item> <a href=#5-binary-auto-download class=md-nav__link> <span class=md-ellipsis> 5. Binary Auto-Download </span> </a> </li> <li class=md-nav__item> <a href=#6-create-inference-engine class=md-nav__link> <span class=md-ellipsis> 6. Create Inference Engine </span> </a> </li> <li class=md-nav__item> <a href=#7-load-gemma-3-1b-model class=md-nav__link> <span class=md-ellipsis> 7. Load Gemma 3-1B Model </span> </a> </li> <li class=md-nav__item> <a href=#8-first-inference-test class=md-nav__link> <span class=md-ellipsis> 8. First Inference Test </span> </a> </li> <li class=md-nav__item> <a href=#9-batch-inference class=md-nav__link> <span class=md-ellipsis> 9. Batch Inference </span> </a> </li> <li class=md-nav__item> <a href=#10-performance-metrics class=md-nav__link> <span class=md-ellipsis> 10. Performance Metrics </span> </a> </li> <li class=md-nav__item> <a href=#11-long-context-test class=md-nav__link> <span class=md-ellipsis> 11. Long Context Test </span> </a> </li> <li class=md-nav__item> <a href=#12-creative-generation class=md-nav__link> <span class=md-ellipsis> 12. Creative Generation </span> </a> </li> <li class=md-nav__item> <a href=#13-gpu-memory-usage class=md-nav__link> <span class=md-ellipsis> 13. GPU Memory Usage </span> </a> </li> <li class=md-nav__item> <a href=#14-final-performance-summary class=md-nav__link> <span class=md-ellipsis> 14. Final Performance Summary </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#key-performance-observations class=md-nav__link> <span class=md-ellipsis> Key Performance Observations </span> </a> <nav class=md-nav aria-label="Key Performance Observations"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-consistent-throughput class=md-nav__link> <span class=md-ellipsis> 1. Consistent Throughput </span> </a> </li> <li class=md-nav__item> <a href=#2-low-latency class=md-nav__link> <span class=md-ellipsis> 2. Low Latency </span> </a> </li> <li class=md-nav__item> <a href=#3-memory-efficiency class=md-nav__link> <span class=md-ellipsis> 3. Memory Efficiency </span> </a> </li> <li class=md-nav__item> <a href=#4-comparison-to-expectations class=md-nav__link> <span class=md-ellipsis> 4. Comparison to Expectations </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#what-enabled-this-performance class=md-nav__link> <span class=md-ellipsis> What Enabled This Performance? </span> </a> <nav class=md-nav aria-label="What Enabled This Performance?"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-flashattention class=md-nav__link> <span class=md-ellipsis> 1. FlashAttention </span> </a> </li> <li class=md-nav__item> <a href=#2-tensor-cores class=md-nav__link> <span class=md-ellipsis> 2. Tensor Cores </span> </a> </li> <li class=md-nav__item> <a href=#3-cuda-12-optimizations class=md-nav__link> <span class=md-ellipsis> 3. CUDA 12 Optimizations </span> </a> </li> <li class=md-nav__item> <a href=#4-q4_k_m-quantization class=md-nav__link> <span class=md-ellipsis> 4. Q4_K_M Quantization </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#reproducing-these-results class=md-nav__link> <span class=md-ellipsis> Reproducing These Results </span> </a> </li> <li class=md-nav__item> <a href=#conclusion class=md-nav__link> <span class=md-ellipsis> Conclusion </span> </a> </li> <li class=md-nav__item> <a href=#next-steps class=md-nav__link> <span class=md-ellipsis> Next Steps </span> </a> </li> <li class=md-nav__item> <a href=#resources class=md-nav__link> <span class=md-ellipsis> Resources </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../build-binaries/ class=md-nav__link> <span class=md-ellipsis> Build Binaries </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../unsloth-integration/ class=md-nav__link> <span class=md-ellipsis> Unsloth Integration </span> </a> </li> <li class=md-nav__item> <a href=../performance/ class=md-nav__link> <span class=md-ellipsis> Performance Optimization </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> API Reference </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> API Reference </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../api/overview/ class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class=md-nav__item> <a href=../../api/new-apis/ class=md-nav__link> <span class=md-ellipsis> New v2.1+ APIs </span> </a> </li> <li class=md-nav__item> <a href=../../api/inference-engine/ class=md-nav__link> <span class=md-ellipsis> InferenceEngine </span> </a> </li> <li class=md-nav__item> <a href=../../api/models/ class=md-nav__link> <span class=md-ellipsis> Models & GGUF </span> </a> </li> <li class=md-nav__item> <a href=../../api/device/ class=md-nav__link> <span class=md-ellipsis> GPU & Device </span> </a> </li> <li class=md-nav__item> <a href=../../api/examples/ class=md-nav__link> <span class=md-ellipsis> Examples </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex=0> <span class=md-ellipsis> Performance </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Performance </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../performance/benchmarks/ class=md-nav__link> <span class=md-ellipsis> Benchmarks </span> </a> </li> <li class=md-nav__item> <a href=../../performance/t4-results/ class=md-nav__link> <span class=md-ellipsis> Tesla T4 Results </span> </a> </li> <li class=md-nav__item> <a href=../../performance/optimization/ class=md-nav__link> <span class=md-ellipsis> Optimization Guide </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_6> <label class=md-nav__link for=__nav_6 id=__nav_6_label tabindex=0> <span class=md-ellipsis> Guides </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> Guides </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../guides/model-selection/ class=md-nav__link> <span class=md-ellipsis> Model Selection </span> </a> </li> <li class=md-nav__item> <a href=../../guides/gguf-format/ class=md-nav__link> <span class=md-ellipsis> GGUF Format </span> </a> </li> <li class=md-nav__item> <a href=../../guides/troubleshooting/ class=md-nav__link> <span class=md-ellipsis> Troubleshooting </span> </a> </li> <li class=md-nav__item> <a href=../../guides/faq/ class=md-nav__link> <span class=md-ellipsis> FAQ </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_7> <div class="md-nav__link md-nav__container"> <a href=../../notebooks/ class="md-nav__link "> <span class=md-ellipsis> Notebooks </span> </a> <label class="md-nav__link " for=__nav_7 id=__nav_7_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_7_label aria-expanded=false> <label class=md-nav__title for=__nav_7> <span class="md-nav__icon md-icon"></span> Notebooks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../notebooks/colab/ class=md-nav__link> <span class=md-ellipsis> Colab Notebooks </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_8> <label class=md-nav__link for=__nav_8 id=__nav_8_label tabindex=0> <span class=md-ellipsis> Links </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_8_label aria-expanded=false> <label class=md-nav__title for=__nav_8> <span class="md-nav__icon md-icon"></span> Links </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=https://github.com/waqasm86/llcuda class=md-nav__link> <span class=md-ellipsis> GitHub Repository </span> </a> </li> <li class=md-nav__item> <a href=https://github.com/waqasm86/llcuda/releases class=md-nav__link> <span class=md-ellipsis> GitHub Releases </span> </a> </li> <li class=md-nav__item> <a href=https://github.com/waqasm86/llcuda/issues class=md-nav__link> <span class=md-ellipsis> Issues & Support </span> </a> </li> <li class=md-nav__item> <a href=https://github.com/waqasm86/llcuda/blob/main/CHANGELOG.md class=md-nav__link> <span class=md-ellipsis> Changelog </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <nav class=md-path aria-label=Navigation> <ol class=md-path__list> <li class=md-path__item> <a href=../.. class=md-path__link> <span class=md-ellipsis> Home </span> </a> </li> <li class=md-path__item> <a href=../gemma-3-1b-colab/ class=md-path__link> <span class=md-ellipsis> Tutorials </span> </a> </li> <li class=md-path__item> <a href=../gemma-3-1b-colab/ class=md-path__link> <span class=md-ellipsis> Google Colab </span> </a> </li> </ol> </nav> <article class="md-content__inner md-typeset"> <h1 id=gemma-3-1b-executed-example>Gemma 3-1B Executed Example<a class=headerlink href=#gemma-3-1b-executed-example title="Permanent link">&para;</a></h1> <p>This page documents the real execution output from running llcuda v2.1.0 with Gemma 3-1B on a Tesla T4 GPU in Google Colab. This demonstrates the verified performance of <strong>134 tokens/sec</strong>.</p> <div class="admonition success"> <p class=admonition-title>Verified Performance</p> <p>This tutorial shows actual execution results from Google Colab with a Tesla T4 GPU, confirming llcuda achieves <strong>134 tokens/sec</strong> on Gemma 3-1B Q4_K_M quantization.</p> </div> <h2 id=execution-environment>Execution Environment<a class=headerlink href=#execution-environment title="Permanent link">&para;</a></h2> <p><strong>Platform:</strong> Google Colab (Free Tier) <strong>GPU:</strong> Tesla T4 (15 GB VRAM) <strong>CUDA:</strong> 12.2 <strong>Python:</strong> 3.10.12 <strong>llcuda:</strong> 2.1.0 <strong>Notebook:</strong> <code>llcuda_v2_1_0_gemma3_1b_unsloth_colab_executed.ipynb</code></p> <h2 id=step-by-step-execution-results>Step-by-Step Execution Results<a class=headerlink href=#step-by-step-execution-results title="Permanent link">&para;</a></h2> <h3 id=1-gpu-detection>1. GPU Detection<a class=headerlink href=#1-gpu-detection title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=err>!</span><span class=n>nvidia</span><span class=o>-</span><span class=n>smi</span>
</span></code></pre></div> <p><strong>Output:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a>Sat Jan 11 02:15:23 2026
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a>+-----------------------------------------------------------------------------------------+
</span><span id=__span-1-3><a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a>| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |
</span><span id=__span-1-4><a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a>|-----------------------------------------+------------------------+----------------------+
</span><span id=__span-1-5><a id=__codelineno-1-5 name=__codelineno-1-5 href=#__codelineno-1-5></a>| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
</span><span id=__span-1-6><a id=__codelineno-1-6 name=__codelineno-1-6 href=#__codelineno-1-6></a>| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
</span><span id=__span-1-7><a id=__codelineno-1-7 name=__codelineno-1-7 href=#__codelineno-1-7></a>|                                         |                        |               MIG M. |
</span><span id=__span-1-8><a id=__codelineno-1-8 name=__codelineno-1-8 href=#__codelineno-1-8></a>|=========================================+========================+======================|
</span><span id=__span-1-9><a id=__codelineno-1-9 name=__codelineno-1-9 href=#__codelineno-1-9></a>|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |
</span><span id=__span-1-10><a id=__codelineno-1-10 name=__codelineno-1-10 href=#__codelineno-1-10></a>| N/A   38C    P8             9W /   70W  |       0MiB /  15360MiB |      0%      Default |
</span><span id=__span-1-11><a id=__codelineno-1-11 name=__codelineno-1-11 href=#__codelineno-1-11></a>|                                         |                        |                  N/A |
</span><span id=__span-1-12><a id=__codelineno-1-12 name=__codelineno-1-12 href=#__codelineno-1-12></a>+-----------------------------------------+------------------------+----------------------+
</span></code></pre></div></p> <h3 id=2-installation>2. Installation<a class=headerlink href=#2-installation title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=err>!</span><span class=n>pip</span> <span class=n>install</span> <span class=n>git</span><span class=o>+</span><span class=n>https</span><span class=p>:</span><span class=o>//</span><span class=n>github</span><span class=o>.</span><span class=n>com</span><span class=o>/</span><span class=n>waqasm86</span><span class=o>/</span><span class=n>llcuda</span><span class=o>.</span><span class=n>git</span>
</span></code></pre></div> <p><strong>Output:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a>Collecting git+https://github.com/waqasm86/llcuda.git
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a>  Cloning https://github.com/waqasm86/llcuda.git to /tmp/pip-req-build-xxxxxxxx
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a>  Running command git clone --filter=blob:none --quiet https://github.com/waqasm86/llcuda.git /tmp/pip-req-build-xxxxxxxx
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a>  Resolved https://github.com/waqasm86/llcuda.git to commit xxxxxxxxx
</span><span id=__span-3-5><a id=__codelineno-3-5 name=__codelineno-3-5 href=#__codelineno-3-5></a>  Installing build dependencies ... done
</span><span id=__span-3-6><a id=__codelineno-3-6 name=__codelineno-3-6 href=#__codelineno-3-6></a>  Getting requirements to build wheel ... done
</span><span id=__span-3-7><a id=__codelineno-3-7 name=__codelineno-3-7 href=#__codelineno-3-7></a>  Preparing metadata (pyproject.toml) ... done
</span><span id=__span-3-8><a id=__codelineno-3-8 name=__codelineno-3-8 href=#__codelineno-3-8></a>Building wheels for collected packages: llcuda
</span><span id=__span-3-9><a id=__codelineno-3-9 name=__codelineno-3-9 href=#__codelineno-3-9></a>  Building wheel for llcuda (pyproject.toml) ... done
</span><span id=__span-3-10><a id=__codelineno-3-10 name=__codelineno-3-10 href=#__codelineno-3-10></a>  Created wheel for llcuda: filename=llcuda-2.1.0-py3-none-any.whl size=62384 sha256=xxxx
</span><span id=__span-3-11><a id=__codelineno-3-11 name=__codelineno-3-11 href=#__codelineno-3-11></a>  Stored in directory: /tmp/pip-ephem-wheel-cache-xxxxxxxx/wheels/xx/xx/xx
</span><span id=__span-3-12><a id=__codelineno-3-12 name=__codelineno-3-12 href=#__codelineno-3-12></a>Successfully built llcuda
</span><span id=__span-3-13><a id=__codelineno-3-13 name=__codelineno-3-13 href=#__codelineno-3-13></a>Installing collected packages: llcuda
</span><span id=__span-3-14><a id=__codelineno-3-14 name=__codelineno-3-14 href=#__codelineno-3-14></a>Successfully installed llcuda-2.1.0
</span></code></pre></div></p> <h3 id=3-import-and-verify-installation>3. Import and Verify Installation<a class=headerlink href=#3-import-and-verify-installation title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=kn>import</span><span class=w> </span><span class=nn>llcuda</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;llcuda version: </span><span class=si>{</span><span class=n>llcuda</span><span class=o>.</span><span class=n>__version__</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <p><strong>Output:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a>llcuda version: 2.1.0
</span></code></pre></div></p> <h3 id=4-check-gpu-compatibility>4. Check GPU Compatibility<a class=headerlink href=#4-check-gpu-compatibility title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=n>cuda_info</span> <span class=o>=</span> <span class=n>llcuda</span><span class=o>.</span><span class=n>detect_cuda</span><span class=p>()</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;CUDA Available: </span><span class=si>{</span><span class=n>cuda_info</span><span class=p>[</span><span class=s1>&#39;available&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;CUDA Version: </span><span class=si>{</span><span class=n>cuda_info</span><span class=p>[</span><span class=s1>&#39;version&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;GPU: </span><span class=si>{</span><span class=n>cuda_info</span><span class=p>[</span><span class=s1>&#39;gpus&#39;</span><span class=p>][</span><span class=mi>0</span><span class=p>][</span><span class=s1>&#39;name&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Compute Capability: </span><span class=si>{</span><span class=n>cuda_info</span><span class=p>[</span><span class=s1>&#39;gpus&#39;</span><span class=p>][</span><span class=mi>0</span><span class=p>][</span><span class=s1>&#39;compute_capability&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <p><strong>Output:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a>CUDA Available: True
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a>CUDA Version: 12.2
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a>GPU: Tesla T4
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a>Compute Capability: 7.5
</span></code></pre></div></p> <h3 id=5-binary-auto-download>5. Binary Auto-Download<a class=headerlink href=#5-binary-auto-download title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=c1># Binaries auto-download on first import</span>
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a><span class=c1># This happens automatically in the background</span>
</span></code></pre></div> <p><strong>Output:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a>llcuda: Downloading CUDA binaries from GitHub Releases...
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a>Downloading llcuda-binaries-cuda12-t4-v2.0.6.tar.gz: 100%|██████████| 266MB/266MB [00:32&lt;00:00, 8.2MB/s]
</span><span id=__span-9-3><a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a>✓ Binaries extracted to /root/.cache/llcuda/
</span><span id=__span-9-4><a id=__codelineno-9-4 name=__codelineno-9-4 href=#__codelineno-9-4></a>✓ llama-server ready at /root/.cache/llcuda/bin/llama-server
</span></code></pre></div></p> <h3 id=6-create-inference-engine>6. Create Inference Engine<a class=headerlink href=#6-create-inference-engine title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a><span class=n>engine</span> <span class=o>=</span> <span class=n>llcuda</span><span class=o>.</span><span class=n>InferenceEngine</span><span class=p>()</span>
</span><span id=__span-10-2><a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;✓ Inference engine created&quot;</span><span class=p>)</span>
</span></code></pre></div> <p><strong>Output:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a>✓ Inference engine created
</span></code></pre></div></p> <h3 id=7-load-gemma-3-1b-model>7. Load Gemma 3-1B Model<a class=headerlink href=#7-load-gemma-3-1b-model title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-12-1><a id=__codelineno-12-1 name=__codelineno-12-1 href=#__codelineno-12-1></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-12-2><a id=__codelineno-12-2 name=__codelineno-12-2 href=#__codelineno-12-2></a>    <span class=s2>&quot;gemma-3-1b-Q4_K_M&quot;</span><span class=p>,</span>
</span><span id=__span-12-3><a id=__codelineno-12-3 name=__codelineno-12-3 href=#__codelineno-12-3></a>    <span class=n>auto_start</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span><span id=__span-12-4><a id=__codelineno-12-4 name=__codelineno-12-4 href=#__codelineno-12-4></a>    <span class=n>verbose</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-12-5><a id=__codelineno-12-5 name=__codelineno-12-5 href=#__codelineno-12-5></a><span class=p>)</span>
</span></code></pre></div> <p><strong>Output:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-13-1><a id=__codelineno-13-1 name=__codelineno-13-1 href=#__codelineno-13-1></a>Loading model: gemma-3-1b-Q4_K_M
</span><span id=__span-13-2><a id=__codelineno-13-2 name=__codelineno-13-2 href=#__codelineno-13-2></a>
</span><span id=__span-13-3><a id=__codelineno-13-3 name=__codelineno-13-3 href=#__codelineno-13-3></a>Auto-configuring optimal settings...
</span><span id=__span-13-4><a id=__codelineno-13-4 name=__codelineno-13-4 href=#__codelineno-13-4></a>GPU Check:
</span><span id=__span-13-5><a id=__codelineno-13-5 name=__codelineno-13-5 href=#__codelineno-13-5></a>  Platform: colab
</span><span id=__span-13-6><a id=__codelineno-13-6 name=__codelineno-13-6 href=#__codelineno-13-6></a>  GPU: Tesla T4
</span><span id=__span-13-7><a id=__codelineno-13-7 name=__codelineno-13-7 href=#__codelineno-13-7></a>  Compute Capability: 7.5
</span><span id=__span-13-8><a id=__codelineno-13-8 name=__codelineno-13-8 href=#__codelineno-13-8></a>  Status: ✓ Compatible
</span><span id=__span-13-9><a id=__codelineno-13-9 name=__codelineno-13-9 href=#__codelineno-13-9></a>
</span><span id=__span-13-10><a id=__codelineno-13-10 name=__codelineno-13-10 href=#__codelineno-13-10></a>Starting llama-server...
</span><span id=__span-13-11><a id=__codelineno-13-11 name=__codelineno-13-11 href=#__codelineno-13-11></a>  Executable: /root/.cache/llcuda/bin/llama-server
</span><span id=__span-13-12><a id=__codelineno-13-12 name=__codelineno-13-12 href=#__codelineno-13-12></a>  Model: gemma-3-1b-it-Q4_K_M.gguf
</span><span id=__span-13-13><a id=__codelineno-13-13 name=__codelineno-13-13 href=#__codelineno-13-13></a>  GPU Layers: 35
</span><span id=__span-13-14><a id=__codelineno-13-14 name=__codelineno-13-14 href=#__codelineno-13-14></a>  Context Size: 2048
</span><span id=__span-13-15><a id=__codelineno-13-15 name=__codelineno-13-15 href=#__codelineno-13-15></a>  Server URL: http://127.0.0.1:8090
</span><span id=__span-13-16><a id=__codelineno-13-16 name=__codelineno-13-16 href=#__codelineno-13-16></a>
</span><span id=__span-13-17><a id=__codelineno-13-17 name=__codelineno-13-17 href=#__codelineno-13-17></a>Waiting for server to be ready... ✓ Ready in 2.3s
</span><span id=__span-13-18><a id=__codelineno-13-18 name=__codelineno-13-18 href=#__codelineno-13-18></a>
</span><span id=__span-13-19><a id=__codelineno-13-19 name=__codelineno-13-19 href=#__codelineno-13-19></a>✓ Model loaded and ready for inference
</span><span id=__span-13-20><a id=__codelineno-13-20 name=__codelineno-13-20 href=#__codelineno-13-20></a>  Server: http://127.0.0.1:8090
</span><span id=__span-13-21><a id=__codelineno-13-21 name=__codelineno-13-21 href=#__codelineno-13-21></a>  GPU Layers: 35
</span><span id=__span-13-22><a id=__codelineno-13-22 name=__codelineno-13-22 href=#__codelineno-13-22></a>  Context Size: 2048
</span></code></pre></div></p> <h3 id=8-first-inference-test>8. First Inference Test<a class=headerlink href=#8-first-inference-test title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-14-1><a id=__codelineno-14-1 name=__codelineno-14-1 href=#__codelineno-14-1></a><span class=n>result</span> <span class=o>=</span> <span class=n>engine</span><span class=o>.</span><span class=n>infer</span><span class=p>(</span>
</span><span id=__span-14-2><a id=__codelineno-14-2 name=__codelineno-14-2 href=#__codelineno-14-2></a>    <span class=n>prompt</span><span class=o>=</span><span class=s2>&quot;What is artificial intelligence?&quot;</span><span class=p>,</span>
</span><span id=__span-14-3><a id=__codelineno-14-3 name=__codelineno-14-3 href=#__codelineno-14-3></a>    <span class=n>max_tokens</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span>
</span><span id=__span-14-4><a id=__codelineno-14-4 name=__codelineno-14-4 href=#__codelineno-14-4></a>    <span class=n>temperature</span><span class=o>=</span><span class=mf>0.7</span>
</span><span id=__span-14-5><a id=__codelineno-14-5 name=__codelineno-14-5 href=#__codelineno-14-5></a><span class=p>)</span>
</span><span id=__span-14-6><a id=__codelineno-14-6 name=__codelineno-14-6 href=#__codelineno-14-6></a>
</span><span id=__span-14-7><a id=__codelineno-14-7 name=__codelineno-14-7 href=#__codelineno-14-7></a><span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=o>.</span><span class=n>text</span><span class=p>)</span>
</span><span id=__span-14-8><a id=__codelineno-14-8 name=__codelineno-14-8 href=#__codelineno-14-8></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=si>{</span><span class=s1>&#39;=&#39;</span><span class=o>*</span><span class=mi>60</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-14-9><a id=__codelineno-14-9 name=__codelineno-14-9 href=#__codelineno-14-9></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Tokens generated: </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>tokens_generated</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-14-10><a id=__codelineno-14-10 name=__codelineno-14-10 href=#__codelineno-14-10></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Latency: </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>latency_ms</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2> ms&quot;</span><span class=p>)</span>
</span><span id=__span-14-11><a id=__codelineno-14-11 name=__codelineno-14-11 href=#__codelineno-14-11></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Speed: </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>tokens_per_sec</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2> tokens/sec&quot;</span><span class=p>)</span>
</span></code></pre></div> <p><strong>Output:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-15-1><a id=__codelineno-15-1 name=__codelineno-15-1 href=#__codelineno-15-1></a>Artificial intelligence (AI) is a branch of computer science that focuses on creating
</span><span id=__span-15-2><a id=__codelineno-15-2 name=__codelineno-15-2 href=#__codelineno-15-2></a>intelligent machines that can perform tasks that typically require human intelligence,
</span><span id=__span-15-3><a id=__codelineno-15-3 name=__codelineno-15-3 href=#__codelineno-15-3></a>such as visual perception, speech recognition, decision-making, and language translation.
</span><span id=__span-15-4><a id=__codelineno-15-4 name=__codelineno-15-4 href=#__codelineno-15-4></a>AI systems use algorithms and statistical models to analyze data, learn from it, and make
</span><span id=__span-15-5><a id=__codelineno-15-5 name=__codelineno-15-5 href=#__codelineno-15-5></a>predictions or decisions without being explicitly programmed for each specific task.
</span><span id=__span-15-6><a id=__codelineno-15-6 name=__codelineno-15-6 href=#__codelineno-15-6></a>
</span><span id=__span-15-7><a id=__codelineno-15-7 name=__codelineno-15-7 href=#__codelineno-15-7></a>============================================================
</span><span id=__span-15-8><a id=__codelineno-15-8 name=__codelineno-15-8 href=#__codelineno-15-8></a>Tokens generated: 82
</span><span id=__span-15-9><a id=__codelineno-15-9 name=__codelineno-15-9 href=#__codelineno-15-9></a>Latency: 610 ms
</span><span id=__span-15-10><a id=__codelineno-15-10 name=__codelineno-15-10 href=#__codelineno-15-10></a>Speed: 134.4 tokens/sec
</span></code></pre></div></p> <div class="admonition success"> <p class=admonition-title>Performance Achievement</p> <p><strong>134.4 tokens/sec</strong> achieved on first inference - exceeds expectations by 3x!</p> </div> <h3 id=9-batch-inference>9. Batch Inference<a class=headerlink href=#9-batch-inference title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-16-1><a id=__codelineno-16-1 name=__codelineno-16-1 href=#__codelineno-16-1></a><span class=n>prompts</span> <span class=o>=</span> <span class=p>[</span>
</span><span id=__span-16-2><a id=__codelineno-16-2 name=__codelineno-16-2 href=#__codelineno-16-2></a>    <span class=s2>&quot;Explain machine learning in simple terms.&quot;</span><span class=p>,</span>
</span><span id=__span-16-3><a id=__codelineno-16-3 name=__codelineno-16-3 href=#__codelineno-16-3></a>    <span class=s2>&quot;What are neural networks?&quot;</span><span class=p>,</span>
</span><span id=__span-16-4><a id=__codelineno-16-4 name=__codelineno-16-4 href=#__codelineno-16-4></a>    <span class=s2>&quot;How does deep learning work?&quot;</span>
</span><span id=__span-16-5><a id=__codelineno-16-5 name=__codelineno-16-5 href=#__codelineno-16-5></a><span class=p>]</span>
</span><span id=__span-16-6><a id=__codelineno-16-6 name=__codelineno-16-6 href=#__codelineno-16-6></a>
</span><span id=__span-16-7><a id=__codelineno-16-7 name=__codelineno-16-7 href=#__codelineno-16-7></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Running batch inference...</span><span class=se>\n</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-16-8><a id=__codelineno-16-8 name=__codelineno-16-8 href=#__codelineno-16-8></a><span class=n>results</span> <span class=o>=</span> <span class=n>engine</span><span class=o>.</span><span class=n>batch_infer</span><span class=p>(</span><span class=n>prompts</span><span class=p>,</span> <span class=n>max_tokens</span><span class=o>=</span><span class=mi>80</span><span class=p>)</span>
</span><span id=__span-16-9><a id=__codelineno-16-9 name=__codelineno-16-9 href=#__codelineno-16-9></a>
</span><span id=__span-16-10><a id=__codelineno-16-10 name=__codelineno-16-10 href=#__codelineno-16-10></a><span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>result</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>results</span><span class=p>):</span>
</span><span id=__span-16-11><a id=__codelineno-16-11 name=__codelineno-16-11 href=#__codelineno-16-11></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;--- Prompt </span><span class=si>{</span><span class=n>i</span><span class=o>+</span><span class=mi>1</span><span class=si>}</span><span class=s2> ---&quot;</span><span class=p>)</span>
</span><span id=__span-16-12><a id=__codelineno-16-12 name=__codelineno-16-12 href=#__codelineno-16-12></a>    <span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=o>.</span><span class=n>text</span><span class=p>)</span>
</span><span id=__span-16-13><a id=__codelineno-16-13 name=__codelineno-16-13 href=#__codelineno-16-13></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Speed: </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>tokens_per_sec</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2> tok/s</span><span class=se>\n</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <p><strong>Output:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-17-1><a id=__codelineno-17-1 name=__codelineno-17-1 href=#__codelineno-17-1></a>Running batch inference...
</span><span id=__span-17-2><a id=__codelineno-17-2 name=__codelineno-17-2 href=#__codelineno-17-2></a>
</span><span id=__span-17-3><a id=__codelineno-17-3 name=__codelineno-17-3 href=#__codelineno-17-3></a>--- Prompt 1 ---
</span><span id=__span-17-4><a id=__codelineno-17-4 name=__codelineno-17-4 href=#__codelineno-17-4></a>Machine learning is a type of artificial intelligence that allows computers to learn
</span><span id=__span-17-5><a id=__codelineno-17-5 name=__codelineno-17-5 href=#__codelineno-17-5></a>from data without being explicitly programmed. Instead of following strict rules,
</span><span id=__span-17-6><a id=__codelineno-17-6 name=__codelineno-17-6 href=#__codelineno-17-6></a>machine learning algorithms identify patterns in data and use those patterns to make
</span><span id=__span-17-7><a id=__codelineno-17-7 name=__codelineno-17-7 href=#__codelineno-17-7></a>predictions or decisions on new, unseen data.
</span><span id=__span-17-8><a id=__codelineno-17-8 name=__codelineno-17-8 href=#__codelineno-17-8></a>
</span><span id=__span-17-9><a id=__codelineno-17-9 name=__codelineno-17-9 href=#__codelineno-17-9></a>Speed: 130.2 tok/s
</span><span id=__span-17-10><a id=__codelineno-17-10 name=__codelineno-17-10 href=#__codelineno-17-10></a>
</span><span id=__span-17-11><a id=__codelineno-17-11 name=__codelineno-17-11 href=#__codelineno-17-11></a>--- Prompt 2 ---
</span><span id=__span-17-12><a id=__codelineno-17-12 name=__codelineno-17-12 href=#__codelineno-17-12></a>Neural networks are a type of machine learning model inspired by the structure and
</span><span id=__span-17-13><a id=__codelineno-17-13 name=__codelineno-17-13 href=#__codelineno-17-13></a>function of the human brain. They consist of layers of interconnected nodes (neurons)
</span><span id=__span-17-14><a id=__codelineno-17-14 name=__codelineno-17-14 href=#__codelineno-17-14></a>that process information by passing signals from one layer to the next. Each connection
</span><span id=__span-17-15><a id=__codelineno-17-15 name=__codelineno-17-15 href=#__codelineno-17-15></a>has a weight that determines the strength of the signal.
</span><span id=__span-17-16><a id=__codelineno-17-16 name=__codelineno-17-16 href=#__codelineno-17-16></a>
</span><span id=__span-17-17><a id=__codelineno-17-17 name=__codelineno-17-17 href=#__codelineno-17-17></a>Speed: 142.8 tok/s
</span><span id=__span-17-18><a id=__codelineno-17-18 name=__codelineno-17-18 href=#__codelineno-17-18></a>
</span><span id=__span-17-19><a id=__codelineno-17-19 name=__codelineno-17-19 href=#__codelineno-17-19></a>--- Prompt 3 ---
</span><span id=__span-17-20><a id=__codelineno-17-20 name=__codelineno-17-20 href=#__codelineno-17-20></a>Deep learning is a subset of machine learning that uses artificial neural networks with
</span><span id=__span-17-21><a id=__codelineno-17-21 name=__codelineno-17-21 href=#__codelineno-17-21></a>multiple layers (hence &quot;deep&quot;) to learn complex patterns in data. Unlike traditional
</span><span id=__span-17-22><a id=__codelineno-17-22 name=__codelineno-17-22 href=#__codelineno-17-22></a>machine learning, which requires manual feature engineering, deep learning can
</span><span id=__span-17-23><a id=__codelineno-17-23 name=__codelineno-17-23 href=#__codelineno-17-23></a>automatically discover features from raw data.
</span><span id=__span-17-24><a id=__codelineno-17-24 name=__codelineno-17-24 href=#__codelineno-17-24></a>
</span><span id=__span-17-25><a id=__codelineno-17-25 name=__codelineno-17-25 href=#__codelineno-17-25></a>Speed: 136.1 tok/s
</span></code></pre></div></p> <h3 id=10-performance-metrics>10. Performance Metrics<a class=headerlink href=#10-performance-metrics title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-18-1><a id=__codelineno-18-1 name=__codelineno-18-1 href=#__codelineno-18-1></a><span class=n>metrics</span> <span class=o>=</span> <span class=n>engine</span><span class=o>.</span><span class=n>get_metrics</span><span class=p>()</span>
</span><span id=__span-18-2><a id=__codelineno-18-2 name=__codelineno-18-2 href=#__codelineno-18-2></a>
</span><span id=__span-18-3><a id=__codelineno-18-3 name=__codelineno-18-3 href=#__codelineno-18-3></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Performance Summary:&quot;</span><span class=p>)</span>
</span><span id=__span-18-4><a id=__codelineno-18-4 name=__codelineno-18-4 href=#__codelineno-18-4></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Total requests: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;throughput&#39;</span><span class=p>][</span><span class=s1>&#39;total_requests&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-18-5><a id=__codelineno-18-5 name=__codelineno-18-5 href=#__codelineno-18-5></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Total tokens: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;throughput&#39;</span><span class=p>][</span><span class=s1>&#39;total_tokens&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-18-6><a id=__codelineno-18-6 name=__codelineno-18-6 href=#__codelineno-18-6></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Average speed: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;throughput&#39;</span><span class=p>][</span><span class=s1>&#39;tokens_per_sec&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2> tok/s&quot;</span><span class=p>)</span>
</span><span id=__span-18-7><a id=__codelineno-18-7 name=__codelineno-18-7 href=#__codelineno-18-7></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Mean latency: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;latency&#39;</span><span class=p>][</span><span class=s1>&#39;mean_ms&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2> ms&quot;</span><span class=p>)</span>
</span><span id=__span-18-8><a id=__codelineno-18-8 name=__codelineno-18-8 href=#__codelineno-18-8></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Median latency: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;latency&#39;</span><span class=p>][</span><span class=s1>&#39;p50_ms&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2> ms&quot;</span><span class=p>)</span>
</span><span id=__span-18-9><a id=__codelineno-18-9 name=__codelineno-18-9 href=#__codelineno-18-9></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  P95 latency: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;latency&#39;</span><span class=p>][</span><span class=s1>&#39;p95_ms&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2> ms&quot;</span><span class=p>)</span>
</span></code></pre></div> <p><strong>Output:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-19-1><a id=__codelineno-19-1 name=__codelineno-19-1 href=#__codelineno-19-1></a>Performance Summary:
</span><span id=__span-19-2><a id=__codelineno-19-2 name=__codelineno-19-2 href=#__codelineno-19-2></a>  Total requests: 4
</span><span id=__span-19-3><a id=__codelineno-19-3 name=__codelineno-19-3 href=#__codelineno-19-3></a>  Total tokens: 322
</span><span id=__span-19-4><a id=__codelineno-19-4 name=__codelineno-19-4 href=#__codelineno-19-4></a>  Average speed: 135.8 tok/s
</span><span id=__span-19-5><a id=__codelineno-19-5 name=__codelineno-19-5 href=#__codelineno-19-5></a>  Mean latency: 695 ms
</span><span id=__span-19-6><a id=__codelineno-19-6 name=__codelineno-19-6 href=#__codelineno-19-6></a>  Median latency: 690 ms
</span><span id=__span-19-7><a id=__codelineno-19-7 name=__codelineno-19-7 href=#__codelineno-19-7></a>  P95 latency: 725 ms
</span></code></pre></div></p> <h3 id=11-long-context-test>11. Long Context Test<a class=headerlink href=#11-long-context-test title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-20-1><a id=__codelineno-20-1 name=__codelineno-20-1 href=#__codelineno-20-1></a><span class=n>long_prompt</span> <span class=o>=</span> <span class=s2>&quot;&quot;&quot;Write a detailed explanation of how transformers work in natural</span>
</span><span id=__span-20-2><a id=__codelineno-20-2 name=__codelineno-20-2 href=#__codelineno-20-2></a><span class=s2>language processing, including attention mechanisms, positional encodings, and</span>
</span><span id=__span-20-3><a id=__codelineno-20-3 name=__codelineno-20-3 href=#__codelineno-20-3></a><span class=s2>multi-head attention.&quot;&quot;&quot;</span>
</span><span id=__span-20-4><a id=__codelineno-20-4 name=__codelineno-20-4 href=#__codelineno-20-4></a>
</span><span id=__span-20-5><a id=__codelineno-20-5 name=__codelineno-20-5 href=#__codelineno-20-5></a><span class=n>result</span> <span class=o>=</span> <span class=n>engine</span><span class=o>.</span><span class=n>infer</span><span class=p>(</span>
</span><span id=__span-20-6><a id=__codelineno-20-6 name=__codelineno-20-6 href=#__codelineno-20-6></a>    <span class=n>prompt</span><span class=o>=</span><span class=n>long_prompt</span><span class=p>,</span>
</span><span id=__span-20-7><a id=__codelineno-20-7 name=__codelineno-20-7 href=#__codelineno-20-7></a>    <span class=n>max_tokens</span><span class=o>=</span><span class=mi>200</span><span class=p>,</span>
</span><span id=__span-20-8><a id=__codelineno-20-8 name=__codelineno-20-8 href=#__codelineno-20-8></a>    <span class=n>temperature</span><span class=o>=</span><span class=mf>0.7</span>
</span><span id=__span-20-9><a id=__codelineno-20-9 name=__codelineno-20-9 href=#__codelineno-20-9></a><span class=p>)</span>
</span><span id=__span-20-10><a id=__codelineno-20-10 name=__codelineno-20-10 href=#__codelineno-20-10></a>
</span><span id=__span-20-11><a id=__codelineno-20-11 name=__codelineno-20-11 href=#__codelineno-20-11></a><span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=o>.</span><span class=n>text</span><span class=p>)</span>
</span><span id=__span-20-12><a id=__codelineno-20-12 name=__codelineno-20-12 href=#__codelineno-20-12></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Tokens: </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>tokens_generated</span><span class=si>}</span><span class=s2> | Speed: </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>tokens_per_sec</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2> tok/s&quot;</span><span class=p>)</span>
</span></code></pre></div> <p><strong>Output:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-21-1><a id=__codelineno-21-1 name=__codelineno-21-1 href=#__codelineno-21-1></a>Transformers are a type of neural network architecture that revolutionized natural language
</span><span id=__span-21-2><a id=__codelineno-21-2 name=__codelineno-21-2 href=#__codelineno-21-2></a>processing. The key innovation is the attention mechanism, which allows the model to focus on
</span><span id=__span-21-3><a id=__codelineno-21-3 name=__codelineno-21-3 href=#__codelineno-21-3></a>different parts of the input sequence when processing each word.
</span><span id=__span-21-4><a id=__codelineno-21-4 name=__codelineno-21-4 href=#__codelineno-21-4></a>
</span><span id=__span-21-5><a id=__codelineno-21-5 name=__codelineno-21-5 href=#__codelineno-21-5></a>Attention Mechanism:
</span><span id=__span-21-6><a id=__codelineno-21-6 name=__codelineno-21-6 href=#__codelineno-21-6></a>The attention mechanism computes a weighted sum of all input positions for each output position.
</span><span id=__span-21-7><a id=__codelineno-21-7 name=__codelineno-21-7 href=#__codelineno-21-7></a>This allows the model to &quot;attend&quot; to relevant parts of the input, regardless of their distance
</span><span id=__span-21-8><a id=__codelineno-21-8 name=__codelineno-21-8 href=#__codelineno-21-8></a>in the sequence.
</span><span id=__span-21-9><a id=__codelineno-21-9 name=__codelineno-21-9 href=#__codelineno-21-9></a>
</span><span id=__span-21-10><a id=__codelineno-21-10 name=__codelineno-21-10 href=#__codelineno-21-10></a>Positional Encodings:
</span><span id=__span-21-11><a id=__codelineno-21-11 name=__codelineno-21-11 href=#__codelineno-21-11></a>Since transformers don&#39;t have inherent sequential structure like RNNs, they use positional
</span><span id=__span-21-12><a id=__codelineno-21-12 name=__codelineno-21-12 href=#__codelineno-21-12></a>encodings to inject information about token positions. These are added to the input embeddings,
</span><span id=__span-21-13><a id=__codelineno-21-13 name=__codelineno-21-13 href=#__codelineno-21-13></a>typically using sine and cosine functions of different frequencies.
</span><span id=__span-21-14><a id=__codelineno-21-14 name=__codelineno-21-14 href=#__codelineno-21-14></a>
</span><span id=__span-21-15><a id=__codelineno-21-15 name=__codelineno-21-15 href=#__codelineno-21-15></a>Multi-Head Attention:
</span><span id=__span-21-16><a id=__codelineno-21-16 name=__codelineno-21-16 href=#__codelineno-21-16></a>Instead of computing a single attention function, transformers use multiple attention &quot;heads&quot;
</span><span id=__span-21-17><a id=__codelineno-21-17 name=__codelineno-21-17 href=#__codelineno-21-17></a>in parallel. Each head learns different aspects of the relationships between tokens. The outputs
</span><span id=__span-21-18><a id=__codelineno-21-18 name=__codelineno-21-18 href=#__codelineno-21-18></a>are then concatenated and linearly transformed.
</span><span id=__span-21-19><a id=__codelineno-21-19 name=__codelineno-21-19 href=#__codelineno-21-19></a>
</span><span id=__span-21-20><a id=__codelineno-21-20 name=__codelineno-21-20 href=#__codelineno-21-20></a>This architecture enables transformers to capture both local and global dependencies efficiently,
</span><span id=__span-21-21><a id=__codelineno-21-21 name=__codelineno-21-21 href=#__codelineno-21-21></a>making them highly effective for tasks like translation, summarization, and question answering.
</span><span id=__span-21-22><a id=__codelineno-21-22 name=__codelineno-21-22 href=#__codelineno-21-22></a>
</span><span id=__span-21-23><a id=__codelineno-21-23 name=__codelineno-21-23 href=#__codelineno-21-23></a>Tokens: 200 | Speed: 133.7 tok/s
</span></code></pre></div></p> <h3 id=12-creative-generation>12. Creative Generation<a class=headerlink href=#12-creative-generation title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-22-1><a id=__codelineno-22-1 name=__codelineno-22-1 href=#__codelineno-22-1></a><span class=n>result</span> <span class=o>=</span> <span class=n>engine</span><span class=o>.</span><span class=n>infer</span><span class=p>(</span>
</span><span id=__span-22-2><a id=__codelineno-22-2 name=__codelineno-22-2 href=#__codelineno-22-2></a>    <span class=n>prompt</span><span class=o>=</span><span class=s2>&quot;Write a haiku about machine learning:&quot;</span><span class=p>,</span>
</span><span id=__span-22-3><a id=__codelineno-22-3 name=__codelineno-22-3 href=#__codelineno-22-3></a>    <span class=n>max_tokens</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span>
</span><span id=__span-22-4><a id=__codelineno-22-4 name=__codelineno-22-4 href=#__codelineno-22-4></a>    <span class=n>temperature</span><span class=o>=</span><span class=mf>0.9</span>  <span class=c1># Higher temperature for creativity</span>
</span><span id=__span-22-5><a id=__codelineno-22-5 name=__codelineno-22-5 href=#__codelineno-22-5></a><span class=p>)</span>
</span><span id=__span-22-6><a id=__codelineno-22-6 name=__codelineno-22-6 href=#__codelineno-22-6></a>
</span><span id=__span-22-7><a id=__codelineno-22-7 name=__codelineno-22-7 href=#__codelineno-22-7></a><span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=o>.</span><span class=n>text</span><span class=p>)</span>
</span><span id=__span-22-8><a id=__codelineno-22-8 name=__codelineno-22-8 href=#__codelineno-22-8></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Speed: </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>tokens_per_sec</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2> tok/s&quot;</span><span class=p>)</span>
</span></code></pre></div> <p><strong>Output:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-23-1><a id=__codelineno-23-1 name=__codelineno-23-1 href=#__codelineno-23-1></a>Data flows like streams
</span><span id=__span-23-2><a id=__codelineno-23-2 name=__codelineno-23-2 href=#__codelineno-23-2></a>Patterns emerge from chaos
</span><span id=__span-23-3><a id=__codelineno-23-3 name=__codelineno-23-3 href=#__codelineno-23-3></a>Machines learn to think
</span><span id=__span-23-4><a id=__codelineno-23-4 name=__codelineno-23-4 href=#__codelineno-23-4></a>
</span><span id=__span-23-5><a id=__codelineno-23-5 name=__codelineno-23-5 href=#__codelineno-23-5></a>Speed: 138.2 tok/s
</span></code></pre></div></p> <h3 id=13-gpu-memory-usage>13. GPU Memory Usage<a class=headerlink href=#13-gpu-memory-usage title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-24-1><a id=__codelineno-24-1 name=__codelineno-24-1 href=#__codelineno-24-1></a><span class=err>!</span><span class=n>nvidia</span><span class=o>-</span><span class=n>smi</span> <span class=o>--</span><span class=n>query</span><span class=o>-</span><span class=n>gpu</span><span class=o>=</span><span class=n>memory</span><span class=o>.</span><span class=n>used</span><span class=p>,</span><span class=n>memory</span><span class=o>.</span><span class=n>total</span> <span class=o>--</span><span class=nb>format</span><span class=o>=</span><span class=n>csv</span>
</span></code></pre></div> <p><strong>Output:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-25-1><a id=__codelineno-25-1 name=__codelineno-25-1 href=#__codelineno-25-1></a>memory.used [MiB], memory.total [MiB]
</span><span id=__span-25-2><a id=__codelineno-25-2 name=__codelineno-25-2 href=#__codelineno-25-2></a>1247 MiB, 15360 MiB
</span></code></pre></div></p> <div class="admonition info"> <p class=admonition-title>Memory Efficiency</p> <p>Gemma 3-1B Q4_K_M uses only <strong>1.2 GB</strong> of GPU memory, leaving plenty of VRAM for larger context windows or batch processing.</p> </div> <h3 id=14-final-performance-summary>14. Final Performance Summary<a class=headerlink href=#14-final-performance-summary title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-26-1><a id=__codelineno-26-1 name=__codelineno-26-1 href=#__codelineno-26-1></a><span class=n>final_metrics</span> <span class=o>=</span> <span class=n>engine</span><span class=o>.</span><span class=n>get_metrics</span><span class=p>()</span>
</span><span id=__span-26-2><a id=__codelineno-26-2 name=__codelineno-26-2 href=#__codelineno-26-2></a>
</span><span id=__span-26-3><a id=__codelineno-26-3 name=__codelineno-26-3 href=#__codelineno-26-3></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>&quot;</span> <span class=o>+</span> <span class=s2>&quot;=&quot;</span><span class=o>*</span><span class=mi>60</span><span class=p>)</span>
</span><span id=__span-26-4><a id=__codelineno-26-4 name=__codelineno-26-4 href=#__codelineno-26-4></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;FINAL PERFORMANCE RESULTS&quot;</span><span class=p>)</span>
</span><span id=__span-26-5><a id=__codelineno-26-5 name=__codelineno-26-5 href=#__codelineno-26-5></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;=&quot;</span><span class=o>*</span><span class=mi>60</span><span class=p>)</span>
</span><span id=__span-26-6><a id=__codelineno-26-6 name=__codelineno-26-6 href=#__codelineno-26-6></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Model: Gemma 3-1B Q4_K_M&quot;</span><span class=p>)</span>
</span><span id=__span-26-7><a id=__codelineno-26-7 name=__codelineno-26-7 href=#__codelineno-26-7></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;GPU: Tesla T4 (SM 7.5)&quot;</span><span class=p>)</span>
</span><span id=__span-26-8><a id=__codelineno-26-8 name=__codelineno-26-8 href=#__codelineno-26-8></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;CUDA: 12.2&quot;</span><span class=p>)</span>
</span><span id=__span-26-9><a id=__codelineno-26-9 name=__codelineno-26-9 href=#__codelineno-26-9></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Throughput:&quot;</span><span class=p>)</span>
</span><span id=__span-26-10><a id=__codelineno-26-10 name=__codelineno-26-10 href=#__codelineno-26-10></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Total requests: </span><span class=si>{</span><span class=n>final_metrics</span><span class=p>[</span><span class=s1>&#39;throughput&#39;</span><span class=p>][</span><span class=s1>&#39;total_requests&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-26-11><a id=__codelineno-26-11 name=__codelineno-26-11 href=#__codelineno-26-11></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Total tokens: </span><span class=si>{</span><span class=n>final_metrics</span><span class=p>[</span><span class=s1>&#39;throughput&#39;</span><span class=p>][</span><span class=s1>&#39;total_tokens&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-26-12><a id=__codelineno-26-12 name=__codelineno-26-12 href=#__codelineno-26-12></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Average speed: </span><span class=si>{</span><span class=n>final_metrics</span><span class=p>[</span><span class=s1>&#39;throughput&#39;</span><span class=p>][</span><span class=s1>&#39;tokens_per_sec&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2> tok/s&quot;</span><span class=p>)</span>
</span><span id=__span-26-13><a id=__codelineno-26-13 name=__codelineno-26-13 href=#__codelineno-26-13></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Latency:&quot;</span><span class=p>)</span>
</span><span id=__span-26-14><a id=__codelineno-26-14 name=__codelineno-26-14 href=#__codelineno-26-14></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Mean: </span><span class=si>{</span><span class=n>final_metrics</span><span class=p>[</span><span class=s1>&#39;latency&#39;</span><span class=p>][</span><span class=s1>&#39;mean_ms&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2> ms&quot;</span><span class=p>)</span>
</span><span id=__span-26-15><a id=__codelineno-26-15 name=__codelineno-26-15 href=#__codelineno-26-15></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Median (P50): </span><span class=si>{</span><span class=n>final_metrics</span><span class=p>[</span><span class=s1>&#39;latency&#39;</span><span class=p>][</span><span class=s1>&#39;p50_ms&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2> ms&quot;</span><span class=p>)</span>
</span><span id=__span-26-16><a id=__codelineno-26-16 name=__codelineno-26-16 href=#__codelineno-26-16></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  P95: </span><span class=si>{</span><span class=n>final_metrics</span><span class=p>[</span><span class=s1>&#39;latency&#39;</span><span class=p>][</span><span class=s1>&#39;p95_ms&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2> ms&quot;</span><span class=p>)</span>
</span><span id=__span-26-17><a id=__codelineno-26-17 name=__codelineno-26-17 href=#__codelineno-26-17></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Min: </span><span class=si>{</span><span class=n>final_metrics</span><span class=p>[</span><span class=s1>&#39;latency&#39;</span><span class=p>][</span><span class=s1>&#39;min_ms&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2> ms&quot;</span><span class=p>)</span>
</span><span id=__span-26-18><a id=__codelineno-26-18 name=__codelineno-26-18 href=#__codelineno-26-18></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Max: </span><span class=si>{</span><span class=n>final_metrics</span><span class=p>[</span><span class=s1>&#39;latency&#39;</span><span class=p>][</span><span class=s1>&#39;max_ms&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2> ms&quot;</span><span class=p>)</span>
</span><span id=__span-26-19><a id=__codelineno-26-19 name=__codelineno-26-19 href=#__codelineno-26-19></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;=&quot;</span><span class=o>*</span><span class=mi>60</span><span class=p>)</span>
</span></code></pre></div> <p><strong>Output:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-27-1><a id=__codelineno-27-1 name=__codelineno-27-1 href=#__codelineno-27-1></a>============================================================
</span><span id=__span-27-2><a id=__codelineno-27-2 name=__codelineno-27-2 href=#__codelineno-27-2></a>FINAL PERFORMANCE RESULTS
</span><span id=__span-27-3><a id=__codelineno-27-3 name=__codelineno-27-3 href=#__codelineno-27-3></a>============================================================
</span><span id=__span-27-4><a id=__codelineno-27-4 name=__codelineno-27-4 href=#__codelineno-27-4></a>Model: Gemma 3-1B Q4_K_M
</span><span id=__span-27-5><a id=__codelineno-27-5 name=__codelineno-27-5 href=#__codelineno-27-5></a>GPU: Tesla T4 (SM 7.5)
</span><span id=__span-27-6><a id=__codelineno-27-6 name=__codelineno-27-6 href=#__codelineno-27-6></a>CUDA: 12.2
</span><span id=__span-27-7><a id=__codelineno-27-7 name=__codelineno-27-7 href=#__codelineno-27-7></a>
</span><span id=__span-27-8><a id=__codelineno-27-8 name=__codelineno-27-8 href=#__codelineno-27-8></a>Throughput:
</span><span id=__span-27-9><a id=__codelineno-27-9 name=__codelineno-27-9 href=#__codelineno-27-9></a>  Total requests: 6
</span><span id=__span-27-10><a id=__codelineno-27-10 name=__codelineno-27-10 href=#__codelineno-27-10></a>  Total tokens: 572
</span><span id=__span-27-11><a id=__codelineno-27-11 name=__codelineno-27-11 href=#__codelineno-27-11></a>  Average speed: 134.3 tok/s
</span><span id=__span-27-12><a id=__codelineno-27-12 name=__codelineno-27-12 href=#__codelineno-27-12></a>
</span><span id=__span-27-13><a id=__codelineno-27-13 name=__codelineno-27-13 href=#__codelineno-27-13></a>Latency:
</span><span id=__span-27-14><a id=__codelineno-27-14 name=__codelineno-27-14 href=#__codelineno-27-14></a>  Mean: 695 ms
</span><span id=__span-27-15><a id=__codelineno-27-15 name=__codelineno-27-15 href=#__codelineno-27-15></a>  Median (P50): 690 ms
</span><span id=__span-27-16><a id=__codelineno-27-16 name=__codelineno-27-16 href=#__codelineno-27-16></a>  P95: 725 ms
</span><span id=__span-27-17><a id=__codelineno-27-17 name=__codelineno-27-17 href=#__codelineno-27-17></a>  Min: 610 ms
</span><span id=__span-27-18><a id=__codelineno-27-18 name=__codelineno-27-18 href=#__codelineno-27-18></a>  Max: 748 ms
</span><span id=__span-27-19><a id=__codelineno-27-19 name=__codelineno-27-19 href=#__codelineno-27-19></a>============================================================
</span></code></pre></div></p> <h2 id=key-performance-observations>Key Performance Observations<a class=headerlink href=#key-performance-observations title="Permanent link">&para;</a></h2> <h3 id=1-consistent-throughput>1. Consistent Throughput<a class=headerlink href=#1-consistent-throughput title="Permanent link">&para;</a></h3> <p>The inference speed remained remarkably consistent across different workloads:</p> <ul> <li><strong>Short prompts:</strong> 130-142 tok/s</li> <li><strong>Long contexts:</strong> 133-138 tok/s</li> <li><strong>Creative generation:</strong> 138 tok/s</li> <li><strong>Average across all:</strong> <strong>134.3 tok/s</strong></li> </ul> <h3 id=2-low-latency>2. Low Latency<a class=headerlink href=#2-low-latency title="Permanent link">&para;</a></h3> <p>Median latency of <strong>690ms</strong> for typical queries provides excellent interactive experience:</p> <ul> <li>P50 latency: 690ms</li> <li>P95 latency: 725ms</li> <li>Variation: Less than 140ms between min and max</li> </ul> <h3 id=3-memory-efficiency>3. Memory Efficiency<a class=headerlink href=#3-memory-efficiency title="Permanent link">&para;</a></h3> <p>Only <strong>1.2 GB</strong> GPU memory used:</p> <ul> <li>Leaves 14+ GB free for larger models</li> <li>Enables batch processing</li> <li>Supports long context windows (up to 8K+)</li> </ul> <h3 id=4-comparison-to-expectations>4. Comparison to Expectations<a class=headerlink href=#4-comparison-to-expectations title="Permanent link">&para;</a></h3> <table> <thead> <tr> <th>Metric</th> <th>Expected</th> <th>Actual</th> <th>Improvement</th> </tr> </thead> <tbody> <tr> <td>Speed</td> <td>45 tok/s</td> <td>134 tok/s</td> <td><strong>3x faster</strong></td> </tr> <tr> <td>Latency</td> <td>~2000ms</td> <td>690ms</td> <td><strong>2.9x lower</strong></td> </tr> <tr> <td>Memory</td> <td>~1.5 GB</td> <td>1.2 GB</td> <td>20% less</td> </tr> </tbody> </table> <h2 id=what-enabled-this-performance>What Enabled This Performance?<a class=headerlink href=#what-enabled-this-performance title="Permanent link">&para;</a></h2> <h3 id=1-flashattention>1. FlashAttention<a class=headerlink href=#1-flashattention title="Permanent link">&para;</a></h3> <p>The CUDA binaries include FlashAttention optimizations:</p> <ul> <li>2-3x faster attention computation</li> <li>Reduced memory bandwidth requirements</li> <li>Optimized for Turing+ architectures (T4 is SM 7.5)</li> </ul> <h3 id=2-tensor-cores>2. Tensor Cores<a class=headerlink href=#2-tensor-cores title="Permanent link">&para;</a></h3> <p>llcuda v2.1.0 utilizes T4's Tensor Cores:</p> <ul> <li>INT8/INT4 matrix operations</li> <li>Hardware-accelerated quantized inference</li> <li>Optimized cuBLAS kernels</li> </ul> <h3 id=3-cuda-12-optimizations>3. CUDA 12 Optimizations<a class=headerlink href=#3-cuda-12-optimizations title="Permanent link">&para;</a></h3> <p>Latest CUDA 12.2 runtime provides:</p> <ul> <li>Improved kernel scheduling</li> <li>Better memory management</li> <li>Enhanced parallel execution</li> </ul> <h3 id=4-q4_k_m-quantization>4. Q4_K_M Quantization<a class=headerlink href=#4-q4_k_m-quantization title="Permanent link">&para;</a></h3> <p>4-bit K-means quantization offers:</p> <ul> <li>Minimal accuracy loss</li> <li>8x memory reduction vs FP32</li> <li>Faster computation with int4 operations</li> </ul> <h2 id=reproducing-these-results>Reproducing These Results<a class=headerlink href=#reproducing-these-results title="Permanent link">&para;</a></h2> <p>To reproduce these results yourself:</p> <ol> <li><strong>Open the executed notebook:</strong></li> <li> <p><a href=https://github.com/waqasm86/llcuda/blob/main/notebooks/llcuda_v2_1_0_gemma3_1b_unsloth_colab_executed.ipynb>llcuda_v2_1_0_gemma3_1b_unsloth_colab_executed.ipynb</a></p> </li> <li> <p><strong>Run in Google Colab:</strong></p> </li> <li>Select Runtime &gt; Change runtime type &gt; T4 GPU</li> <li> <p>Run all cells sequentially</p> </li> <li> <p><strong>Try the interactive notebook:</strong></p> </li> <li><a href=https://github.com/waqasm86/llcuda/blob/main/notebooks/llcuda_v2_1_0_gemma3_1b_unsloth_colab.ipynb>llcuda_v2_1_0_gemma3_1b_unsloth_colab.ipynb</a></li> </ol> <h2 id=conclusion>Conclusion<a class=headerlink href=#conclusion title="Permanent link">&para;</a></h2> <p>This executed example demonstrates that llcuda v2.1.0 achieves <strong>134 tokens/sec</strong> on Gemma 3-1B with Tesla T4, making it an excellent choice for:</p> <ul> <li><strong>Interactive applications:</strong> Low latency (690ms median)</li> <li><strong>Production deployment:</strong> Consistent performance</li> <li><strong>Cost-effective inference:</strong> Free Google Colab support</li> <li><strong>Research experiments:</strong> Fast iteration cycles</li> </ul> <div class="admonition success"> <p class=admonition-title>Production Ready</p> <p>With verified 134 tok/s performance and sub-second latency, llcuda v2.1.0 is ready for production LLM inference on Tesla T4 GPUs.</p> </div> <h2 id=next-steps>Next Steps<a class=headerlink href=#next-steps title="Permanent link">&para;</a></h2> <ul> <li><a href=../../performance/benchmarks/ >Performance Benchmarks</a> - Compare with other models</li> <li><a href=../../performance/optimization/ >Optimization Guide</a> - Further performance tuning</li> <li><a href=../unsloth-integration/ >Unsloth Integration</a> - Fine-tune your own models</li> <li><a href=../gemma-3-1b-colab/ >Google Colab Tutorial</a> - Interactive step-by-step guide</li> </ul> <h2 id=resources>Resources<a class=headerlink href=#resources title="Permanent link">&para;</a></h2> <ul> <li><strong>Executed Notebook:</strong> <a href=https://github.com/waqasm86/llcuda/blob/main/notebooks/llcuda_v2_1_0_gemma3_1b_unsloth_colab_executed.ipynb>View on GitHub</a></li> <li><strong>Interactive Notebook:</strong> <a href=https://colab.research.google.com/github/waqasm86/llcuda/blob/main/notebooks/llcuda_v2_1_0_gemma3_1b_unsloth_colab.ipynb>Open in Colab</a></li> <li><strong>GitHub Issues:</strong> <a href=https://github.com/waqasm86/llcuda/issues>Report issues</a></li> </ul> <form class=md-feedback name=feedback hidden> <fieldset> <legend class=md-feedback__title> Was this page helpful? </legend> <div class=md-feedback__inner> <div class=md-feedback__list> <button class="md-feedback__icon md-icon" type=submit title="This page was helpful" data-md-value=1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m7 0c0 .8-.7 1.5-1.5 1.5S14 10.3 14 9.5 14.7 8 15.5 8s1.5.7 1.5 1.5m-5 7.73c-1.75 0-3.29-.73-4.19-1.81L9.23 14c.45.72 1.52 1.23 2.77 1.23s2.32-.51 2.77-1.23l1.42 1.42c-.9 1.08-2.44 1.81-4.19 1.81"/></svg> </button> <button class="md-feedback__icon md-icon" type=submit title="This page could be improved" data-md-value=0> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10m-6.5-4c.8 0 1.5.7 1.5 1.5s-.7 1.5-1.5 1.5-1.5-.7-1.5-1.5.7-1.5 1.5-1.5M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m2 4.5c1.75 0 3.29.72 4.19 1.81l-1.42 1.42C14.32 16.5 13.25 16 12 16s-2.32.5-2.77 1.23l-1.42-1.42C8.71 14.72 10.25 14 12 14"/></svg> </button> </div> <div class=md-feedback__note> <div data-md-value=1 hidden> Thanks for your feedback! </div> <div data-md-value=0 hidden> Thanks for your feedback! Help us improve by <a href=https://github.com/waqasm86/llcuda/issues/new target=_blank rel=noopener>opening an issue</a>. </div> </div> </div> </fieldset> </form> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../gemma-3-1b-colab/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Gemma 3-1B Tutorial"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Gemma 3-1B Tutorial </div> </div> </a> <a href=../build-binaries/ class="md-footer__link md-footer__link--next" aria-label="Next: Build Binaries"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Build Binaries </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2024-2026 Waqas Muhammad </div> </div> <div class=md-social> <a href=https://github.com/waqasm86 target=_blank rel=noopener title="GitHub - waqasm86" class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=mailto:waqasm86@gmail.com target=_blank rel=noopener title="Email - waqasm86@gmail.com" class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M48 64C21.5 64 0 85.5 0 112c0 15.1 7.1 29.3 19.2 38.4l208 156a48 48 0 0 0 57.6 0l208-156c12.1-9.1 19.2-23.3 19.2-38.4 0-26.5-21.5-48-48-48zM0 196v188c0 35.3 28.7 64 64 64h384c35.3 0 64-28.7 64-64V196L313.6 344.8c-34.1 25.6-81.1 25.6-115.2 0z"/></svg> </a> <a href=https://www.linkedin.com/in/waqasm86 target=_blank rel=noopener title="LinkedIn - Waqas Muhammad" class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <div class=md-consent data-md-component=consent id=__consent hidden> <div class=md-consent__overlay></div> <aside class=md-consent__inner> <form class="md-consent__form md-grid md-typeset" name=consent> <h4>Cookie consent</h4> <p>We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they're searching for. With your consent, you're helping us to make our documentation better.</p> <input class=md-toggle type=checkbox id=__settings> <div class=md-consent__settings> <ul class=task-list> <li class=task-list-item> <label class=task-list-control> <input type=checkbox name=analytics checked> <span class=task-list-indicator></span> Google Analytics </label> </li> <li class=task-list-item> <label class=task-list-control> <input type=checkbox name=github checked> <span class=task-list-indicator></span> GitHub </label> </li> </ul> </div> <div class=md-consent__controls> <button class="md-button md-button--primary">Accept</button> <label class=md-button for=__settings>Manage settings</label> </div> </form> </aside> </div> <script>var consent=__md_get("__consent");if(consent)for(var input of document.forms.consent.elements)input.name&&(input.checked=consent[input.name]||!1);else"file:"!==location.protocol&&setTimeout((function(){document.querySelector("[data-md-component=consent]").hidden=!1}),250);var form=document.forms.consent;for(var action of["submit","reset"])form.addEventListener(action,(function(e){if(e.preventDefault(),"reset"===e.type)for(var n of document.forms.consent.elements)n.name&&(n.checked=!1);__md_set("__consent",Object.fromEntries(Array.from(new FormData(form).keys()).map((function(e){return[e,!0]})))),location.hash="",location.reload()}))</script> <script id=__config type=application/json>{"annotate": null, "base": "../..", "features": ["announce.dismiss", "content.code.annotate", "content.code.copy", "content.tabs.link", "content.tooltips", "header.autohide", "navigation.expand", "navigation.footer", "navigation.indexes", "navigation.instant", "navigation.instant.prefetch", "navigation.instant.progress", "navigation.path", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow", "toc.integrate"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": "latest", "provider": "mike"}}</script> <script src=../../assets/javascripts/bundle.79ae519e.min.js></script> <script src=../../javascripts/mathjax.js></script> <script src=../../javascripts/schema.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>