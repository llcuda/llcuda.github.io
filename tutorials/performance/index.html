<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Fast LLM inference on Tesla T4 GPUs with CUDA 12, FlashAttention, and Unsloth integration. Verified 134 tokens/sec on Gemma 3-1B. GitHub-only distribution with auto-downloading binaries. Perfect for Google Colab and production deployment."><meta name=author content="Waqas Muhammad"><link href=https://llcuda.github.io/tutorials/performance/ rel=canonical><link href=../unsloth-integration/ rel=prev><link href=../../api/overview/ rel=next><link rel=icon href=../../assets/images/logo.svg><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.7.1"><title>Performance Optimization - llcuda v2.0.6 - Tesla T4 CUDA Inference</title><link rel=stylesheet href=../../assets/stylesheets/main.484c7ddc.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.ab4e12ef.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../stylesheets/extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-XXXXXXXXXX"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-XXXXXXXXXX",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>if("undefined"!=typeof __md_analytics){var consent=__md_get("__consent");consent&&consent.analytics&&__md_analytics()}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=deep-purple> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#performance-optimization-tutorial class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <div data-md-color-scheme=default data-md-component=outdated hidden> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="llcuda v2.0.6 - Tesla T4 CUDA Inference" class="md-header__button md-logo" aria-label="llcuda v2.0.6 - Tesla T4 CUDA Inference" data-md-component=logo> <img src=../../assets/images/logo.svg alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> llcuda v2.0.6 - Tesla T4 CUDA Inference </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Performance Optimization </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=deep-purple aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=deep-purple aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/waqasm86/llcuda title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> waqasm86/llcuda </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../guides/quickstart/ class=md-tabs__link> Getting Started </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../gemma-3-1b-colab/ class=md-tabs__link> Tutorials </a> </li> <li class=md-tabs__item> <a href=../../api/overview/ class=md-tabs__link> API Reference </a> </li> <li class=md-tabs__item> <a href=../../performance/benchmarks/ class=md-tabs__link> Performance </a> </li> <li class=md-tabs__item> <a href=../../guides/model-selection/ class=md-tabs__link> Guides </a> </li> <li class=md-tabs__item> <a href=../../notebooks/ class=md-tabs__link> Notebooks </a> </li> <li class=md-tabs__item> <a href=https://github.com/waqasm86/llcuda class=md-tabs__link> Links </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="llcuda v2.0.6 - Tesla T4 CUDA Inference" class="md-nav__button md-logo" aria-label="llcuda v2.0.6 - Tesla T4 CUDA Inference" data-md-component=logo> <img src=../../assets/images/logo.svg alt=logo> </a> llcuda v2.0.6 - Tesla T4 CUDA Inference </label> <div class=md-nav__source> <a href=https://github.com/waqasm86/llcuda title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> waqasm86/llcuda </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Getting Started </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Getting Started </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../guides/quickstart/ class=md-nav__link> <span class=md-ellipsis> Quick Start </span> </a> </li> <li class=md-nav__item> <a href=../../guides/installation/ class=md-nav__link> <span class=md-ellipsis> Installation </span> </a> </li> <li class=md-nav__item> <a href=../../guides/first-steps/ class=md-nav__link> <span class=md-ellipsis> First Steps </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_3 checked> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex> <span class=md-ellipsis> Tutorials </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=true> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Tutorials </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3_1> <label class=md-nav__link for=__nav_3_1 id=__nav_3_1_label tabindex> <span class=md-ellipsis> Google Colab </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_1_label aria-expanded=false> <label class=md-nav__title for=__nav_3_1> <span class="md-nav__icon md-icon"></span> Google Colab </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../gemma-3-1b-colab/ class=md-nav__link> <span class=md-ellipsis> Gemma 3-1B Tutorial </span> </a> </li> <li class=md-nav__item> <a href=../gemma-3-1b-executed/ class=md-nav__link> <span class=md-ellipsis> Executed Example </span> </a> </li> <li class=md-nav__item> <a href=../build-binaries/ class=md-nav__link> <span class=md-ellipsis> Build Binaries </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../unsloth-integration/ class=md-nav__link> <span class=md-ellipsis> Unsloth Integration </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Performance Optimization </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Performance Optimization </span> </a> <nav class="md-nav md-nav--secondary" aria-label="On this page"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> On this page </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#performance-overview class=md-nav__link> <span class=md-ellipsis> Performance Overview </span> </a> </li> <li class=md-nav__item> <a href=#key-performance-factors class=md-nav__link> <span class=md-ellipsis> Key Performance Factors </span> </a> <nav class=md-nav aria-label="Key Performance Factors"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#1-quantization-method class=md-nav__link> <span class=md-ellipsis> 1. Quantization Method </span> </a> </li> <li class=md-nav__item> <a href=#2-gpu-layer-offloading class=md-nav__link> <span class=md-ellipsis> 2. GPU Layer Offloading </span> </a> </li> <li class=md-nav__item> <a href=#3-context-window-size class=md-nav__link> <span class=md-ellipsis> 3. Context Window Size </span> </a> </li> <li class=md-nav__item> <a href=#4-batch-processing class=md-nav__link> <span class=md-ellipsis> 4. Batch Processing </span> </a> </li> <li class=md-nav__item> <a href=#5-flash-attention class=md-nav__link> <span class=md-ellipsis> 5. Flash Attention </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#optimization-workflow class=md-nav__link> <span class=md-ellipsis> Optimization Workflow </span> </a> <nav class=md-nav aria-label="Optimization Workflow"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#step-1-baseline-measurement class=md-nav__link> <span class=md-ellipsis> Step 1: Baseline Measurement </span> </a> </li> <li class=md-nav__item> <a href=#step-2-optimize-gpu-offload class=md-nav__link> <span class=md-ellipsis> Step 2: Optimize GPU Offload </span> </a> </li> <li class=md-nav__item> <a href=#step-3-optimize-context-size class=md-nav__link> <span class=md-ellipsis> Step 3: Optimize Context Size </span> </a> </li> <li class=md-nav__item> <a href=#step-4-optimize-batch-parameters class=md-nav__link> <span class=md-ellipsis> Step 4: Optimize Batch Parameters </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#advanced-optimizations class=md-nav__link> <span class=md-ellipsis> Advanced Optimizations </span> </a> <nav class=md-nav aria-label="Advanced Optimizations"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#parallel-sequences class=md-nav__link> <span class=md-ellipsis> Parallel Sequences </span> </a> </li> <li class=md-nav__item> <a href=#continuous-batching class=md-nav__link> <span class=md-ellipsis> Continuous Batching </span> </a> </li> <li class=md-nav__item> <a href=#temperature-tuning class=md-nav__link> <span class=md-ellipsis> Temperature Tuning </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#memory-optimization class=md-nav__link> <span class=md-ellipsis> Memory Optimization </span> </a> <nav class=md-nav aria-label="Memory Optimization"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#model-caching class=md-nav__link> <span class=md-ellipsis> Model Caching </span> </a> </li> <li class=md-nav__item> <a href=#kv-cache-management class=md-nav__link> <span class=md-ellipsis> KV Cache Management </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#profiling-and-monitoring class=md-nav__link> <span class=md-ellipsis> Profiling and Monitoring </span> </a> <nav class=md-nav aria-label="Profiling and Monitoring"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#built-in-metrics class=md-nav__link> <span class=md-ellipsis> Built-in Metrics </span> </a> </li> <li class=md-nav__item> <a href=#gpu-monitoring class=md-nav__link> <span class=md-ellipsis> GPU Monitoring </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#performance-checklist class=md-nav__link> <span class=md-ellipsis> Performance Checklist </span> </a> </li> <li class=md-nav__item> <a href=#common-performance-issues class=md-nav__link> <span class=md-ellipsis> Common Performance Issues </span> </a> <nav class=md-nav aria-label="Common Performance Issues"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#issue-slow-inference-50-toks class=md-nav__link> <span class=md-ellipsis> Issue: Slow Inference (&lt;50 tok/s) </span> </a> </li> <li class=md-nav__item> <a href=#issue-high-latency-2000ms class=md-nav__link> <span class=md-ellipsis> Issue: High Latency (&gt;2000ms) </span> </a> </li> <li class=md-nav__item> <a href=#issue-out-of-memory class=md-nav__link> <span class=md-ellipsis> Issue: Out of Memory </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#best-configurations class=md-nav__link> <span class=md-ellipsis> Best Configurations </span> </a> <nav class=md-nav aria-label="Best Configurations"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#configuration-1-maximum-speed class=md-nav__link> <span class=md-ellipsis> Configuration 1: Maximum Speed </span> </a> </li> <li class=md-nav__item> <a href=#configuration-2-balanced class=md-nav__link> <span class=md-ellipsis> Configuration 2: Balanced </span> </a> </li> <li class=md-nav__item> <a href=#configuration-3-long-context class=md-nav__link> <span class=md-ellipsis> Configuration 3: Long Context </span> </a> </li> <li class=md-nav__item> <a href=#configuration-4-multi-request class=md-nav__link> <span class=md-ellipsis> Configuration 4: Multi-Request </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#next-steps class=md-nav__link> <span class=md-ellipsis> Next Steps </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> API Reference </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> API Reference </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../api/overview/ class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class=md-nav__item> <a href=../../api/inference-engine/ class=md-nav__link> <span class=md-ellipsis> InferenceEngine </span> </a> </li> <li class=md-nav__item> <a href=../../api/models/ class=md-nav__link> <span class=md-ellipsis> Models & GGUF </span> </a> </li> <li class=md-nav__item> <a href=../../api/device/ class=md-nav__link> <span class=md-ellipsis> GPU & Device </span> </a> </li> <li class=md-nav__item> <a href=../../api/examples/ class=md-nav__link> <span class=md-ellipsis> Examples </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex=0> <span class=md-ellipsis> Performance </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Performance </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../performance/benchmarks/ class=md-nav__link> <span class=md-ellipsis> Benchmarks </span> </a> </li> <li class=md-nav__item> <a href=../../performance/t4-results/ class=md-nav__link> <span class=md-ellipsis> Tesla T4 Results </span> </a> </li> <li class=md-nav__item> <a href=../../performance/optimization/ class=md-nav__link> <span class=md-ellipsis> Optimization Guide </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_6> <label class=md-nav__link for=__nav_6 id=__nav_6_label tabindex=0> <span class=md-ellipsis> Guides </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> Guides </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../guides/model-selection/ class=md-nav__link> <span class=md-ellipsis> Model Selection </span> </a> </li> <li class=md-nav__item> <a href=../../guides/gguf-format/ class=md-nav__link> <span class=md-ellipsis> GGUF Format </span> </a> </li> <li class=md-nav__item> <a href=../../guides/troubleshooting/ class=md-nav__link> <span class=md-ellipsis> Troubleshooting </span> </a> </li> <li class=md-nav__item> <a href=../../guides/faq/ class=md-nav__link> <span class=md-ellipsis> FAQ </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_7> <div class="md-nav__link md-nav__container"> <a href=../../notebooks/ class="md-nav__link "> <span class=md-ellipsis> Notebooks </span> </a> <label class="md-nav__link " for=__nav_7 id=__nav_7_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_7_label aria-expanded=false> <label class=md-nav__title for=__nav_7> <span class="md-nav__icon md-icon"></span> Notebooks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../notebooks/colab/ class=md-nav__link> <span class=md-ellipsis> Colab Notebooks </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_8> <label class=md-nav__link for=__nav_8 id=__nav_8_label tabindex=0> <span class=md-ellipsis> Links </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_8_label aria-expanded=false> <label class=md-nav__title for=__nav_8> <span class="md-nav__icon md-icon"></span> Links </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=https://github.com/waqasm86/llcuda class=md-nav__link> <span class=md-ellipsis> GitHub Repository </span> </a> </li> <li class=md-nav__item> <a href=https://github.com/waqasm86/llcuda/releases class=md-nav__link> <span class=md-ellipsis> GitHub Releases </span> </a> </li> <li class=md-nav__item> <a href=https://github.com/waqasm86/llcuda/issues class=md-nav__link> <span class=md-ellipsis> Issues & Support </span> </a> </li> <li class=md-nav__item> <a href=https://github.com/waqasm86/llcuda/blob/main/CHANGELOG.md class=md-nav__link> <span class=md-ellipsis> Changelog </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <nav class=md-path aria-label=Navigation> <ol class=md-path__list> <li class=md-path__item> <a href=../.. class=md-path__link> <span class=md-ellipsis> Home </span> </a> </li> <li class=md-path__item> <a href=../gemma-3-1b-colab/ class=md-path__link> <span class=md-ellipsis> Tutorials </span> </a> </li> </ol> </nav> <article class="md-content__inner md-typeset"> <h1 id=performance-optimization-tutorial>Performance Optimization Tutorial<a class=headerlink href=#performance-optimization-tutorial title="Permanent link">&para;</a></h1> <p>Learn how to optimize llcuda for maximum throughput and minimum latency on Tesla T4 GPUs.</p> <div class="admonition tip"> <p class=admonition-title>Quick Win</p> <p>For immediate performance gains, use Q4_K_M quantization with full GPU offload (gpu_layers=99). This achieves 130+ tok/s on Gemma 3-1B.</p> </div> <h2 id=performance-overview>Performance Overview<a class=headerlink href=#performance-overview title="Permanent link">&para;</a></h2> <p>llcuda v2.0.6 achieves exceptional performance on Tesla T4:</p> <ul> <li><strong>Gemma 3-1B:</strong> 134 tok/s (verified)</li> <li><strong>Latency:</strong> &lt; 700ms median</li> <li><strong>Memory:</strong> 1.2 GB for 1B models</li> <li><strong>Throughput:</strong> Consistent across batch sizes</li> </ul> <h2 id=key-performance-factors>Key Performance Factors<a class=headerlink href=#key-performance-factors title="Permanent link">&para;</a></h2> <h3 id=1-quantization-method>1. Quantization Method<a class=headerlink href=#1-quantization-method title="Permanent link">&para;</a></h3> <p>Choose the right quantization for your use case:</p> <div class="tabbed-set tabbed-alternate" data-tabs=1:3><input checked=checked id=__tabbed_1_1 name=__tabbed_1 type=radio><input id=__tabbed_1_2 name=__tabbed_1 type=radio><input id=__tabbed_1_3 name=__tabbed_1 type=radio><div class=tabbed-labels><label for=__tabbed_1_1>Q4_K_M (Recommended)</label><label for=__tabbed_1_2>Q5_K_M (Better Quality)</label><label for=__tabbed_1_3>Q8_0 (Highest Quality)</label></div> <div class=tabbed-content> <div class=tabbed-block> <div class="language-python highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=s2>&quot;model-Q4_K_M.gguf&quot;</span><span class=p>,</span> <span class=n>gpu_layers</span><span class=o>=</span><span class=mi>99</span><span class=p>)</span>
</span></code></pre></div> <p><strong>Performance:</strong> 134 tok/s (Gemma 3-1B) <strong>Memory:</strong> 1.2 GB <strong>Quality:</strong> Excellent (&lt; 1% degradation) <strong>Use case:</strong> Production inference</p> </div> <div class=tabbed-block> <div class="language-python highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=s2>&quot;model-Q5_K_M.gguf&quot;</span><span class=p>,</span> <span class=n>gpu_layers</span><span class=o>=</span><span class=mi>99</span><span class=p>)</span>
</span></code></pre></div> <p><strong>Performance:</strong> ~110 tok/s <strong>Memory:</strong> 1.5 GB <strong>Quality:</strong> Near-perfect <strong>Use case:</strong> Quality-critical applications</p> </div> <div class=tabbed-block> <div class="language-python highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=s2>&quot;model-Q8_0.gguf&quot;</span><span class=p>,</span> <span class=n>gpu_layers</span><span class=o>=</span><span class=mi>99</span><span class=p>)</span>
</span></code></pre></div> <p><strong>Performance:</strong> ~75 tok/s <strong>Memory:</strong> 2.5 GB <strong>Quality:</strong> Minimal loss <strong>Use case:</strong> Accuracy-first scenarios</p> </div> </div> </div> <p><strong>Recommendation:</strong> Use Q4_K_M for best performance/quality balance.</p> <h3 id=2-gpu-layer-offloading>2. GPU Layer Offloading<a class=headerlink href=#2-gpu-layer-offloading title="Permanent link">&para;</a></h3> <p>Control how many layers run on GPU:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=c1># Full GPU offload (fastest)</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=s2>&quot;model.gguf&quot;</span><span class=p>,</span> <span class=n>gpu_layers</span><span class=o>=</span><span class=mi>99</span><span class=p>)</span>  <span class=c1># 134 tok/s</span>
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a>
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a><span class=c1># Partial offload (if VRAM limited)</span>
</span><span id=__span-3-5><a id=__codelineno-3-5 name=__codelineno-3-5 href=#__codelineno-3-5></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=s2>&quot;model.gguf&quot;</span><span class=p>,</span> <span class=n>gpu_layers</span><span class=o>=</span><span class=mi>20</span><span class=p>)</span>  <span class=c1># ~80 tok/s</span>
</span><span id=__span-3-6><a id=__codelineno-3-6 name=__codelineno-3-6 href=#__codelineno-3-6></a>
</span><span id=__span-3-7><a id=__codelineno-3-7 name=__codelineno-3-7 href=#__codelineno-3-7></a><span class=c1># CPU only (very slow)</span>
</span><span id=__span-3-8><a id=__codelineno-3-8 name=__codelineno-3-8 href=#__codelineno-3-8></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=s2>&quot;model.gguf&quot;</span><span class=p>,</span> <span class=n>gpu_layers</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>   <span class=c1># ~8 tok/s</span>
</span></code></pre></div> <p><strong>Rule of thumb:</strong> Always use gpu_layers=99 unless you have VRAM constraints.</p> <h3 id=3-context-window-size>3. Context Window Size<a class=headerlink href=#3-context-window-size title="Permanent link">&para;</a></h3> <p>Balance between functionality and speed:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=c1># Small context (fastest)</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=s2>&quot;model.gguf&quot;</span><span class=p>,</span> <span class=n>ctx_size</span><span class=o>=</span><span class=mi>1024</span><span class=p>)</span>  <span class=c1># +10% speed</span>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a>
</span><span id=__span-4-4><a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a><span class=c1># Medium context (balanced)</span>
</span><span id=__span-4-5><a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=s2>&quot;model.gguf&quot;</span><span class=p>,</span> <span class=n>ctx_size</span><span class=o>=</span><span class=mi>2048</span><span class=p>)</span>  <span class=c1># Baseline</span>
</span><span id=__span-4-6><a id=__codelineno-4-6 name=__codelineno-4-6 href=#__codelineno-4-6></a>
</span><span id=__span-4-7><a id=__codelineno-4-7 name=__codelineno-4-7 href=#__codelineno-4-7></a><span class=c1># Large context (slower)</span>
</span><span id=__span-4-8><a id=__codelineno-4-8 name=__codelineno-4-8 href=#__codelineno-4-8></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=s2>&quot;model.gguf&quot;</span><span class=p>,</span> <span class=n>ctx_size</span><span class=o>=</span><span class=mi>8192</span><span class=p>)</span>  <span class=c1># -20% speed</span>
</span></code></pre></div> <p><strong>Memory impact:</strong> - 1024 ctx: +0.5 GB - 2048 ctx: +1.0 GB - 4096 ctx: +2.0 GB - 8192 ctx: +4.0 GB</p> <h3 id=4-batch-processing>4. Batch Processing<a class=headerlink href=#4-batch-processing title="Permanent link">&para;</a></h3> <p>Use batch sizes for throughput:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=c1># Configure batch parameters</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a>    <span class=s2>&quot;model.gguf&quot;</span><span class=p>,</span>
</span><span id=__span-5-4><a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a>    <span class=n>batch_size</span><span class=o>=</span><span class=mi>512</span><span class=p>,</span>    <span class=c1># Logical batch size</span>
</span><span id=__span-5-5><a id=__codelineno-5-5 name=__codelineno-5-5 href=#__codelineno-5-5></a>    <span class=n>ubatch_size</span><span class=o>=</span><span class=mi>128</span><span class=p>,</span>   <span class=c1># Physical batch size</span>
</span><span id=__span-5-6><a id=__codelineno-5-6 name=__codelineno-5-6 href=#__codelineno-5-6></a>    <span class=n>gpu_layers</span><span class=o>=</span><span class=mi>99</span>
</span><span id=__span-5-7><a id=__codelineno-5-7 name=__codelineno-5-7 href=#__codelineno-5-7></a><span class=p>)</span>
</span></code></pre></div> <p><strong>Batch size guidelines:</strong></p> <table> <thead> <tr> <th>Model Size</th> <th>batch_size</th> <th>ubatch_size</th> <th>Throughput</th> </tr> </thead> <tbody> <tr> <td>1B params</td> <td>512</td> <td>128</td> <td>134 tok/s</td> </tr> <tr> <td>3B params</td> <td>256</td> <td>64</td> <td>~100 tok/s</td> </tr> <tr> <td>7B params</td> <td>128</td> <td>32</td> <td>~50 tok/s</td> </tr> </tbody> </table> <h3 id=5-flash-attention>5. Flash Attention<a class=headerlink href=#5-flash-attention title="Permanent link">&para;</a></h3> <p>llcuda v2.0.6 includes FlashAttention by default:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=c1># FlashAttention is automatically enabled for:</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a><span class=c1># - Compute capability 7.5+ (T4, RTX 20xx+)</span>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a><span class=c1># - Context sizes &gt; 2048</span>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a><span class=c1># - All quantization types</span>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a>
</span><span id=__span-6-6><a id=__codelineno-6-6 name=__codelineno-6-6 href=#__codelineno-6-6></a><span class=c1># Benefit: 2-3x faster for long contexts</span>
</span></code></pre></div> <p><strong>Performance with FlashAttention:</strong></p> <table> <thead> <tr> <th>Context Size</th> <th>Without FA</th> <th>With FA</th> <th>Speedup</th> </tr> </thead> <tbody> <tr> <td>512</td> <td>140 tok/s</td> <td>142 tok/s</td> <td>1.01x</td> </tr> <tr> <td>2048</td> <td>134 tok/s</td> <td>135 tok/s</td> <td>1.01x</td> </tr> <tr> <td>4096</td> <td>95 tok/s</td> <td>125 tok/s</td> <td><strong>1.32x</strong></td> </tr> <tr> <td>8192</td> <td>55 tok/s</td> <td>105 tok/s</td> <td><strong>1.91x</strong></td> </tr> </tbody> </table> <h2 id=optimization-workflow>Optimization Workflow<a class=headerlink href=#optimization-workflow title="Permanent link">&para;</a></h2> <h3 id=step-1-baseline-measurement>Step 1: Baseline Measurement<a class=headerlink href=#step-1-baseline-measurement title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=kn>import</span><span class=w> </span><span class=nn>llcuda</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a><span class=n>engine</span> <span class=o>=</span> <span class=n>llcuda</span><span class=o>.</span><span class=n>InferenceEngine</span><span class=p>()</span>
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a>    <span class=s2>&quot;gemma-3-1b-Q4_K_M&quot;</span><span class=p>,</span>
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a>    <span class=n>auto_start</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span><span id=__span-7-7><a id=__codelineno-7-7 name=__codelineno-7-7 href=#__codelineno-7-7></a>    <span class=n>verbose</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-7-8><a id=__codelineno-7-8 name=__codelineno-7-8 href=#__codelineno-7-8></a><span class=p>)</span>
</span><span id=__span-7-9><a id=__codelineno-7-9 name=__codelineno-7-9 href=#__codelineno-7-9></a>
</span><span id=__span-7-10><a id=__codelineno-7-10 name=__codelineno-7-10 href=#__codelineno-7-10></a><span class=c1># Run baseline test</span>
</span><span id=__span-7-11><a id=__codelineno-7-11 name=__codelineno-7-11 href=#__codelineno-7-11></a><span class=n>prompts</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&quot;Test prompt&quot;</span><span class=p>]</span> <span class=o>*</span> <span class=mi>10</span>
</span><span id=__span-7-12><a id=__codelineno-7-12 name=__codelineno-7-12 href=#__codelineno-7-12></a><span class=n>results</span> <span class=o>=</span> <span class=n>engine</span><span class=o>.</span><span class=n>batch_infer</span><span class=p>(</span><span class=n>prompts</span><span class=p>,</span> <span class=n>max_tokens</span><span class=o>=</span><span class=mi>100</span><span class=p>)</span>
</span><span id=__span-7-13><a id=__codelineno-7-13 name=__codelineno-7-13 href=#__codelineno-7-13></a>
</span><span id=__span-7-14><a id=__codelineno-7-14 name=__codelineno-7-14 href=#__codelineno-7-14></a><span class=c1># Check metrics</span>
</span><span id=__span-7-15><a id=__codelineno-7-15 name=__codelineno-7-15 href=#__codelineno-7-15></a><span class=n>metrics</span> <span class=o>=</span> <span class=n>engine</span><span class=o>.</span><span class=n>get_metrics</span><span class=p>()</span>
</span><span id=__span-7-16><a id=__codelineno-7-16 name=__codelineno-7-16 href=#__codelineno-7-16></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Baseline speed: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;throughput&#39;</span><span class=p>][</span><span class=s1>&#39;tokens_per_sec&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2> tok/s&quot;</span><span class=p>)</span>
</span><span id=__span-7-17><a id=__codelineno-7-17 name=__codelineno-7-17 href=#__codelineno-7-17></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Baseline latency: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;latency&#39;</span><span class=p>][</span><span class=s1>&#39;mean_ms&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2> ms&quot;</span><span class=p>)</span>
</span></code></pre></div> <h3 id=step-2-optimize-gpu-offload>Step 2: Optimize GPU Offload<a class=headerlink href=#step-2-optimize-gpu-offload title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=c1># Test different GPU layer counts</span>
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a><span class=k>for</span> <span class=n>gpu_layers</span> <span class=ow>in</span> <span class=p>[</span><span class=mi>10</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>35</span><span class=p>,</span> <span class=mi>99</span><span class=p>]:</span>
</span><span id=__span-8-3><a id=__codelineno-8-3 name=__codelineno-8-3 href=#__codelineno-8-3></a>    <span class=n>engine</span><span class=o>.</span><span class=n>unload_model</span><span class=p>()</span>
</span><span id=__span-8-4><a id=__codelineno-8-4 name=__codelineno-8-4 href=#__codelineno-8-4></a>    <span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-8-5><a id=__codelineno-8-5 name=__codelineno-8-5 href=#__codelineno-8-5></a>        <span class=s2>&quot;model.gguf&quot;</span><span class=p>,</span>
</span><span id=__span-8-6><a id=__codelineno-8-6 name=__codelineno-8-6 href=#__codelineno-8-6></a>        <span class=n>gpu_layers</span><span class=o>=</span><span class=n>gpu_layers</span><span class=p>,</span>
</span><span id=__span-8-7><a id=__codelineno-8-7 name=__codelineno-8-7 href=#__codelineno-8-7></a>        <span class=n>auto_start</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span><span id=__span-8-8><a id=__codelineno-8-8 name=__codelineno-8-8 href=#__codelineno-8-8></a>        <span class=n>verbose</span><span class=o>=</span><span class=kc>False</span>
</span><span id=__span-8-9><a id=__codelineno-8-9 name=__codelineno-8-9 href=#__codelineno-8-9></a>    <span class=p>)</span>
</span><span id=__span-8-10><a id=__codelineno-8-10 name=__codelineno-8-10 href=#__codelineno-8-10></a>
</span><span id=__span-8-11><a id=__codelineno-8-11 name=__codelineno-8-11 href=#__codelineno-8-11></a>    <span class=n>result</span> <span class=o>=</span> <span class=n>engine</span><span class=o>.</span><span class=n>infer</span><span class=p>(</span><span class=s2>&quot;Test&quot;</span><span class=p>,</span> <span class=n>max_tokens</span><span class=o>=</span><span class=mi>50</span><span class=p>)</span>
</span><span id=__span-8-12><a id=__codelineno-8-12 name=__codelineno-8-12 href=#__codelineno-8-12></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;gpu_layers=</span><span class=si>{</span><span class=n>gpu_layers</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>tokens_per_sec</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2> tok/s&quot;</span><span class=p>)</span>
</span><span id=__span-8-13><a id=__codelineno-8-13 name=__codelineno-8-13 href=#__codelineno-8-13></a>
</span><span id=__span-8-14><a id=__codelineno-8-14 name=__codelineno-8-14 href=#__codelineno-8-14></a><span class=c1># Expected output:</span>
</span><span id=__span-8-15><a id=__codelineno-8-15 name=__codelineno-8-15 href=#__codelineno-8-15></a><span class=c1># gpu_layers=10: 65.2 tok/s</span>
</span><span id=__span-8-16><a id=__codelineno-8-16 name=__codelineno-8-16 href=#__codelineno-8-16></a><span class=c1># gpu_layers=20: 92.1 tok/s</span>
</span><span id=__span-8-17><a id=__codelineno-8-17 name=__codelineno-8-17 href=#__codelineno-8-17></a><span class=c1># gpu_layers=35: 127.5 tok/s</span>
</span><span id=__span-8-18><a id=__codelineno-8-18 name=__codelineno-8-18 href=#__codelineno-8-18></a><span class=c1># gpu_layers=99: 134.2 tok/s ‚Üê Best</span>
</span></code></pre></div> <h3 id=step-3-optimize-context-size>Step 3: Optimize Context Size<a class=headerlink href=#step-3-optimize-context-size title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=c1># Test different context sizes</span>
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a><span class=k>for</span> <span class=n>ctx_size</span> <span class=ow>in</span> <span class=p>[</span><span class=mi>512</span><span class=p>,</span> <span class=mi>1024</span><span class=p>,</span> <span class=mi>2048</span><span class=p>,</span> <span class=mi>4096</span><span class=p>]:</span>
</span><span id=__span-9-3><a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a>    <span class=n>engine</span><span class=o>.</span><span class=n>unload_model</span><span class=p>()</span>
</span><span id=__span-9-4><a id=__codelineno-9-4 name=__codelineno-9-4 href=#__codelineno-9-4></a>    <span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-9-5><a id=__codelineno-9-5 name=__codelineno-9-5 href=#__codelineno-9-5></a>        <span class=s2>&quot;model.gguf&quot;</span><span class=p>,</span>
</span><span id=__span-9-6><a id=__codelineno-9-6 name=__codelineno-9-6 href=#__codelineno-9-6></a>        <span class=n>ctx_size</span><span class=o>=</span><span class=n>ctx_size</span><span class=p>,</span>
</span><span id=__span-9-7><a id=__codelineno-9-7 name=__codelineno-9-7 href=#__codelineno-9-7></a>        <span class=n>gpu_layers</span><span class=o>=</span><span class=mi>99</span><span class=p>,</span>
</span><span id=__span-9-8><a id=__codelineno-9-8 name=__codelineno-9-8 href=#__codelineno-9-8></a>        <span class=n>auto_start</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span><span id=__span-9-9><a id=__codelineno-9-9 name=__codelineno-9-9 href=#__codelineno-9-9></a>        <span class=n>verbose</span><span class=o>=</span><span class=kc>False</span>
</span><span id=__span-9-10><a id=__codelineno-9-10 name=__codelineno-9-10 href=#__codelineno-9-10></a>    <span class=p>)</span>
</span><span id=__span-9-11><a id=__codelineno-9-11 name=__codelineno-9-11 href=#__codelineno-9-11></a>
</span><span id=__span-9-12><a id=__codelineno-9-12 name=__codelineno-9-12 href=#__codelineno-9-12></a>    <span class=n>result</span> <span class=o>=</span> <span class=n>engine</span><span class=o>.</span><span class=n>infer</span><span class=p>(</span><span class=s2>&quot;Test&quot;</span><span class=p>,</span> <span class=n>max_tokens</span><span class=o>=</span><span class=mi>50</span><span class=p>)</span>
</span><span id=__span-9-13><a id=__codelineno-9-13 name=__codelineno-9-13 href=#__codelineno-9-13></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;ctx_size=</span><span class=si>{</span><span class=n>ctx_size</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>tokens_per_sec</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2> tok/s&quot;</span><span class=p>)</span>
</span><span id=__span-9-14><a id=__codelineno-9-14 name=__codelineno-9-14 href=#__codelineno-9-14></a>
</span><span id=__span-9-15><a id=__codelineno-9-15 name=__codelineno-9-15 href=#__codelineno-9-15></a><span class=c1># Choose smallest ctx_size that meets your needs</span>
</span></code></pre></div> <h3 id=step-4-optimize-batch-parameters>Step 4: Optimize Batch Parameters<a class=headerlink href=#step-4-optimize-batch-parameters title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a><span class=c1># Test batch configurations</span>
</span><span id=__span-10-2><a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a><span class=n>configs</span> <span class=o>=</span> <span class=p>[</span>
</span><span id=__span-10-3><a id=__codelineno-10-3 name=__codelineno-10-3 href=#__codelineno-10-3></a>    <span class=p>(</span><span class=mi>256</span><span class=p>,</span> <span class=mi>64</span><span class=p>),</span>   <span class=c1># Small</span>
</span><span id=__span-10-4><a id=__codelineno-10-4 name=__codelineno-10-4 href=#__codelineno-10-4></a>    <span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=mi>128</span><span class=p>),</span>  <span class=c1># Medium (default)</span>
</span><span id=__span-10-5><a id=__codelineno-10-5 name=__codelineno-10-5 href=#__codelineno-10-5></a>    <span class=p>(</span><span class=mi>1024</span><span class=p>,</span> <span class=mi>256</span><span class=p>),</span> <span class=c1># Large</span>
</span><span id=__span-10-6><a id=__codelineno-10-6 name=__codelineno-10-6 href=#__codelineno-10-6></a><span class=p>]</span>
</span><span id=__span-10-7><a id=__codelineno-10-7 name=__codelineno-10-7 href=#__codelineno-10-7></a>
</span><span id=__span-10-8><a id=__codelineno-10-8 name=__codelineno-10-8 href=#__codelineno-10-8></a><span class=k>for</span> <span class=n>batch_size</span><span class=p>,</span> <span class=n>ubatch_size</span> <span class=ow>in</span> <span class=n>configs</span><span class=p>:</span>
</span><span id=__span-10-9><a id=__codelineno-10-9 name=__codelineno-10-9 href=#__codelineno-10-9></a>    <span class=n>engine</span><span class=o>.</span><span class=n>unload_model</span><span class=p>()</span>
</span><span id=__span-10-10><a id=__codelineno-10-10 name=__codelineno-10-10 href=#__codelineno-10-10></a>    <span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-10-11><a id=__codelineno-10-11 name=__codelineno-10-11 href=#__codelineno-10-11></a>        <span class=s2>&quot;model.gguf&quot;</span><span class=p>,</span>
</span><span id=__span-10-12><a id=__codelineno-10-12 name=__codelineno-10-12 href=#__codelineno-10-12></a>        <span class=n>batch_size</span><span class=o>=</span><span class=n>batch_size</span><span class=p>,</span>
</span><span id=__span-10-13><a id=__codelineno-10-13 name=__codelineno-10-13 href=#__codelineno-10-13></a>        <span class=n>ubatch_size</span><span class=o>=</span><span class=n>ubatch_size</span><span class=p>,</span>
</span><span id=__span-10-14><a id=__codelineno-10-14 name=__codelineno-10-14 href=#__codelineno-10-14></a>        <span class=n>gpu_layers</span><span class=o>=</span><span class=mi>99</span><span class=p>,</span>
</span><span id=__span-10-15><a id=__codelineno-10-15 name=__codelineno-10-15 href=#__codelineno-10-15></a>        <span class=n>auto_start</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span><span id=__span-10-16><a id=__codelineno-10-16 name=__codelineno-10-16 href=#__codelineno-10-16></a>        <span class=n>verbose</span><span class=o>=</span><span class=kc>False</span>
</span><span id=__span-10-17><a id=__codelineno-10-17 name=__codelineno-10-17 href=#__codelineno-10-17></a>    <span class=p>)</span>
</span><span id=__span-10-18><a id=__codelineno-10-18 name=__codelineno-10-18 href=#__codelineno-10-18></a>
</span><span id=__span-10-19><a id=__codelineno-10-19 name=__codelineno-10-19 href=#__codelineno-10-19></a>    <span class=n>result</span> <span class=o>=</span> <span class=n>engine</span><span class=o>.</span><span class=n>infer</span><span class=p>(</span><span class=s2>&quot;Test&quot;</span><span class=p>,</span> <span class=n>max_tokens</span><span class=o>=</span><span class=mi>50</span><span class=p>)</span>
</span><span id=__span-10-20><a id=__codelineno-10-20 name=__codelineno-10-20 href=#__codelineno-10-20></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;batch=</span><span class=si>{</span><span class=n>batch_size</span><span class=si>}</span><span class=s2>, ubatch=</span><span class=si>{</span><span class=n>ubatch_size</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>tokens_per_sec</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2> tok/s&quot;</span><span class=p>)</span>
</span></code></pre></div> <h2 id=advanced-optimizations>Advanced Optimizations<a class=headerlink href=#advanced-optimizations title="Permanent link">&para;</a></h2> <h3 id=parallel-sequences>Parallel Sequences<a class=headerlink href=#parallel-sequences title="Permanent link">&para;</a></h3> <p>Process multiple sequences in parallel:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-11-2><a id=__codelineno-11-2 name=__codelineno-11-2 href=#__codelineno-11-2></a>    <span class=s2>&quot;model.gguf&quot;</span><span class=p>,</span>
</span><span id=__span-11-3><a id=__codelineno-11-3 name=__codelineno-11-3 href=#__codelineno-11-3></a>    <span class=n>n_parallel</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span>  <span class=c1># Process 4 sequences simultaneously</span>
</span><span id=__span-11-4><a id=__codelineno-11-4 name=__codelineno-11-4 href=#__codelineno-11-4></a>    <span class=n>gpu_layers</span><span class=o>=</span><span class=mi>99</span><span class=p>,</span>
</span><span id=__span-11-5><a id=__codelineno-11-5 name=__codelineno-11-5 href=#__codelineno-11-5></a>    <span class=n>auto_start</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-11-6><a id=__codelineno-11-6 name=__codelineno-11-6 href=#__codelineno-11-6></a><span class=p>)</span>
</span><span id=__span-11-7><a id=__codelineno-11-7 name=__codelineno-11-7 href=#__codelineno-11-7></a>
</span><span id=__span-11-8><a id=__codelineno-11-8 name=__codelineno-11-8 href=#__codelineno-11-8></a><span class=c1># Submit multiple requests</span>
</span><span id=__span-11-9><a id=__codelineno-11-9 name=__codelineno-11-9 href=#__codelineno-11-9></a><span class=kn>import</span><span class=w> </span><span class=nn>concurrent.futures</span>
</span><span id=__span-11-10><a id=__codelineno-11-10 name=__codelineno-11-10 href=#__codelineno-11-10></a>
</span><span id=__span-11-11><a id=__codelineno-11-11 name=__codelineno-11-11 href=#__codelineno-11-11></a><span class=k>def</span><span class=w> </span><span class=nf>infer_async</span><span class=p>(</span><span class=n>prompt</span><span class=p>):</span>
</span><span id=__span-11-12><a id=__codelineno-11-12 name=__codelineno-11-12 href=#__codelineno-11-12></a>    <span class=k>return</span> <span class=n>engine</span><span class=o>.</span><span class=n>infer</span><span class=p>(</span><span class=n>prompt</span><span class=p>,</span> <span class=n>max_tokens</span><span class=o>=</span><span class=mi>50</span><span class=p>)</span>
</span><span id=__span-11-13><a id=__codelineno-11-13 name=__codelineno-11-13 href=#__codelineno-11-13></a>
</span><span id=__span-11-14><a id=__codelineno-11-14 name=__codelineno-11-14 href=#__codelineno-11-14></a><span class=n>prompts</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&quot;Prompt 1&quot;</span><span class=p>,</span> <span class=s2>&quot;Prompt 2&quot;</span><span class=p>,</span> <span class=s2>&quot;Prompt 3&quot;</span><span class=p>,</span> <span class=s2>&quot;Prompt 4&quot;</span><span class=p>]</span>
</span><span id=__span-11-15><a id=__codelineno-11-15 name=__codelineno-11-15 href=#__codelineno-11-15></a>
</span><span id=__span-11-16><a id=__codelineno-11-16 name=__codelineno-11-16 href=#__codelineno-11-16></a><span class=k>with</span> <span class=n>concurrent</span><span class=o>.</span><span class=n>futures</span><span class=o>.</span><span class=n>ThreadPoolExecutor</span><span class=p>(</span><span class=n>max_workers</span><span class=o>=</span><span class=mi>4</span><span class=p>)</span> <span class=k>as</span> <span class=n>executor</span><span class=p>:</span>
</span><span id=__span-11-17><a id=__codelineno-11-17 name=__codelineno-11-17 href=#__codelineno-11-17></a>    <span class=n>results</span> <span class=o>=</span> <span class=nb>list</span><span class=p>(</span><span class=n>executor</span><span class=o>.</span><span class=n>map</span><span class=p>(</span><span class=n>infer_async</span><span class=p>,</span> <span class=n>prompts</span><span class=p>))</span>
</span><span id=__span-11-18><a id=__codelineno-11-18 name=__codelineno-11-18 href=#__codelineno-11-18></a>
</span><span id=__span-11-19><a id=__codelineno-11-19 name=__codelineno-11-19 href=#__codelineno-11-19></a><span class=c1># Total throughput: ~500 tok/s with n_parallel=4</span>
</span></code></pre></div> <h3 id=continuous-batching>Continuous Batching<a class=headerlink href=#continuous-batching title="Permanent link">&para;</a></h3> <p>For serving applications:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-12-1><a id=__codelineno-12-1 name=__codelineno-12-1 href=#__codelineno-12-1></a><span class=c1># Enable continuous batching</span>
</span><span id=__span-12-2><a id=__codelineno-12-2 name=__codelineno-12-2 href=#__codelineno-12-2></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-12-3><a id=__codelineno-12-3 name=__codelineno-12-3 href=#__codelineno-12-3></a>    <span class=s2>&quot;model.gguf&quot;</span><span class=p>,</span>
</span><span id=__span-12-4><a id=__codelineno-12-4 name=__codelineno-12-4 href=#__codelineno-12-4></a>    <span class=n>n_parallel</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
</span><span id=__span-12-5><a id=__codelineno-12-5 name=__codelineno-12-5 href=#__codelineno-12-5></a>    <span class=n>batch_size</span><span class=o>=</span><span class=mi>512</span><span class=p>,</span>
</span><span id=__span-12-6><a id=__codelineno-12-6 name=__codelineno-12-6 href=#__codelineno-12-6></a>    <span class=n>ubatch_size</span><span class=o>=</span><span class=mi>128</span><span class=p>,</span>
</span><span id=__span-12-7><a id=__codelineno-12-7 name=__codelineno-12-7 href=#__codelineno-12-7></a>    <span class=n>gpu_layers</span><span class=o>=</span><span class=mi>99</span><span class=p>,</span>
</span><span id=__span-12-8><a id=__codelineno-12-8 name=__codelineno-12-8 href=#__codelineno-12-8></a>    <span class=n>auto_start</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-12-9><a id=__codelineno-12-9 name=__codelineno-12-9 href=#__codelineno-12-9></a><span class=p>)</span>
</span><span id=__span-12-10><a id=__codelineno-12-10 name=__codelineno-12-10 href=#__codelineno-12-10></a>
</span><span id=__span-12-11><a id=__codelineno-12-11 name=__codelineno-12-11 href=#__codelineno-12-11></a><span class=c1># Handles variable-length sequences efficiently</span>
</span><span id=__span-12-12><a id=__codelineno-12-12 name=__codelineno-12-12 href=#__codelineno-12-12></a><span class=c1># Throughput increases with concurrent requests</span>
</span></code></pre></div> <h3 id=temperature-tuning>Temperature Tuning<a class=headerlink href=#temperature-tuning title="Permanent link">&para;</a></h3> <p>Balance quality and speed:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-13-1><a id=__codelineno-13-1 name=__codelineno-13-1 href=#__codelineno-13-1></a><span class=c1># Faster (less sampling)</span>
</span><span id=__span-13-2><a id=__codelineno-13-2 name=__codelineno-13-2 href=#__codelineno-13-2></a><span class=n>result</span> <span class=o>=</span> <span class=n>engine</span><span class=o>.</span><span class=n>infer</span><span class=p>(</span>
</span><span id=__span-13-3><a id=__codelineno-13-3 name=__codelineno-13-3 href=#__codelineno-13-3></a>    <span class=s2>&quot;Prompt&quot;</span><span class=p>,</span>
</span><span id=__span-13-4><a id=__codelineno-13-4 name=__codelineno-13-4 href=#__codelineno-13-4></a>    <span class=n>temperature</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span>  <span class=c1># Greedy-like</span>
</span><span id=__span-13-5><a id=__codelineno-13-5 name=__codelineno-13-5 href=#__codelineno-13-5></a>    <span class=n>top_k</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span>         <span class=c1># Limit sampling</span>
</span><span id=__span-13-6><a id=__codelineno-13-6 name=__codelineno-13-6 href=#__codelineno-13-6></a>    <span class=n>max_tokens</span><span class=o>=</span><span class=mi>100</span>
</span><span id=__span-13-7><a id=__codelineno-13-7 name=__codelineno-13-7 href=#__codelineno-13-7></a><span class=p>)</span>
</span><span id=__span-13-8><a id=__codelineno-13-8 name=__codelineno-13-8 href=#__codelineno-13-8></a><span class=c1># Speed: ~140 tok/s</span>
</span><span id=__span-13-9><a id=__codelineno-13-9 name=__codelineno-13-9 href=#__codelineno-13-9></a>
</span><span id=__span-13-10><a id=__codelineno-13-10 name=__codelineno-13-10 href=#__codelineno-13-10></a><span class=c1># Balanced</span>
</span><span id=__span-13-11><a id=__codelineno-13-11 name=__codelineno-13-11 href=#__codelineno-13-11></a><span class=n>result</span> <span class=o>=</span> <span class=n>engine</span><span class=o>.</span><span class=n>infer</span><span class=p>(</span>
</span><span id=__span-13-12><a id=__codelineno-13-12 name=__codelineno-13-12 href=#__codelineno-13-12></a>    <span class=s2>&quot;Prompt&quot;</span><span class=p>,</span>
</span><span id=__span-13-13><a id=__codelineno-13-13 name=__codelineno-13-13 href=#__codelineno-13-13></a>    <span class=n>temperature</span><span class=o>=</span><span class=mf>0.7</span><span class=p>,</span>  <span class=c1># Default</span>
</span><span id=__span-13-14><a id=__codelineno-13-14 name=__codelineno-13-14 href=#__codelineno-13-14></a>    <span class=n>top_k</span><span class=o>=</span><span class=mi>40</span><span class=p>,</span>
</span><span id=__span-13-15><a id=__codelineno-13-15 name=__codelineno-13-15 href=#__codelineno-13-15></a>    <span class=n>max_tokens</span><span class=o>=</span><span class=mi>100</span>
</span><span id=__span-13-16><a id=__codelineno-13-16 name=__codelineno-13-16 href=#__codelineno-13-16></a><span class=p>)</span>
</span><span id=__span-13-17><a id=__codelineno-13-17 name=__codelineno-13-17 href=#__codelineno-13-17></a><span class=c1># Speed: ~134 tok/s</span>
</span><span id=__span-13-18><a id=__codelineno-13-18 name=__codelineno-13-18 href=#__codelineno-13-18></a>
</span><span id=__span-13-19><a id=__codelineno-13-19 name=__codelineno-13-19 href=#__codelineno-13-19></a><span class=c1># Creative (more sampling)</span>
</span><span id=__span-13-20><a id=__codelineno-13-20 name=__codelineno-13-20 href=#__codelineno-13-20></a><span class=n>result</span> <span class=o>=</span> <span class=n>engine</span><span class=o>.</span><span class=n>infer</span><span class=p>(</span>
</span><span id=__span-13-21><a id=__codelineno-13-21 name=__codelineno-13-21 href=#__codelineno-13-21></a>    <span class=s2>&quot;Prompt&quot;</span><span class=p>,</span>
</span><span id=__span-13-22><a id=__codelineno-13-22 name=__codelineno-13-22 href=#__codelineno-13-22></a>    <span class=n>temperature</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span>
</span><span id=__span-13-23><a id=__codelineno-13-23 name=__codelineno-13-23 href=#__codelineno-13-23></a>    <span class=n>top_k</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span>
</span><span id=__span-13-24><a id=__codelineno-13-24 name=__codelineno-13-24 href=#__codelineno-13-24></a>    <span class=n>max_tokens</span><span class=o>=</span><span class=mi>100</span>
</span><span id=__span-13-25><a id=__codelineno-13-25 name=__codelineno-13-25 href=#__codelineno-13-25></a><span class=p>)</span>
</span><span id=__span-13-26><a id=__codelineno-13-26 name=__codelineno-13-26 href=#__codelineno-13-26></a><span class=c1># Speed: ~125 tok/s</span>
</span></code></pre></div> <h2 id=memory-optimization>Memory Optimization<a class=headerlink href=#memory-optimization title="Permanent link">&para;</a></h2> <h3 id=model-caching>Model Caching<a class=headerlink href=#model-caching title="Permanent link">&para;</a></h3> <p>Cache models to avoid reloading:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-14-1><a id=__codelineno-14-1 name=__codelineno-14-1 href=#__codelineno-14-1></a><span class=c1># Keep model in memory between sessions</span>
</span><span id=__span-14-2><a id=__codelineno-14-2 name=__codelineno-14-2 href=#__codelineno-14-2></a><span class=n>engine</span> <span class=o>=</span> <span class=n>llcuda</span><span class=o>.</span><span class=n>InferenceEngine</span><span class=p>()</span>
</span><span id=__span-14-3><a id=__codelineno-14-3 name=__codelineno-14-3 href=#__codelineno-14-3></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=s2>&quot;model.gguf&quot;</span><span class=p>,</span> <span class=n>auto_start</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-14-4><a id=__codelineno-14-4 name=__codelineno-14-4 href=#__codelineno-14-4></a>
</span><span id=__span-14-5><a id=__codelineno-14-5 name=__codelineno-14-5 href=#__codelineno-14-5></a><span class=c1># Reuse engine for multiple inferences</span>
</span><span id=__span-14-6><a id=__codelineno-14-6 name=__codelineno-14-6 href=#__codelineno-14-6></a><span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1000</span><span class=p>):</span>
</span><span id=__span-14-7><a id=__codelineno-14-7 name=__codelineno-14-7 href=#__codelineno-14-7></a>    <span class=n>result</span> <span class=o>=</span> <span class=n>engine</span><span class=o>.</span><span class=n>infer</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Prompt </span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>,</span> <span class=n>max_tokens</span><span class=o>=</span><span class=mi>50</span><span class=p>)</span>
</span><span id=__span-14-8><a id=__codelineno-14-8 name=__codelineno-14-8 href=#__codelineno-14-8></a>
</span><span id=__span-14-9><a id=__codelineno-14-9 name=__codelineno-14-9 href=#__codelineno-14-9></a><span class=c1># Don&#39;t unload until done</span>
</span><span id=__span-14-10><a id=__codelineno-14-10 name=__codelineno-14-10 href=#__codelineno-14-10></a><span class=n>engine</span><span class=o>.</span><span class=n>unload_model</span><span class=p>()</span>
</span></code></pre></div> <h3 id=kv-cache-management>KV Cache Management<a class=headerlink href=#kv-cache-management title="Permanent link">&para;</a></h3> <p>Control key-value cache:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-15-1><a id=__codelineno-15-1 name=__codelineno-15-1 href=#__codelineno-15-1></a><span class=c1># Allocate more VRAM for KV cache</span>
</span><span id=__span-15-2><a id=__codelineno-15-2 name=__codelineno-15-2 href=#__codelineno-15-2></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-15-3><a id=__codelineno-15-3 name=__codelineno-15-3 href=#__codelineno-15-3></a>    <span class=s2>&quot;model.gguf&quot;</span><span class=p>,</span>
</span><span id=__span-15-4><a id=__codelineno-15-4 name=__codelineno-15-4 href=#__codelineno-15-4></a>    <span class=n>ctx_size</span><span class=o>=</span><span class=mi>4096</span><span class=p>,</span>       <span class=c1># Context window</span>
</span><span id=__span-15-5><a id=__codelineno-15-5 name=__codelineno-15-5 href=#__codelineno-15-5></a>    <span class=n>cache_size</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span>     <span class=c1># Auto-calculate</span>
</span><span id=__span-15-6><a id=__codelineno-15-6 name=__codelineno-15-6 href=#__codelineno-15-6></a>    <span class=n>gpu_layers</span><span class=o>=</span><span class=mi>99</span>
</span><span id=__span-15-7><a id=__codelineno-15-7 name=__codelineno-15-7 href=#__codelineno-15-7></a><span class=p>)</span>
</span><span id=__span-15-8><a id=__codelineno-15-8 name=__codelineno-15-8 href=#__codelineno-15-8></a>
</span><span id=__span-15-9><a id=__codelineno-15-9 name=__codelineno-15-9 href=#__codelineno-15-9></a><span class=c1># Manual cache control (advanced)</span>
</span><span id=__span-15-10><a id=__codelineno-15-10 name=__codelineno-15-10 href=#__codelineno-15-10></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-15-11><a id=__codelineno-15-11 name=__codelineno-15-11 href=#__codelineno-15-11></a>    <span class=s2>&quot;model.gguf&quot;</span><span class=p>,</span>
</span><span id=__span-15-12><a id=__codelineno-15-12 name=__codelineno-15-12 href=#__codelineno-15-12></a>    <span class=n>ctx_size</span><span class=o>=</span><span class=mi>4096</span><span class=p>,</span>
</span><span id=__span-15-13><a id=__codelineno-15-13 name=__codelineno-15-13 href=#__codelineno-15-13></a>    <span class=n>cache_size</span><span class=o>=</span><span class=mi>8192</span><span class=p>,</span>     <span class=c1># 2x context for better caching</span>
</span><span id=__span-15-14><a id=__codelineno-15-14 name=__codelineno-15-14 href=#__codelineno-15-14></a>    <span class=n>gpu_layers</span><span class=o>=</span><span class=mi>99</span>
</span><span id=__span-15-15><a id=__codelineno-15-15 name=__codelineno-15-15 href=#__codelineno-15-15></a><span class=p>)</span>
</span></code></pre></div> <h2 id=profiling-and-monitoring>Profiling and Monitoring<a class=headerlink href=#profiling-and-monitoring title="Permanent link">&para;</a></h2> <h3 id=built-in-metrics>Built-in Metrics<a class=headerlink href=#built-in-metrics title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-16-1><a id=__codelineno-16-1 name=__codelineno-16-1 href=#__codelineno-16-1></a><span class=c1># Get detailed metrics</span>
</span><span id=__span-16-2><a id=__codelineno-16-2 name=__codelineno-16-2 href=#__codelineno-16-2></a><span class=n>metrics</span> <span class=o>=</span> <span class=n>engine</span><span class=o>.</span><span class=n>get_metrics</span><span class=p>()</span>
</span><span id=__span-16-3><a id=__codelineno-16-3 name=__codelineno-16-3 href=#__codelineno-16-3></a>
</span><span id=__span-16-4><a id=__codelineno-16-4 name=__codelineno-16-4 href=#__codelineno-16-4></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Latency Stats:&quot;</span><span class=p>)</span>
</span><span id=__span-16-5><a id=__codelineno-16-5 name=__codelineno-16-5 href=#__codelineno-16-5></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Mean: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;latency&#39;</span><span class=p>][</span><span class=s1>&#39;mean_ms&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2> ms&quot;</span><span class=p>)</span>
</span><span id=__span-16-6><a id=__codelineno-16-6 name=__codelineno-16-6 href=#__codelineno-16-6></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  P50:  </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;latency&#39;</span><span class=p>][</span><span class=s1>&#39;p50_ms&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2> ms&quot;</span><span class=p>)</span>
</span><span id=__span-16-7><a id=__codelineno-16-7 name=__codelineno-16-7 href=#__codelineno-16-7></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  P95:  </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;latency&#39;</span><span class=p>][</span><span class=s1>&#39;p95_ms&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2> ms&quot;</span><span class=p>)</span>
</span><span id=__span-16-8><a id=__codelineno-16-8 name=__codelineno-16-8 href=#__codelineno-16-8></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  P99:  </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;latency&#39;</span><span class=p>][</span><span class=s1>&#39;p99_ms&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2> ms&quot;</span><span class=p>)</span>
</span><span id=__span-16-9><a id=__codelineno-16-9 name=__codelineno-16-9 href=#__codelineno-16-9></a>
</span><span id=__span-16-10><a id=__codelineno-16-10 name=__codelineno-16-10 href=#__codelineno-16-10></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>Throughput Stats:&quot;</span><span class=p>)</span>
</span><span id=__span-16-11><a id=__codelineno-16-11 name=__codelineno-16-11 href=#__codelineno-16-11></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Tokens/sec: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;throughput&#39;</span><span class=p>][</span><span class=s1>&#39;tokens_per_sec&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-16-12><a id=__codelineno-16-12 name=__codelineno-16-12 href=#__codelineno-16-12></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Requests/sec: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;throughput&#39;</span><span class=p>][</span><span class=s1>&#39;requests_per_sec&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-16-13><a id=__codelineno-16-13 name=__codelineno-16-13 href=#__codelineno-16-13></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Total tokens: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;throughput&#39;</span><span class=p>][</span><span class=s1>&#39;total_tokens&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <h3 id=gpu-monitoring>GPU Monitoring<a class=headerlink href=#gpu-monitoring title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-17-1><a id=__codelineno-17-1 name=__codelineno-17-1 href=#__codelineno-17-1></a><span class=kn>import</span><span class=w> </span><span class=nn>subprocess</span>
</span><span id=__span-17-2><a id=__codelineno-17-2 name=__codelineno-17-2 href=#__codelineno-17-2></a>
</span><span id=__span-17-3><a id=__codelineno-17-3 name=__codelineno-17-3 href=#__codelineno-17-3></a><span class=k>def</span><span class=w> </span><span class=nf>monitor_gpu</span><span class=p>():</span>
</span><span id=__span-17-4><a id=__codelineno-17-4 name=__codelineno-17-4 href=#__codelineno-17-4></a>    <span class=n>result</span> <span class=o>=</span> <span class=n>subprocess</span><span class=o>.</span><span class=n>run</span><span class=p>(</span>
</span><span id=__span-17-5><a id=__codelineno-17-5 name=__codelineno-17-5 href=#__codelineno-17-5></a>        <span class=p>[</span><span class=s2>&quot;nvidia-smi&quot;</span><span class=p>,</span> <span class=s2>&quot;--query-gpu=utilization.gpu,memory.used&quot;</span><span class=p>,</span> <span class=s2>&quot;--format=csv,noheader&quot;</span><span class=p>],</span>
</span><span id=__span-17-6><a id=__codelineno-17-6 name=__codelineno-17-6 href=#__codelineno-17-6></a>        <span class=n>capture_output</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span><span id=__span-17-7><a id=__codelineno-17-7 name=__codelineno-17-7 href=#__codelineno-17-7></a>        <span class=n>text</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-17-8><a id=__codelineno-17-8 name=__codelineno-17-8 href=#__codelineno-17-8></a>    <span class=p>)</span>
</span><span id=__span-17-9><a id=__codelineno-17-9 name=__codelineno-17-9 href=#__codelineno-17-9></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;GPU: </span><span class=si>{</span><span class=n>result</span><span class=o>.</span><span class=n>stdout</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-17-10><a id=__codelineno-17-10 name=__codelineno-17-10 href=#__codelineno-17-10></a>
</span><span id=__span-17-11><a id=__codelineno-17-11 name=__codelineno-17-11 href=#__codelineno-17-11></a><span class=c1># Monitor during inference</span>
</span><span id=__span-17-12><a id=__codelineno-17-12 name=__codelineno-17-12 href=#__codelineno-17-12></a><span class=n>monitor_gpu</span><span class=p>()</span>
</span><span id=__span-17-13><a id=__codelineno-17-13 name=__codelineno-17-13 href=#__codelineno-17-13></a><span class=n>result</span> <span class=o>=</span> <span class=n>engine</span><span class=o>.</span><span class=n>infer</span><span class=p>(</span><span class=s2>&quot;Long prompt...&quot;</span><span class=p>,</span> <span class=n>max_tokens</span><span class=o>=</span><span class=mi>200</span><span class=p>)</span>
</span><span id=__span-17-14><a id=__codelineno-17-14 name=__codelineno-17-14 href=#__codelineno-17-14></a><span class=n>monitor_gpu</span><span class=p>()</span>
</span></code></pre></div> <h2 id=performance-checklist>Performance Checklist<a class=headerlink href=#performance-checklist title="Permanent link">&para;</a></h2> <p>Use this checklist to ensure optimal performance:</p> <ul class=task-list> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled checked><span class=task-list-indicator></span></label> <strong>Quantization:</strong> Using Q4_K_M or Q5_K_M</li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled checked><span class=task-list-indicator></span></label> <strong>GPU Offload:</strong> gpu_layers=99 (full offload)</li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled checked><span class=task-list-indicator></span></label> <strong>Context Size:</strong> Smallest that meets requirements</li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled checked><span class=task-list-indicator></span></label> <strong>Batch Size:</strong> 512/128 for 1B models</li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled checked><span class=task-list-indicator></span></label> <strong>FlashAttention:</strong> Enabled (automatic on T4)</li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled checked><span class=task-list-indicator></span></label> <strong>CUDA Version:</strong> 12.0+</li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled checked><span class=task-list-indicator></span></label> <strong>Driver:</strong> Latest NVIDIA driver</li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled checked><span class=task-list-indicator></span></label> <strong>Model Choice:</strong> Appropriate size for T4 (1B-3B)</li> </ul> <h2 id=common-performance-issues>Common Performance Issues<a class=headerlink href=#common-performance-issues title="Permanent link">&para;</a></h2> <h3 id=issue-slow-inference-50-toks>Issue: Slow Inference (&lt;50 tok/s)<a class=headerlink href=#issue-slow-inference-50-toks title="Permanent link">&para;</a></h3> <p><strong>Diagnosis:</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-18-1><a id=__codelineno-18-1 name=__codelineno-18-1 href=#__codelineno-18-1></a><span class=n>metrics</span> <span class=o>=</span> <span class=n>engine</span><span class=o>.</span><span class=n>get_metrics</span><span class=p>()</span>
</span><span id=__span-18-2><a id=__codelineno-18-2 name=__codelineno-18-2 href=#__codelineno-18-2></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Speed: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;throughput&#39;</span><span class=p>][</span><span class=s1>&#39;tokens_per_sec&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2> tok/s&quot;</span><span class=p>)</span>
</span><span id=__span-18-3><a id=__codelineno-18-3 name=__codelineno-18-3 href=#__codelineno-18-3></a>
</span><span id=__span-18-4><a id=__codelineno-18-4 name=__codelineno-18-4 href=#__codelineno-18-4></a><span class=c1># Check GPU usage</span>
</span><span id=__span-18-5><a id=__codelineno-18-5 name=__codelineno-18-5 href=#__codelineno-18-5></a><span class=err>!</span><span class=n>nvidia</span><span class=o>-</span><span class=n>smi</span>
</span></code></pre></div></p> <p><strong>Solutions:</strong> 1. Increase GPU layers: <code>gpu_layers=99</code> 2. Use Q4_K_M quantization 3. Reduce context size: <code>ctx_size=2048</code> 4. Check GPU utilization (should be &gt;80%)</p> <h3 id=issue-high-latency-2000ms>Issue: High Latency (&gt;2000ms)<a class=headerlink href=#issue-high-latency-2000ms title="Permanent link">&para;</a></h3> <p><strong>Diagnosis:</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-19-1><a id=__codelineno-19-1 name=__codelineno-19-1 href=#__codelineno-19-1></a><span class=n>metrics</span> <span class=o>=</span> <span class=n>engine</span><span class=o>.</span><span class=n>get_metrics</span><span class=p>()</span>
</span><span id=__span-19-2><a id=__codelineno-19-2 name=__codelineno-19-2 href=#__codelineno-19-2></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;P95 latency: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;latency&#39;</span><span class=p>][</span><span class=s1>&#39;p95_ms&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2> ms&quot;</span><span class=p>)</span>
</span></code></pre></div></p> <p><strong>Solutions:</strong> 1. Reduce max_tokens 2. Use smaller context size 3. Check for CPU bottleneck 4. Verify T4 GPU (not CPU-only)</p> <h3 id=issue-out-of-memory>Issue: Out of Memory<a class=headerlink href=#issue-out-of-memory title="Permanent link">&para;</a></h3> <p><strong>Diagnosis:</strong> <div class="language-bash highlight"><pre><span></span><code><span id=__span-20-1><a id=__codelineno-20-1 name=__codelineno-20-1 href=#__codelineno-20-1></a>nvidia-smi<span class=w>  </span><span class=c1># Check memory usage</span>
</span></code></pre></div></p> <p><strong>Solutions:</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-21-1><a id=__codelineno-21-1 name=__codelineno-21-1 href=#__codelineno-21-1></a><span class=c1># Reduce GPU layers</span>
</span><span id=__span-21-2><a id=__codelineno-21-2 name=__codelineno-21-2 href=#__codelineno-21-2></a><span class=n>gpu_layers</span> <span class=o>=</span> <span class=mi>20</span>  <span class=c1># Instead of 99</span>
</span><span id=__span-21-3><a id=__codelineno-21-3 name=__codelineno-21-3 href=#__codelineno-21-3></a>
</span><span id=__span-21-4><a id=__codelineno-21-4 name=__codelineno-21-4 href=#__codelineno-21-4></a><span class=c1># Reduce context</span>
</span><span id=__span-21-5><a id=__codelineno-21-5 name=__codelineno-21-5 href=#__codelineno-21-5></a><span class=n>ctx_size</span> <span class=o>=</span> <span class=mi>1024</span>  <span class=c1># Instead of 4096</span>
</span><span id=__span-21-6><a id=__codelineno-21-6 name=__codelineno-21-6 href=#__codelineno-21-6></a>
</span><span id=__span-21-7><a id=__codelineno-21-7 name=__codelineno-21-7 href=#__codelineno-21-7></a><span class=c1># Reduce batch size</span>
</span><span id=__span-21-8><a id=__codelineno-21-8 name=__codelineno-21-8 href=#__codelineno-21-8></a><span class=n>batch_size</span> <span class=o>=</span> <span class=mi>256</span>  <span class=c1># Instead of 512</span>
</span></code></pre></div></p> <h2 id=best-configurations>Best Configurations<a class=headerlink href=#best-configurations title="Permanent link">&para;</a></h2> <h3 id=configuration-1-maximum-speed>Configuration 1: Maximum Speed<a class=headerlink href=#configuration-1-maximum-speed title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-22-1><a id=__codelineno-22-1 name=__codelineno-22-1 href=#__codelineno-22-1></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-22-2><a id=__codelineno-22-2 name=__codelineno-22-2 href=#__codelineno-22-2></a>    <span class=s2>&quot;gemma-3-1b-Q4_K_M.gguf&quot;</span><span class=p>,</span>
</span><span id=__span-22-3><a id=__codelineno-22-3 name=__codelineno-22-3 href=#__codelineno-22-3></a>    <span class=n>gpu_layers</span><span class=o>=</span><span class=mi>99</span><span class=p>,</span>
</span><span id=__span-22-4><a id=__codelineno-22-4 name=__codelineno-22-4 href=#__codelineno-22-4></a>    <span class=n>ctx_size</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span>
</span><span id=__span-22-5><a id=__codelineno-22-5 name=__codelineno-22-5 href=#__codelineno-22-5></a>    <span class=n>batch_size</span><span class=o>=</span><span class=mi>512</span><span class=p>,</span>
</span><span id=__span-22-6><a id=__codelineno-22-6 name=__codelineno-22-6 href=#__codelineno-22-6></a>    <span class=n>ubatch_size</span><span class=o>=</span><span class=mi>128</span><span class=p>,</span>
</span><span id=__span-22-7><a id=__codelineno-22-7 name=__codelineno-22-7 href=#__codelineno-22-7></a>    <span class=n>n_parallel</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
</span><span id=__span-22-8><a id=__codelineno-22-8 name=__codelineno-22-8 href=#__codelineno-22-8></a>    <span class=n>auto_start</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-22-9><a id=__codelineno-22-9 name=__codelineno-22-9 href=#__codelineno-22-9></a><span class=p>)</span>
</span><span id=__span-22-10><a id=__codelineno-22-10 name=__codelineno-22-10 href=#__codelineno-22-10></a>
</span><span id=__span-22-11><a id=__codelineno-22-11 name=__codelineno-22-11 href=#__codelineno-22-11></a><span class=c1># Expected: 140+ tok/s</span>
</span></code></pre></div> <h3 id=configuration-2-balanced>Configuration 2: Balanced<a class=headerlink href=#configuration-2-balanced title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-23-1><a id=__codelineno-23-1 name=__codelineno-23-1 href=#__codelineno-23-1></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-23-2><a id=__codelineno-23-2 name=__codelineno-23-2 href=#__codelineno-23-2></a>    <span class=s2>&quot;gemma-3-1b-Q4_K_M.gguf&quot;</span><span class=p>,</span>
</span><span id=__span-23-3><a id=__codelineno-23-3 name=__codelineno-23-3 href=#__codelineno-23-3></a>    <span class=n>gpu_layers</span><span class=o>=</span><span class=mi>99</span><span class=p>,</span>
</span><span id=__span-23-4><a id=__codelineno-23-4 name=__codelineno-23-4 href=#__codelineno-23-4></a>    <span class=n>ctx_size</span><span class=o>=</span><span class=mi>2048</span><span class=p>,</span>
</span><span id=__span-23-5><a id=__codelineno-23-5 name=__codelineno-23-5 href=#__codelineno-23-5></a>    <span class=n>batch_size</span><span class=o>=</span><span class=mi>512</span><span class=p>,</span>
</span><span id=__span-23-6><a id=__codelineno-23-6 name=__codelineno-23-6 href=#__codelineno-23-6></a>    <span class=n>ubatch_size</span><span class=o>=</span><span class=mi>128</span><span class=p>,</span>
</span><span id=__span-23-7><a id=__codelineno-23-7 name=__codelineno-23-7 href=#__codelineno-23-7></a>    <span class=n>n_parallel</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
</span><span id=__span-23-8><a id=__codelineno-23-8 name=__codelineno-23-8 href=#__codelineno-23-8></a>    <span class=n>auto_start</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-23-9><a id=__codelineno-23-9 name=__codelineno-23-9 href=#__codelineno-23-9></a><span class=p>)</span>
</span><span id=__span-23-10><a id=__codelineno-23-10 name=__codelineno-23-10 href=#__codelineno-23-10></a>
</span><span id=__span-23-11><a id=__codelineno-23-11 name=__codelineno-23-11 href=#__codelineno-23-11></a><span class=c1># Expected: 134 tok/s (default)</span>
</span></code></pre></div> <h3 id=configuration-3-long-context>Configuration 3: Long Context<a class=headerlink href=#configuration-3-long-context title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-24-1><a id=__codelineno-24-1 name=__codelineno-24-1 href=#__codelineno-24-1></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-24-2><a id=__codelineno-24-2 name=__codelineno-24-2 href=#__codelineno-24-2></a>    <span class=s2>&quot;gemma-3-1b-Q4_K_M.gguf&quot;</span><span class=p>,</span>
</span><span id=__span-24-3><a id=__codelineno-24-3 name=__codelineno-24-3 href=#__codelineno-24-3></a>    <span class=n>gpu_layers</span><span class=o>=</span><span class=mi>99</span><span class=p>,</span>
</span><span id=__span-24-4><a id=__codelineno-24-4 name=__codelineno-24-4 href=#__codelineno-24-4></a>    <span class=n>ctx_size</span><span class=o>=</span><span class=mi>8192</span><span class=p>,</span>
</span><span id=__span-24-5><a id=__codelineno-24-5 name=__codelineno-24-5 href=#__codelineno-24-5></a>    <span class=n>batch_size</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span>
</span><span id=__span-24-6><a id=__codelineno-24-6 name=__codelineno-24-6 href=#__codelineno-24-6></a>    <span class=n>ubatch_size</span><span class=o>=</span><span class=mi>64</span><span class=p>,</span>
</span><span id=__span-24-7><a id=__codelineno-24-7 name=__codelineno-24-7 href=#__codelineno-24-7></a>    <span class=n>n_parallel</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
</span><span id=__span-24-8><a id=__codelineno-24-8 name=__codelineno-24-8 href=#__codelineno-24-8></a>    <span class=n>auto_start</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-24-9><a id=__codelineno-24-9 name=__codelineno-24-9 href=#__codelineno-24-9></a><span class=p>)</span>
</span><span id=__span-24-10><a id=__codelineno-24-10 name=__codelineno-24-10 href=#__codelineno-24-10></a>
</span><span id=__span-24-11><a id=__codelineno-24-11 name=__codelineno-24-11 href=#__codelineno-24-11></a><span class=c1># Expected: 105 tok/s with FlashAttention</span>
</span></code></pre></div> <h3 id=configuration-4-multi-request>Configuration 4: Multi-Request<a class=headerlink href=#configuration-4-multi-request title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-25-1><a id=__codelineno-25-1 name=__codelineno-25-1 href=#__codelineno-25-1></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-25-2><a id=__codelineno-25-2 name=__codelineno-25-2 href=#__codelineno-25-2></a>    <span class=s2>&quot;gemma-3-1b-Q4_K_M.gguf&quot;</span><span class=p>,</span>
</span><span id=__span-25-3><a id=__codelineno-25-3 name=__codelineno-25-3 href=#__codelineno-25-3></a>    <span class=n>gpu_layers</span><span class=o>=</span><span class=mi>99</span><span class=p>,</span>
</span><span id=__span-25-4><a id=__codelineno-25-4 name=__codelineno-25-4 href=#__codelineno-25-4></a>    <span class=n>ctx_size</span><span class=o>=</span><span class=mi>2048</span><span class=p>,</span>
</span><span id=__span-25-5><a id=__codelineno-25-5 name=__codelineno-25-5 href=#__codelineno-25-5></a>    <span class=n>batch_size</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span>
</span><span id=__span-25-6><a id=__codelineno-25-6 name=__codelineno-25-6 href=#__codelineno-25-6></a>    <span class=n>ubatch_size</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span>
</span><span id=__span-25-7><a id=__codelineno-25-7 name=__codelineno-25-7 href=#__codelineno-25-7></a>    <span class=n>n_parallel</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
</span><span id=__span-25-8><a id=__codelineno-25-8 name=__codelineno-25-8 href=#__codelineno-25-8></a>    <span class=n>auto_start</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-25-9><a id=__codelineno-25-9 name=__codelineno-25-9 href=#__codelineno-25-9></a><span class=p>)</span>
</span><span id=__span-25-10><a id=__codelineno-25-10 name=__codelineno-25-10 href=#__codelineno-25-10></a>
</span><span id=__span-25-11><a id=__codelineno-25-11 name=__codelineno-25-11 href=#__codelineno-25-11></a><span class=c1># Expected: 400+ tok/s total throughput</span>
</span></code></pre></div> <h2 id=next-steps>Next Steps<a class=headerlink href=#next-steps title="Permanent link">&para;</a></h2> <ul> <li><a href=../../performance/benchmarks/ >Benchmarks</a> - Compare model performance</li> <li><a href=../../performance/t4-results/ >T4 Results</a> - Detailed T4 benchmarks</li> <li><a href=../../performance/optimization/ >Optimization Guide</a> - Advanced tuning</li> <li><a href=../../guides/troubleshooting/ >Troubleshooting</a> - Fix issues</li> </ul> <div class="admonition success"> <p class=admonition-title>Performance Achieved</p> <p>Following these optimizations, you should achieve 130+ tok/s on Gemma 3-1B with Tesla T4, matching our verified benchmarks.</p> </div> <form class=md-feedback name=feedback hidden> <fieldset> <legend class=md-feedback__title> Was this page helpful? </legend> <div class=md-feedback__inner> <div class=md-feedback__list> <button class="md-feedback__icon md-icon" type=submit title="This page was helpful" data-md-value=1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m7 0c0 .8-.7 1.5-1.5 1.5S14 10.3 14 9.5 14.7 8 15.5 8s1.5.7 1.5 1.5m-5 7.73c-1.75 0-3.29-.73-4.19-1.81L9.23 14c.45.72 1.52 1.23 2.77 1.23s2.32-.51 2.77-1.23l1.42 1.42c-.9 1.08-2.44 1.81-4.19 1.81"/></svg> </button> <button class="md-feedback__icon md-icon" type=submit title="This page could be improved" data-md-value=0> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10m-6.5-4c.8 0 1.5.7 1.5 1.5s-.7 1.5-1.5 1.5-1.5-.7-1.5-1.5.7-1.5 1.5-1.5M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m2 4.5c1.75 0 3.29.72 4.19 1.81l-1.42 1.42C14.32 16.5 13.25 16 12 16s-2.32.5-2.77 1.23l-1.42-1.42C8.71 14.72 10.25 14 12 14"/></svg> </button> </div> <div class=md-feedback__note> <div data-md-value=1 hidden> Thanks for your feedback! </div> <div data-md-value=0 hidden> Thanks for your feedback! Help us improve by <a href=https://github.com/waqasm86/llcuda/issues/new target=_blank rel=noopener>opening an issue</a>. </div> </div> </div> </fieldset> </form> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../unsloth-integration/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Unsloth Integration"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Unsloth Integration </div> </div> </a> <a href=../../api/overview/ class="md-footer__link md-footer__link--next" aria-label="Next: Overview"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Overview </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2024-2026 Waqas Muhammad </div> </div> <div class=md-social> <a href=https://github.com/waqasm86 target=_blank rel=noopener title="GitHub - waqasm86" class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=mailto:waqasm86@gmail.com target=_blank rel=noopener title="Email - waqasm86@gmail.com" class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M48 64C21.5 64 0 85.5 0 112c0 15.1 7.1 29.3 19.2 38.4l208 156a48 48 0 0 0 57.6 0l208-156c12.1-9.1 19.2-23.3 19.2-38.4 0-26.5-21.5-48-48-48zM0 196v188c0 35.3 28.7 64 64 64h384c35.3 0 64-28.7 64-64V196L313.6 344.8c-34.1 25.6-81.1 25.6-115.2 0z"/></svg> </a> <a href=https://www.linkedin.com/in/waqasm86 target=_blank rel=noopener title="LinkedIn - Waqas Muhammad" class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <div class=md-consent data-md-component=consent id=__consent hidden> <div class=md-consent__overlay></div> <aside class=md-consent__inner> <form class="md-consent__form md-grid md-typeset" name=consent> <h4>Cookie consent</h4> <p>We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they're searching for. With your consent, you're helping us to make our documentation better.</p> <input class=md-toggle type=checkbox id=__settings> <div class=md-consent__settings> <ul class=task-list> <li class=task-list-item> <label class=task-list-control> <input type=checkbox name=analytics checked> <span class=task-list-indicator></span> Google Analytics </label> </li> <li class=task-list-item> <label class=task-list-control> <input type=checkbox name=github checked> <span class=task-list-indicator></span> GitHub </label> </li> </ul> </div> <div class=md-consent__controls> <button class="md-button md-button--primary">Accept</button> <label class=md-button for=__settings>Manage settings</label> </div> </form> </aside> </div> <script>var consent=__md_get("__consent");if(consent)for(var input of document.forms.consent.elements)input.name&&(input.checked=consent[input.name]||!1);else"file:"!==location.protocol&&setTimeout((function(){document.querySelector("[data-md-component=consent]").hidden=!1}),250);var form=document.forms.consent;for(var action of["submit","reset"])form.addEventListener(action,(function(e){if(e.preventDefault(),"reset"===e.type)for(var n of document.forms.consent.elements)n.name&&(n.checked=!1);__md_set("__consent",Object.fromEntries(Array.from(new FormData(form).keys()).map((function(e){return[e,!0]})))),location.hash="",location.reload()}))</script> <script id=__config type=application/json>{"annotate": null, "base": "../..", "features": ["announce.dismiss", "content.code.annotate", "content.code.copy", "content.tabs.link", "content.tooltips", "header.autohide", "navigation.expand", "navigation.footer", "navigation.indexes", "navigation.instant", "navigation.instant.prefetch", "navigation.instant.progress", "navigation.path", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow", "toc.integrate"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": "latest", "provider": "mike"}}</script> <script src=../../assets/javascripts/bundle.79ae519e.min.js></script> <script src=../../javascripts/mathjax.js></script> <script src=../../javascripts/schema.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>