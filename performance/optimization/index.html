<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Fast LLM inference on Tesla T4 GPUs with CUDA 12, FlashAttention, and Unsloth integration. Verified 134 tokens/sec on Gemma 3-1B. GitHub-only distribution with auto-downloading binaries. Perfect for Google Colab and production deployment."><meta name=author content="Waqas Muhammad"><link href=https://llcuda.github.io/performance/optimization/ rel=canonical><link href=../t4-results/ rel=prev><link href=../../guides/model-selection/ rel=next><link rel=icon href=../../assets/images/logo.svg><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.7.1"><title>Optimization Guide - llcuda v2.0.6 - Tesla T4 CUDA Inference</title><link rel=stylesheet href=../../assets/stylesheets/main.484c7ddc.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.ab4e12ef.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../stylesheets/extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-XXXXXXXXXX"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-XXXXXXXXXX",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>if("undefined"!=typeof __md_analytics){var consent=__md_get("__consent");consent&&consent.analytics&&__md_analytics()}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=deep-purple> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#performance-optimization class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <div data-md-color-scheme=default data-md-component=outdated hidden> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="llcuda v2.0.6 - Tesla T4 CUDA Inference" class="md-header__button md-logo" aria-label="llcuda v2.0.6 - Tesla T4 CUDA Inference" data-md-component=logo> <img src=../../assets/images/logo.svg alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> llcuda v2.0.6 - Tesla T4 CUDA Inference </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Optimization Guide </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=deep-purple aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=deep-purple aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/waqasm86/llcuda title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> waqasm86/llcuda </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../guides/quickstart/ class=md-tabs__link> Getting Started </a> </li> <li class=md-tabs__item> <a href=../../tutorials/gemma-3-1b-colab/ class=md-tabs__link> Tutorials </a> </li> <li class=md-tabs__item> <a href=../../api/overview/ class=md-tabs__link> API Reference </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../benchmarks/ class=md-tabs__link> Performance </a> </li> <li class=md-tabs__item> <a href=../../guides/model-selection/ class=md-tabs__link> Guides </a> </li> <li class=md-tabs__item> <a href=../../notebooks/ class=md-tabs__link> Notebooks </a> </li> <li class=md-tabs__item> <a href=https://github.com/waqasm86/llcuda class=md-tabs__link> Links </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="llcuda v2.0.6 - Tesla T4 CUDA Inference" class="md-nav__button md-logo" aria-label="llcuda v2.0.6 - Tesla T4 CUDA Inference" data-md-component=logo> <img src=../../assets/images/logo.svg alt=logo> </a> llcuda v2.0.6 - Tesla T4 CUDA Inference </label> <div class=md-nav__source> <a href=https://github.com/waqasm86/llcuda title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> waqasm86/llcuda </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Getting Started </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Getting Started </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../guides/quickstart/ class=md-nav__link> <span class=md-ellipsis> Quick Start </span> </a> </li> <li class=md-nav__item> <a href=../../guides/installation/ class=md-nav__link> <span class=md-ellipsis> Installation </span> </a> </li> <li class=md-nav__item> <a href=../../guides/first-steps/ class=md-nav__link> <span class=md-ellipsis> First Steps </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> Tutorials </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Tutorials </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3_1> <label class=md-nav__link for=__nav_3_1 id=__nav_3_1_label tabindex=0> <span class=md-ellipsis> Google Colab </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_1_label aria-expanded=false> <label class=md-nav__title for=__nav_3_1> <span class="md-nav__icon md-icon"></span> Google Colab </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../tutorials/gemma-3-1b-colab/ class=md-nav__link> <span class=md-ellipsis> Gemma 3-1B Tutorial </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/gemma-3-1b-executed/ class=md-nav__link> <span class=md-ellipsis> Executed Example </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/build-binaries/ class=md-nav__link> <span class=md-ellipsis> Build Binaries </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../tutorials/unsloth-integration/ class=md-nav__link> <span class=md-ellipsis> Unsloth Integration </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/performance/ class=md-nav__link> <span class=md-ellipsis> Performance Optimization </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_4> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex=0> <span class=md-ellipsis> API Reference </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=false> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> API Reference </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../api/overview/ class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class=md-nav__item> <a href=../../api/inference-engine/ class=md-nav__link> <span class=md-ellipsis> InferenceEngine </span> </a> </li> <li class=md-nav__item> <a href=../../api/models/ class=md-nav__link> <span class=md-ellipsis> Models & GGUF </span> </a> </li> <li class=md-nav__item> <a href=../../api/device/ class=md-nav__link> <span class=md-ellipsis> GPU & Device </span> </a> </li> <li class=md-nav__item> <a href=../../api/examples/ class=md-nav__link> <span class=md-ellipsis> Examples </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_5 checked> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex> <span class=md-ellipsis> Performance </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=true> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Performance </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../benchmarks/ class=md-nav__link> <span class=md-ellipsis> Benchmarks </span> </a> </li> <li class=md-nav__item> <a href=../t4-results/ class=md-nav__link> <span class=md-ellipsis> Tesla T4 Results </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Optimization Guide </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> Optimization Guide </span> </a> <nav class="md-nav md-nav--secondary" aria-label="On this page"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> On this page </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#overview class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class=md-nav__item> <a href=#quantization-selection class=md-nav__link> <span class=md-ellipsis> Quantization Selection </span> </a> <nav class=md-nav aria-label="Quantization Selection"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#understanding-quantization class=md-nav__link> <span class=md-ellipsis> Understanding Quantization </span> </a> </li> <li class=md-nav__item> <a href=#choosing-the-right-quantization class=md-nav__link> <span class=md-ellipsis> Choosing the Right Quantization </span> </a> </li> <li class=md-nav__item> <a href=#quantization-performance-comparison class=md-nav__link> <span class=md-ellipsis> Quantization Performance Comparison </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#context-length-optimization class=md-nav__link> <span class=md-ellipsis> Context Length Optimization </span> </a> <nav class=md-nav aria-label="Context Length Optimization"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#impact-of-context-size class=md-nav__link> <span class=md-ellipsis> Impact of Context Size </span> </a> </li> <li class=md-nav__item> <a href=#optimal-context-sizes class=md-nav__link> <span class=md-ellipsis> Optimal Context Sizes </span> </a> </li> <li class=md-nav__item> <a href=#memory-vs-context-trade-off class=md-nav__link> <span class=md-ellipsis> Memory vs Context Trade-off </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#batch-size-tuning class=md-nav__link> <span class=md-ellipsis> Batch Size Tuning </span> </a> <nav class=md-nav aria-label="Batch Size Tuning"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#understanding-batch-parameters class=md-nav__link> <span class=md-ellipsis> Understanding Batch Parameters </span> </a> </li> <li class=md-nav__item> <a href=#optimal-settings-for-tesla-t4 class=md-nav__link> <span class=md-ellipsis> Optimal Settings for Tesla T4 </span> </a> </li> <li class=md-nav__item> <a href=#batch-size-recommendations class=md-nav__link> <span class=md-ellipsis> Batch Size Recommendations </span> </a> </li> <li class=md-nav__item> <a href=#impact-analysis class=md-nav__link> <span class=md-ellipsis> Impact Analysis </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#gpu-layer-offload class=md-nav__link> <span class=md-ellipsis> GPU Layer Offload </span> </a> <nav class=md-nav aria-label="GPU Layer Offload"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#full-vs-partial-offload class=md-nav__link> <span class=md-ellipsis> Full vs Partial Offload </span> </a> </li> <li class=md-nav__item> <a href=#partial-offload-limited-vram class=md-nav__link> <span class=md-ellipsis> Partial Offload (Limited VRAM) </span> </a> </li> <li class=md-nav__item> <a href=#layer-offload-performance class=md-nav__link> <span class=md-ellipsis> Layer Offload Performance </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#server-configuration class=md-nav__link> <span class=md-ellipsis> Server Configuration </span> </a> <nav class=md-nav aria-label="Server Configuration"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#optimal-server-settings class=md-nav__link> <span class=md-ellipsis> Optimal Server Settings </span> </a> </li> <li class=md-nav__item> <a href=#parallel-request-handling class=md-nav__link> <span class=md-ellipsis> Parallel Request Handling </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#flashattention-optimization class=md-nav__link> <span class=md-ellipsis> FlashAttention Optimization </span> </a> <nav class=md-nav aria-label="FlashAttention Optimization"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#when-to-use-flashattention class=md-nav__link> <span class=md-ellipsis> When to Use FlashAttention </span> </a> </li> <li class=md-nav__item> <a href=#flashattention-benefits class=md-nav__link> <span class=md-ellipsis> FlashAttention Benefits </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#memory-optimization class=md-nav__link> <span class=md-ellipsis> Memory Optimization </span> </a> <nav class=md-nav aria-label="Memory Optimization"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#reduce-vram-usage class=md-nav__link> <span class=md-ellipsis> Reduce VRAM Usage </span> </a> </li> <li class=md-nav__item> <a href=#memory-constrained-configuration class=md-nav__link> <span class=md-ellipsis> Memory-Constrained Configuration </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#auto-configuration class=md-nav__link> <span class=md-ellipsis> Auto-Configuration </span> </a> <nav class=md-nav aria-label=Auto-Configuration> <ul class=md-nav__list> <li class=md-nav__item> <a href=#let-llcuda-optimize class=md-nav__link> <span class=md-ellipsis> Let llcuda Optimize </span> </a> </li> <li class=md-nav__item> <a href=#manual-override class=md-nav__link> <span class=md-ellipsis> Manual Override </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#model-selection-for-performance class=md-nav__link> <span class=md-ellipsis> Model Selection for Performance </span> </a> <nav class=md-nav aria-label="Model Selection for Performance"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#size-vs-speed-trade-off class=md-nav__link> <span class=md-ellipsis> Size vs Speed Trade-off </span> </a> </li> <li class=md-nav__item> <a href=#popular-high-performance-models class=md-nav__link> <span class=md-ellipsis> Popular High-Performance Models </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#generation-parameter-tuning class=md-nav__link> <span class=md-ellipsis> Generation Parameter Tuning </span> </a> <nav class=md-nav aria-label="Generation Parameter Tuning"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#speed-vs-quality class=md-nav__link> <span class=md-ellipsis> Speed vs Quality </span> </a> </li> <li class=md-nav__item> <a href=#parameter-impact class=md-nav__link> <span class=md-ellipsis> Parameter Impact </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#multi-gpu-configuration class=md-nav__link> <span class=md-ellipsis> Multi-GPU Configuration </span> </a> <nav class=md-nav aria-label="Multi-GPU Configuration"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#select-specific-gpu class=md-nav__link> <span class=md-ellipsis> Select Specific GPU </span> </a> </li> <li class=md-nav__item> <a href=#load-balance-across-gpus class=md-nav__link> <span class=md-ellipsis> Load Balance Across GPUs </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#benchmarking-your-setup class=md-nav__link> <span class=md-ellipsis> Benchmarking Your Setup </span> </a> <nav class=md-nav aria-label="Benchmarking Your Setup"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#quick-benchmark class=md-nav__link> <span class=md-ellipsis> Quick Benchmark </span> </a> </li> <li class=md-nav__item> <a href=#compare-configurations class=md-nav__link> <span class=md-ellipsis> Compare Configurations </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#optimization-checklist class=md-nav__link> <span class=md-ellipsis> Optimization Checklist </span> </a> <nav class=md-nav aria-label="Optimization Checklist"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#pre-deployment-checklist class=md-nav__link> <span class=md-ellipsis> Pre-Deployment Checklist </span> </a> </li> <li class=md-nav__item> <a href=#production-settings class=md-nav__link> <span class=md-ellipsis> Production Settings </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#common-optimization-pitfalls class=md-nav__link> <span class=md-ellipsis> Common Optimization Pitfalls </span> </a> <nav class=md-nav aria-label="Common Optimization Pitfalls"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#dont-do-this class=md-nav__link> <span class=md-ellipsis> ❌ Don't Do This </span> </a> </li> <li class=md-nav__item> <a href=#do-this-instead class=md-nav__link> <span class=md-ellipsis> ✅ Do This Instead </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#see-also class=md-nav__link> <span class=md-ellipsis> See Also </span> </a> </li> </ul> </nav> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_6> <label class=md-nav__link for=__nav_6 id=__nav_6_label tabindex=0> <span class=md-ellipsis> Guides </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> Guides </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../guides/model-selection/ class=md-nav__link> <span class=md-ellipsis> Model Selection </span> </a> </li> <li class=md-nav__item> <a href=../../guides/gguf-format/ class=md-nav__link> <span class=md-ellipsis> GGUF Format </span> </a> </li> <li class=md-nav__item> <a href=../../guides/troubleshooting/ class=md-nav__link> <span class=md-ellipsis> Troubleshooting </span> </a> </li> <li class=md-nav__item> <a href=../../guides/faq/ class=md-nav__link> <span class=md-ellipsis> FAQ </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_7> <div class="md-nav__link md-nav__container"> <a href=../../notebooks/ class="md-nav__link "> <span class=md-ellipsis> Notebooks </span> </a> <label class="md-nav__link " for=__nav_7 id=__nav_7_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_7_label aria-expanded=false> <label class=md-nav__title for=__nav_7> <span class="md-nav__icon md-icon"></span> Notebooks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../notebooks/colab/ class=md-nav__link> <span class=md-ellipsis> Colab Notebooks </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_8> <label class=md-nav__link for=__nav_8 id=__nav_8_label tabindex=0> <span class=md-ellipsis> Links </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_8_label aria-expanded=false> <label class=md-nav__title for=__nav_8> <span class="md-nav__icon md-icon"></span> Links </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=https://github.com/waqasm86/llcuda class=md-nav__link> <span class=md-ellipsis> GitHub Repository </span> </a> </li> <li class=md-nav__item> <a href=https://github.com/waqasm86/llcuda/releases class=md-nav__link> <span class=md-ellipsis> GitHub Releases </span> </a> </li> <li class=md-nav__item> <a href=https://github.com/waqasm86/llcuda/issues class=md-nav__link> <span class=md-ellipsis> Issues & Support </span> </a> </li> <li class=md-nav__item> <a href=https://github.com/waqasm86/llcuda/blob/main/CHANGELOG.md class=md-nav__link> <span class=md-ellipsis> Changelog </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <nav class=md-path aria-label=Navigation> <ol class=md-path__list> <li class=md-path__item> <a href=../.. class=md-path__link> <span class=md-ellipsis> Home </span> </a> </li> <li class=md-path__item> <a href=../benchmarks/ class=md-path__link> <span class=md-ellipsis> Performance </span> </a> </li> </ol> </nav> <article class="md-content__inner md-typeset"> <h1 id=performance-optimization>Performance Optimization<a class=headerlink href=#performance-optimization title="Permanent link">&para;</a></h1> <p>Advanced techniques to maximize inference performance with llcuda v2.0.6.</p> <h2 id=overview>Overview<a class=headerlink href=#overview title="Permanent link">&para;</a></h2> <p>This guide covers optimization strategies for:</p> <ul> <li>Quantization selection</li> <li>Context length tuning</li> <li>Batch size optimization</li> <li>Server configuration</li> <li>Memory optimization</li> <li>Multi-GPU setups</li> </ul> <hr> <h2 id=quantization-selection>Quantization Selection<a class=headerlink href=#quantization-selection title="Permanent link">&para;</a></h2> <h3 id=understanding-quantization>Understanding Quantization<a class=headerlink href=#understanding-quantization title="Permanent link">&para;</a></h3> <p>Quantization reduces model precision to improve speed and reduce VRAM usage.</p> <table> <thead> <tr> <th>Quantization</th> <th>Bits/Weight</th> <th>Speed</th> <th>Quality</th> <th>VRAM</th> <th>Recommendation</th> </tr> </thead> <tbody> <tr> <td><strong>Q2_K</strong></td> <td>2.5</td> <td>Fastest</td> <td>Poor</td> <td>Lowest</td> <td>Prototyping only</td> </tr> <tr> <td><strong>Q3_K_M</strong></td> <td>3.5</td> <td>Very fast</td> <td>Fair</td> <td>Low</td> <td>Low VRAM only</td> </tr> <tr> <td><strong>Q4_0</strong></td> <td>4.0</td> <td>Fast</td> <td>Good</td> <td>Medium</td> <td>Speed priority</td> </tr> <tr> <td><strong>Q4_K_M</strong></td> <td>4.5</td> <td>Fast</td> <td>Excellent</td> <td>Medium</td> <td>✅ <strong>Best balance</strong></td> </tr> <tr> <td><strong>Q5_K_M</strong></td> <td>5.5</td> <td>Moderate</td> <td>Near-perfect</td> <td>High</td> <td>Quality priority</td> </tr> <tr> <td><strong>Q6_K</strong></td> <td>6.5</td> <td>Slow</td> <td>Minimal loss</td> <td>Higher</td> <td>Rarely needed</td> </tr> <tr> <td><strong>Q8_0</strong></td> <td>8.0</td> <td>Slower</td> <td>Negligible loss</td> <td>Highest</td> <td>Development only</td> </tr> <tr> <td><strong>F16</strong></td> <td>16.0</td> <td>Slowest</td> <td>Perfect</td> <td>Maximum</td> <td>Not recommended</td> </tr> </tbody> </table> <h3 id=choosing-the-right-quantization>Choosing the Right Quantization<a class=headerlink href=#choosing-the-right-quantization title="Permanent link">&para;</a></h3> <p><strong>For Tesla T4 (15 GB VRAM):</strong></p> <div class="language-python highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=kn>import</span><span class=w> </span><span class=nn>llcuda</span>
</span><span id=__span-0-2><a id=__codelineno-0-2 name=__codelineno-0-2 href=#__codelineno-0-2></a>
</span><span id=__span-0-3><a id=__codelineno-0-3 name=__codelineno-0-3 href=#__codelineno-0-3></a><span class=c1># Q4_K_M: Best overall choice</span>
</span><span id=__span-0-4><a id=__codelineno-0-4 name=__codelineno-0-4 href=#__codelineno-0-4></a><span class=c1># - 134 tok/s</span>
</span><span id=__span-0-5><a id=__codelineno-0-5 name=__codelineno-0-5 href=#__codelineno-0-5></a><span class=c1># - 1.2 GB VRAM</span>
</span><span id=__span-0-6><a id=__codelineno-0-6 name=__codelineno-0-6 href=#__codelineno-0-6></a><span class=c1># - 99% quality</span>
</span><span id=__span-0-7><a id=__codelineno-0-7 name=__codelineno-0-7 href=#__codelineno-0-7></a><span class=n>engine</span> <span class=o>=</span> <span class=n>llcuda</span><span class=o>.</span><span class=n>InferenceEngine</span><span class=p>()</span>
</span><span id=__span-0-8><a id=__codelineno-0-8 name=__codelineno-0-8 href=#__codelineno-0-8></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-0-9><a id=__codelineno-0-9 name=__codelineno-0-9 href=#__codelineno-0-9></a>    <span class=s2>&quot;unsloth/gemma-3-1b-it-GGUF:gemma-3-1b-it-Q4_K_M.gguf&quot;</span><span class=p>,</span>
</span><span id=__span-0-10><a id=__codelineno-0-10 name=__codelineno-0-10 href=#__codelineno-0-10></a>    <span class=n>silent</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-0-11><a id=__codelineno-0-11 name=__codelineno-0-11 href=#__codelineno-0-11></a><span class=p>)</span>
</span></code></pre></div> <p><strong>For limited VRAM (&lt; 8 GB):</strong></p> <div class="language-python highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=c1># Q4_0: Faster, less VRAM</span>
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-1-3><a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a>    <span class=s2>&quot;unsloth/gemma-3-1b-it-GGUF:gemma-3-1b-it-Q4_0.gguf&quot;</span><span class=p>,</span>
</span><span id=__span-1-4><a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a>    <span class=n>silent</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-1-5><a id=__codelineno-1-5 name=__codelineno-1-5 href=#__codelineno-1-5></a><span class=p>)</span>
</span></code></pre></div> <p><strong>For quality-critical applications:</strong></p> <div class="language-python highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=c1># Q5_K_M: Better quality, slower</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-2-3><a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a>    <span class=s2>&quot;unsloth/gemma-3-1b-it-GGUF:gemma-3-1b-it-Q5_K_M.gguf&quot;</span><span class=p>,</span>
</span><span id=__span-2-4><a id=__codelineno-2-4 name=__codelineno-2-4 href=#__codelineno-2-4></a>    <span class=n>silent</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-2-5><a id=__codelineno-2-5 name=__codelineno-2-5 href=#__codelineno-2-5></a><span class=p>)</span>
</span></code></pre></div> <h3 id=quantization-performance-comparison>Quantization Performance Comparison<a class=headerlink href=#quantization-performance-comparison title="Permanent link">&para;</a></h3> <p>On Tesla T4, Gemma 3-1B:</p> <table> <thead> <tr> <th>Quantization</th> <th>Tokens/sec</th> <th>Speedup</th> <th>Quality</th> <th>Best For</th> </tr> </thead> <tbody> <tr> <td>Q4_K_M</td> <td>134.3</td> <td>1.00x</td> <td>99%</td> <td>General use ✅</td> </tr> <tr> <td>Q4_0</td> <td>138.7</td> <td>1.03x</td> <td>97%</td> <td>Speed-critical</td> </tr> <tr> <td>Q5_K_M</td> <td>110.2</td> <td>0.82x</td> <td>99.5%</td> <td>High quality</td> </tr> <tr> <td>Q3_K_M</td> <td>142.3</td> <td>1.06x</td> <td>92%</td> <td>Low VRAM</td> </tr> </tbody> </table> <hr> <h2 id=context-length-optimization>Context Length Optimization<a class=headerlink href=#context-length-optimization title="Permanent link">&para;</a></h2> <h3 id=impact-of-context-size>Impact of Context Size<a class=headerlink href=#impact-of-context-size title="Permanent link">&para;</a></h3> <table> <thead> <tr> <th>Context Size</th> <th>Use Case</th> <th>Tokens/sec</th> <th>VRAM</th> <th>Latency/100tok</th> </tr> </thead> <tbody> <tr> <td>512</td> <td>Quick Q&amp;A</td> <td>142.5</td> <td>0.9 GB</td> <td>702 ms</td> </tr> <tr> <td>1024</td> <td>Short chat</td> <td>138.7</td> <td>1.0 GB</td> <td>721 ms</td> </tr> <tr> <td><strong>2048</strong></td> <td><strong>Standard</strong></td> <td><strong>134.3</strong></td> <td><strong>1.2 GB</strong></td> <td><strong>745 ms</strong></td> </tr> <tr> <td>4096</td> <td>Long chat</td> <td>125.1</td> <td>2.0 GB</td> <td>799 ms</td> </tr> <tr> <td>8192</td> <td>Documents</td> <td>105.3</td> <td>3.5 GB</td> <td>950 ms</td> </tr> </tbody> </table> <p><strong>Rule of thumb:</strong> Use the smallest context size that fits your use case.</p> <h3 id=optimal-context-sizes>Optimal Context Sizes<a class=headerlink href=#optimal-context-sizes title="Permanent link">&para;</a></h3> <p><strong>For interactive chat:</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a>    <span class=n>model_path</span><span class=p>,</span>
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a>    <span class=n>ctx_size</span><span class=o>=</span><span class=mi>2048</span><span class=p>,</span>  <span class=c1># Optimal for most conversations</span>
</span><span id=__span-3-4><a id=__codelineno-3-4 name=__codelineno-3-4 href=#__codelineno-3-4></a>    <span class=n>silent</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-3-5><a id=__codelineno-3-5 name=__codelineno-3-5 href=#__codelineno-3-5></a><span class=p>)</span>
</span></code></pre></div></p> <p><strong>For document Q&amp;A:</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-4-2><a id=__codelineno-4-2 name=__codelineno-4-2 href=#__codelineno-4-2></a>    <span class=n>model_path</span><span class=p>,</span>
</span><span id=__span-4-3><a id=__codelineno-4-3 name=__codelineno-4-3 href=#__codelineno-4-3></a>    <span class=n>ctx_size</span><span class=o>=</span><span class=mi>4096</span><span class=p>,</span>  <span class=c1># Long context support</span>
</span><span id=__span-4-4><a id=__codelineno-4-4 name=__codelineno-4-4 href=#__codelineno-4-4></a>    <span class=n>silent</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-4-5><a id=__codelineno-4-5 name=__codelineno-4-5 href=#__codelineno-4-5></a><span class=p>)</span>
</span></code></pre></div></p> <p><strong>For quick responses:</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a>    <span class=n>model_path</span><span class=p>,</span>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a>    <span class=n>ctx_size</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span>  <span class=c1># Faster, lower VRAM</span>
</span><span id=__span-5-4><a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a>    <span class=n>silent</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-5-5><a id=__codelineno-5-5 name=__codelineno-5-5 href=#__codelineno-5-5></a><span class=p>)</span>
</span></code></pre></div></p> <h3 id=memory-vs-context-trade-off>Memory vs Context Trade-off<a class=headerlink href=#memory-vs-context-trade-off title="Permanent link">&para;</a></h3> <p>VRAM usage grows quadratically with context (KV cache):</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=c1># Calculate VRAM for context</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a><span class=k>def</span><span class=w> </span><span class=nf>estimate_vram_gb</span><span class=p>(</span><span class=n>model_size_gb</span><span class=p>,</span> <span class=n>ctx_size</span><span class=p>):</span>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a>    <span class=n>base_vram</span> <span class=o>=</span> <span class=n>model_size_gb</span>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a>    <span class=n>kv_cache_gb</span> <span class=o>=</span> <span class=p>(</span><span class=n>ctx_size</span> <span class=o>/</span> <span class=mi>2048</span><span class=p>)</span> <span class=o>**</span> <span class=mf>1.2</span> <span class=o>*</span> <span class=mf>0.3</span>  <span class=c1># Approximate</span>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a>    <span class=k>return</span> <span class=n>base_vram</span> <span class=o>+</span> <span class=n>kv_cache_gb</span>
</span><span id=__span-6-6><a id=__codelineno-6-6 name=__codelineno-6-6 href=#__codelineno-6-6></a>
</span><span id=__span-6-7><a id=__codelineno-6-7 name=__codelineno-6-7 href=#__codelineno-6-7></a><span class=c1># Example: Gemma 3-1B Q4_K_M</span>
</span><span id=__span-6-8><a id=__codelineno-6-8 name=__codelineno-6-8 href=#__codelineno-6-8></a><span class=nb>print</span><span class=p>(</span><span class=n>estimate_vram_gb</span><span class=p>(</span><span class=mf>1.2</span><span class=p>,</span> <span class=mi>2048</span><span class=p>))</span>  <span class=c1># ~1.5 GB</span>
</span><span id=__span-6-9><a id=__codelineno-6-9 name=__codelineno-6-9 href=#__codelineno-6-9></a><span class=nb>print</span><span class=p>(</span><span class=n>estimate_vram_gb</span><span class=p>(</span><span class=mf>1.2</span><span class=p>,</span> <span class=mi>8192</span><span class=p>))</span>  <span class=c1># ~3.2 GB</span>
</span></code></pre></div> <hr> <h2 id=batch-size-tuning>Batch Size Tuning<a class=headerlink href=#batch-size-tuning title="Permanent link">&para;</a></h2> <h3 id=understanding-batch-parameters>Understanding Batch Parameters<a class=headerlink href=#understanding-batch-parameters title="Permanent link">&para;</a></h3> <ul> <li><code>batch_size</code>: Maximum tokens processed in parallel (prompt processing)</li> <li><code>ubatch_size</code>: Micro-batch size for generation (critical for low VRAM)</li> </ul> <h3 id=optimal-settings-for-tesla-t4>Optimal Settings for Tesla T4<a class=headerlink href=#optimal-settings-for-tesla-t4 title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a>    <span class=n>model_path</span><span class=p>,</span>
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a>    <span class=n>batch_size</span><span class=o>=</span><span class=mi>512</span><span class=p>,</span>     <span class=c1># Optimal for T4</span>
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a>    <span class=n>ubatch_size</span><span class=o>=</span><span class=mi>128</span><span class=p>,</span>    <span class=c1># Good balance</span>
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a>    <span class=n>silent</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a><span class=p>)</span>
</span></code></pre></div> <h3 id=batch-size-recommendations>Batch Size Recommendations<a class=headerlink href=#batch-size-recommendations title="Permanent link">&para;</a></h3> <table> <thead> <tr> <th>VRAM</th> <th>Model Size</th> <th>batch_size</th> <th>ubatch_size</th> <th>Performance</th> </tr> </thead> <tbody> <tr> <td>4 GB</td> <td>1B</td> <td>256</td> <td>64</td> <td>Good</td> </tr> <tr> <td>8 GB</td> <td>1-3B</td> <td>512</td> <td>128</td> <td>Optimal</td> </tr> <tr> <td>15 GB</td> <td>1-7B</td> <td>512</td> <td>128</td> <td>Optimal</td> </tr> <tr> <td>24 GB</td> <td>1-13B</td> <td>1024</td> <td>256</td> <td>Excellent</td> </tr> <tr> <td>40+ GB</td> <td>Any</td> <td>2048</td> <td>512</td> <td>Maximum</td> </tr> </tbody> </table> <h3 id=impact-analysis>Impact Analysis<a class=headerlink href=#impact-analysis title="Permanent link">&para;</a></h3> <p>On Tesla T4, Gemma 3-1B Q4_K_M:</p> <table> <thead> <tr> <th>batch_size</th> <th>ubatch_size</th> <th>Tokens/sec</th> <th>VRAM</th> <th>Notes</th> </tr> </thead> <tbody> <tr> <td>128</td> <td>32</td> <td>128.5</td> <td>1.12 GB</td> <td>Too small</td> </tr> <tr> <td>256</td> <td>64</td> <td>131.2</td> <td>1.15 GB</td> <td>Suboptimal</td> </tr> <tr> <td><strong>512</strong></td> <td><strong>128</strong></td> <td><strong>134.3</strong></td> <td><strong>1.18 GB</strong></td> <td><strong>Optimal</strong></td> </tr> <tr> <td>1024</td> <td>256</td> <td>133.8</td> <td>1.25 GB</td> <td>Diminishing returns</td> </tr> <tr> <td>2048</td> <td>512</td> <td>132.1</td> <td>1.42 GB</td> <td>Slower</td> </tr> </tbody> </table> <hr> <h2 id=gpu-layer-offload>GPU Layer Offload<a class=headerlink href=#gpu-layer-offload title="Permanent link">&para;</a></h2> <h3 id=full-vs-partial-offload>Full vs Partial Offload<a class=headerlink href=#full-vs-partial-offload title="Permanent link">&para;</a></h3> <p>Always use full GPU offload when possible:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=c1># RECOMMENDED: Full GPU offload</span>
</span><span id=__span-8-2><a id=__codelineno-8-2 name=__codelineno-8-2 href=#__codelineno-8-2></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-8-3><a id=__codelineno-8-3 name=__codelineno-8-3 href=#__codelineno-8-3></a>    <span class=n>model_path</span><span class=p>,</span>
</span><span id=__span-8-4><a id=__codelineno-8-4 name=__codelineno-8-4 href=#__codelineno-8-4></a>    <span class=n>gpu_layers</span><span class=o>=</span><span class=mi>99</span><span class=p>,</span>  <span class=c1># Offload all layers</span>
</span><span id=__span-8-5><a id=__codelineno-8-5 name=__codelineno-8-5 href=#__codelineno-8-5></a>    <span class=n>silent</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-8-6><a id=__codelineno-8-6 name=__codelineno-8-6 href=#__codelineno-8-6></a><span class=p>)</span>
</span></code></pre></div> <h3 id=partial-offload-limited-vram>Partial Offload (Limited VRAM)<a class=headerlink href=#partial-offload-limited-vram title="Permanent link">&para;</a></h3> <p>If VRAM is insufficient:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=kn>from</span><span class=w> </span><span class=nn>llcuda.utils</span><span class=w> </span><span class=kn>import</span> <span class=n>get_recommended_gpu_layers</span>
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a>
</span><span id=__span-9-3><a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a><span class=c1># Calculate optimal layers</span>
</span><span id=__span-9-4><a id=__codelineno-9-4 name=__codelineno-9-4 href=#__codelineno-9-4></a><span class=n>gpu_layers</span> <span class=o>=</span> <span class=n>get_recommended_gpu_layers</span><span class=p>(</span>
</span><span id=__span-9-5><a id=__codelineno-9-5 name=__codelineno-9-5 href=#__codelineno-9-5></a>    <span class=n>model_size_gb</span><span class=o>=</span><span class=mf>1.2</span><span class=p>,</span>
</span><span id=__span-9-6><a id=__codelineno-9-6 name=__codelineno-9-6 href=#__codelineno-9-6></a>    <span class=n>vram_gb</span><span class=o>=</span><span class=mf>4.0</span>
</span><span id=__span-9-7><a id=__codelineno-9-7 name=__codelineno-9-7 href=#__codelineno-9-7></a><span class=p>)</span>
</span><span id=__span-9-8><a id=__codelineno-9-8 name=__codelineno-9-8 href=#__codelineno-9-8></a>
</span><span id=__span-9-9><a id=__codelineno-9-9 name=__codelineno-9-9 href=#__codelineno-9-9></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-9-10><a id=__codelineno-9-10 name=__codelineno-9-10 href=#__codelineno-9-10></a>    <span class=n>model_path</span><span class=p>,</span>
</span><span id=__span-9-11><a id=__codelineno-9-11 name=__codelineno-9-11 href=#__codelineno-9-11></a>    <span class=n>gpu_layers</span><span class=o>=</span><span class=n>gpu_layers</span><span class=p>,</span>  <span class=c1># Partial offload</span>
</span><span id=__span-9-12><a id=__codelineno-9-12 name=__codelineno-9-12 href=#__codelineno-9-12></a>    <span class=n>silent</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-9-13><a id=__codelineno-9-13 name=__codelineno-9-13 href=#__codelineno-9-13></a><span class=p>)</span>
</span></code></pre></div> <h3 id=layer-offload-performance>Layer Offload Performance<a class=headerlink href=#layer-offload-performance title="Permanent link">&para;</a></h3> <p>Tesla T4, Gemma 3-1B:</p> <table> <thead> <tr> <th>GPU Layers</th> <th>Tokens/sec</th> <th>VRAM</th> <th>Speedup</th> </tr> </thead> <tbody> <tr> <td>0</td> <td>8.2</td> <td>0 GB</td> <td>1.0x</td> </tr> <tr> <td>10</td> <td>45.3</td> <td>0.4 GB</td> <td>5.5x</td> </tr> <tr> <td>20</td> <td>92.1</td> <td>0.9 GB</td> <td>11.2x</td> </tr> <tr> <td>35 (full)</td> <td>134.3</td> <td>1.2 GB</td> <td><strong>16.4x</strong></td> </tr> </tbody> </table> <p><strong>Rule:</strong> Each layer adds ~3.8 tok/s and ~34 MB VRAM.</p> <hr> <h2 id=server-configuration>Server Configuration<a class=headerlink href=#server-configuration title="Permanent link">&para;</a></h2> <h3 id=optimal-server-settings>Optimal Server Settings<a class=headerlink href=#optimal-server-settings title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-10-2><a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a>    <span class=n>model_path</span><span class=p>,</span>
</span><span id=__span-10-3><a id=__codelineno-10-3 name=__codelineno-10-3 href=#__codelineno-10-3></a>    <span class=c1># Core settings</span>
</span><span id=__span-10-4><a id=__codelineno-10-4 name=__codelineno-10-4 href=#__codelineno-10-4></a>    <span class=n>gpu_layers</span><span class=o>=</span><span class=mi>99</span><span class=p>,</span>
</span><span id=__span-10-5><a id=__codelineno-10-5 name=__codelineno-10-5 href=#__codelineno-10-5></a>    <span class=n>ctx_size</span><span class=o>=</span><span class=mi>2048</span><span class=p>,</span>
</span><span id=__span-10-6><a id=__codelineno-10-6 name=__codelineno-10-6 href=#__codelineno-10-6></a>    <span class=n>batch_size</span><span class=o>=</span><span class=mi>512</span><span class=p>,</span>
</span><span id=__span-10-7><a id=__codelineno-10-7 name=__codelineno-10-7 href=#__codelineno-10-7></a>    <span class=n>ubatch_size</span><span class=o>=</span><span class=mi>128</span><span class=p>,</span>
</span><span id=__span-10-8><a id=__codelineno-10-8 name=__codelineno-10-8 href=#__codelineno-10-8></a>
</span><span id=__span-10-9><a id=__codelineno-10-9 name=__codelineno-10-9 href=#__codelineno-10-9></a>    <span class=c1># Server optimization</span>
</span><span id=__span-10-10><a id=__codelineno-10-10 name=__codelineno-10-10 href=#__codelineno-10-10></a>    <span class=n>n_parallel</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>           <span class=c1># Single request (interactive)</span>
</span><span id=__span-10-11><a id=__codelineno-10-11 name=__codelineno-10-11 href=#__codelineno-10-11></a>    <span class=n>threads</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span>              <span class=c1># CPU threads for processing</span>
</span><span id=__span-10-12><a id=__codelineno-10-12 name=__codelineno-10-12 href=#__codelineno-10-12></a>    <span class=n>flash_attn</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>        <span class=c1># Enable FlashAttention</span>
</span><span id=__span-10-13><a id=__codelineno-10-13 name=__codelineno-10-13 href=#__codelineno-10-13></a>
</span><span id=__span-10-14><a id=__codelineno-10-14 name=__codelineno-10-14 href=#__codelineno-10-14></a>    <span class=c1># Advanced</span>
</span><span id=__span-10-15><a id=__codelineno-10-15 name=__codelineno-10-15 href=#__codelineno-10-15></a>    <span class=n>mlock</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>            <span class=c1># Don&#39;t lock memory (Colab)</span>
</span><span id=__span-10-16><a id=__codelineno-10-16 name=__codelineno-10-16 href=#__codelineno-10-16></a>    <span class=n>numa</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>             <span class=c1># Single NUMA node</span>
</span><span id=__span-10-17><a id=__codelineno-10-17 name=__codelineno-10-17 href=#__codelineno-10-17></a>    <span class=n>silent</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-10-18><a id=__codelineno-10-18 name=__codelineno-10-18 href=#__codelineno-10-18></a><span class=p>)</span>
</span></code></pre></div> <h3 id=parallel-request-handling>Parallel Request Handling<a class=headerlink href=#parallel-request-handling title="Permanent link">&para;</a></h3> <p>For server applications:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a><span class=c1># Handle 4 concurrent requests</span>
</span><span id=__span-11-2><a id=__codelineno-11-2 name=__codelineno-11-2 href=#__codelineno-11-2></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-11-3><a id=__codelineno-11-3 name=__codelineno-11-3 href=#__codelineno-11-3></a>    <span class=n>model_path</span><span class=p>,</span>
</span><span id=__span-11-4><a id=__codelineno-11-4 name=__codelineno-11-4 href=#__codelineno-11-4></a>    <span class=n>gpu_layers</span><span class=o>=</span><span class=mi>99</span><span class=p>,</span>
</span><span id=__span-11-5><a id=__codelineno-11-5 name=__codelineno-11-5 href=#__codelineno-11-5></a>    <span class=n>ctx_size</span><span class=o>=</span><span class=mi>2048</span><span class=p>,</span>
</span><span id=__span-11-6><a id=__codelineno-11-6 name=__codelineno-11-6 href=#__codelineno-11-6></a>    <span class=n>batch_size</span><span class=o>=</span><span class=mi>512</span><span class=p>,</span>
</span><span id=__span-11-7><a id=__codelineno-11-7 name=__codelineno-11-7 href=#__codelineno-11-7></a>    <span class=n>ubatch_size</span><span class=o>=</span><span class=mi>128</span><span class=p>,</span>
</span><span id=__span-11-8><a id=__codelineno-11-8 name=__codelineno-11-8 href=#__codelineno-11-8></a>    <span class=n>n_parallel</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span>  <span class=c1># 4 parallel sequences</span>
</span><span id=__span-11-9><a id=__codelineno-11-9 name=__codelineno-11-9 href=#__codelineno-11-9></a>    <span class=n>silent</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-11-10><a id=__codelineno-11-10 name=__codelineno-11-10 href=#__codelineno-11-10></a><span class=p>)</span>
</span></code></pre></div> <p><strong>Performance with n_parallel:</strong></p> <table> <thead> <tr> <th>n_parallel</th> <th>Total tok/s</th> <th>Latency/request</th> <th>VRAM</th> <th>Best For</th> </tr> </thead> <tbody> <tr> <td>1</td> <td>134</td> <td>690 ms</td> <td>1.2 GB</td> <td>Interactive chat</td> </tr> <tr> <td>2</td> <td>250</td> <td>755 ms</td> <td>1.5 GB</td> <td>Small server</td> </tr> <tr> <td>4</td> <td>460</td> <td>830 ms</td> <td>2.3 GB</td> <td>Production server</td> </tr> <tr> <td>8</td> <td>790</td> <td>980 ms</td> <td>3.9 GB</td> <td>High throughput</td> </tr> </tbody> </table> <hr> <h2 id=flashattention-optimization>FlashAttention Optimization<a class=headerlink href=#flashattention-optimization title="Permanent link">&para;</a></h2> <h3 id=when-to-use-flashattention>When to Use FlashAttention<a class=headerlink href=#when-to-use-flashattention title="Permanent link">&para;</a></h3> <p>Enable for contexts &gt; 4096:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-12-1><a id=__codelineno-12-1 name=__codelineno-12-1 href=#__codelineno-12-1></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-12-2><a id=__codelineno-12-2 name=__codelineno-12-2 href=#__codelineno-12-2></a>    <span class=n>model_path</span><span class=p>,</span>
</span><span id=__span-12-3><a id=__codelineno-12-3 name=__codelineno-12-3 href=#__codelineno-12-3></a>    <span class=n>ctx_size</span><span class=o>=</span><span class=mi>8192</span><span class=p>,</span>
</span><span id=__span-12-4><a id=__codelineno-12-4 name=__codelineno-12-4 href=#__codelineno-12-4></a>    <span class=n>flash_attn</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>  <span class=c1># Enable FlashAttention</span>
</span><span id=__span-12-5><a id=__codelineno-12-5 name=__codelineno-12-5 href=#__codelineno-12-5></a>    <span class=n>silent</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-12-6><a id=__codelineno-12-6 name=__codelineno-12-6 href=#__codelineno-12-6></a><span class=p>)</span>
</span></code></pre></div> <h3 id=flashattention-benefits>FlashAttention Benefits<a class=headerlink href=#flashattention-benefits title="Permanent link">&para;</a></h3> <table> <thead> <tr> <th>Context Size</th> <th>Without FA</th> <th>With FA</th> <th>Speedup</th> <th>VRAM Saved</th> </tr> </thead> <tbody> <tr> <td>2048</td> <td>134.3</td> <td>135.2</td> <td>1.01x</td> <td>0.12 GB</td> </tr> <tr> <td>4096</td> <td>95.5</td> <td>125.1</td> <td><strong>1.31x</strong></td> <td>0.35 GB</td> </tr> <tr> <td>8192</td> <td>55.2</td> <td>105.3</td> <td><strong>1.91x</strong></td> <td>0.98 GB</td> </tr> <tr> <td>16384</td> <td>28.5</td> <td>78.5</td> <td><strong>2.75x</strong></td> <td>2.52 GB</td> </tr> </tbody> </table> <p><strong>Key Finding:</strong> Significant benefits (1.3-2.8x) for long contexts.</p> <hr> <h2 id=memory-optimization>Memory Optimization<a class=headerlink href=#memory-optimization title="Permanent link">&para;</a></h2> <h3 id=reduce-vram-usage>Reduce VRAM Usage<a class=headerlink href=#reduce-vram-usage title="Permanent link">&para;</a></h3> <p><strong>1. Use Aggressive Quantization:</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-13-1><a id=__codelineno-13-1 name=__codelineno-13-1 href=#__codelineno-13-1></a><span class=c1># Q4_0 instead of Q4_K_M saves ~100 MB</span>
</span><span id=__span-13-2><a id=__codelineno-13-2 name=__codelineno-13-2 href=#__codelineno-13-2></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-13-3><a id=__codelineno-13-3 name=__codelineno-13-3 href=#__codelineno-13-3></a>    <span class=s2>&quot;model-Q4_0.gguf&quot;</span><span class=p>,</span>
</span><span id=__span-13-4><a id=__codelineno-13-4 name=__codelineno-13-4 href=#__codelineno-13-4></a>    <span class=n>silent</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-13-5><a id=__codelineno-13-5 name=__codelineno-13-5 href=#__codelineno-13-5></a><span class=p>)</span>
</span></code></pre></div></p> <p><strong>2. Reduce Context Size:</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-14-1><a id=__codelineno-14-1 name=__codelineno-14-1 href=#__codelineno-14-1></a><span class=c1># 1024 instead of 2048 saves ~200 MB</span>
</span><span id=__span-14-2><a id=__codelineno-14-2 name=__codelineno-14-2 href=#__codelineno-14-2></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-14-3><a id=__codelineno-14-3 name=__codelineno-14-3 href=#__codelineno-14-3></a>    <span class=n>model_path</span><span class=p>,</span>
</span><span id=__span-14-4><a id=__codelineno-14-4 name=__codelineno-14-4 href=#__codelineno-14-4></a>    <span class=n>ctx_size</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span>
</span><span id=__span-14-5><a id=__codelineno-14-5 name=__codelineno-14-5 href=#__codelineno-14-5></a>    <span class=n>silent</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-14-6><a id=__codelineno-14-6 name=__codelineno-14-6 href=#__codelineno-14-6></a><span class=p>)</span>
</span></code></pre></div></p> <p><strong>3. Lower Batch Sizes:</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-15-1><a id=__codelineno-15-1 name=__codelineno-15-1 href=#__codelineno-15-1></a><span class=c1># Smaller batches use less VRAM</span>
</span><span id=__span-15-2><a id=__codelineno-15-2 name=__codelineno-15-2 href=#__codelineno-15-2></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-15-3><a id=__codelineno-15-3 name=__codelineno-15-3 href=#__codelineno-15-3></a>    <span class=n>model_path</span><span class=p>,</span>
</span><span id=__span-15-4><a id=__codelineno-15-4 name=__codelineno-15-4 href=#__codelineno-15-4></a>    <span class=n>batch_size</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span>
</span><span id=__span-15-5><a id=__codelineno-15-5 name=__codelineno-15-5 href=#__codelineno-15-5></a>    <span class=n>ubatch_size</span><span class=o>=</span><span class=mi>64</span><span class=p>,</span>
</span><span id=__span-15-6><a id=__codelineno-15-6 name=__codelineno-15-6 href=#__codelineno-15-6></a>    <span class=n>silent</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-15-7><a id=__codelineno-15-7 name=__codelineno-15-7 href=#__codelineno-15-7></a><span class=p>)</span>
</span></code></pre></div></p> <h3 id=memory-constrained-configuration>Memory-Constrained Configuration<a class=headerlink href=#memory-constrained-configuration title="Permanent link">&para;</a></h3> <p>For GPUs with &lt; 6 GB VRAM:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-16-1><a id=__codelineno-16-1 name=__codelineno-16-1 href=#__codelineno-16-1></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-16-2><a id=__codelineno-16-2 name=__codelineno-16-2 href=#__codelineno-16-2></a>    <span class=s2>&quot;model-Q4_0.gguf&quot;</span><span class=p>,</span>
</span><span id=__span-16-3><a id=__codelineno-16-3 name=__codelineno-16-3 href=#__codelineno-16-3></a>    <span class=n>gpu_layers</span><span class=o>=</span><span class=mi>99</span><span class=p>,</span>
</span><span id=__span-16-4><a id=__codelineno-16-4 name=__codelineno-16-4 href=#__codelineno-16-4></a>    <span class=n>ctx_size</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span>
</span><span id=__span-16-5><a id=__codelineno-16-5 name=__codelineno-16-5 href=#__codelineno-16-5></a>    <span class=n>batch_size</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span>
</span><span id=__span-16-6><a id=__codelineno-16-6 name=__codelineno-16-6 href=#__codelineno-16-6></a>    <span class=n>ubatch_size</span><span class=o>=</span><span class=mi>64</span><span class=p>,</span>
</span><span id=__span-16-7><a id=__codelineno-16-7 name=__codelineno-16-7 href=#__codelineno-16-7></a>    <span class=n>n_parallel</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span>
</span><span id=__span-16-8><a id=__codelineno-16-8 name=__codelineno-16-8 href=#__codelineno-16-8></a>    <span class=n>silent</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-16-9><a id=__codelineno-16-9 name=__codelineno-16-9 href=#__codelineno-16-9></a><span class=p>)</span>
</span></code></pre></div> <hr> <h2 id=auto-configuration>Auto-Configuration<a class=headerlink href=#auto-configuration title="Permanent link">&para;</a></h2> <h3 id=let-llcuda-optimize>Let llcuda Optimize<a class=headerlink href=#let-llcuda-optimize title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-17-1><a id=__codelineno-17-1 name=__codelineno-17-1 href=#__codelineno-17-1></a><span class=kn>from</span><span class=w> </span><span class=nn>llcuda.utils</span><span class=w> </span><span class=kn>import</span> <span class=n>auto_configure_for_model</span>
</span><span id=__span-17-2><a id=__codelineno-17-2 name=__codelineno-17-2 href=#__codelineno-17-2></a><span class=kn>from</span><span class=w> </span><span class=nn>pathlib</span><span class=w> </span><span class=kn>import</span> <span class=n>Path</span>
</span><span id=__span-17-3><a id=__codelineno-17-3 name=__codelineno-17-3 href=#__codelineno-17-3></a>
</span><span id=__span-17-4><a id=__codelineno-17-4 name=__codelineno-17-4 href=#__codelineno-17-4></a><span class=c1># Auto-detect optimal settings</span>
</span><span id=__span-17-5><a id=__codelineno-17-5 name=__codelineno-17-5 href=#__codelineno-17-5></a><span class=n>settings</span> <span class=o>=</span> <span class=n>auto_configure_for_model</span><span class=p>(</span><span class=n>Path</span><span class=p>(</span><span class=s2>&quot;model.gguf&quot;</span><span class=p>))</span>
</span><span id=__span-17-6><a id=__codelineno-17-6 name=__codelineno-17-6 href=#__codelineno-17-6></a>
</span><span id=__span-17-7><a id=__codelineno-17-7 name=__codelineno-17-7 href=#__codelineno-17-7></a><span class=c1># Apply settings</span>
</span><span id=__span-17-8><a id=__codelineno-17-8 name=__codelineno-17-8 href=#__codelineno-17-8></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-17-9><a id=__codelineno-17-9 name=__codelineno-17-9 href=#__codelineno-17-9></a>    <span class=s2>&quot;model.gguf&quot;</span><span class=p>,</span>
</span><span id=__span-17-10><a id=__codelineno-17-10 name=__codelineno-17-10 href=#__codelineno-17-10></a>    <span class=o>**</span><span class=n>settings</span><span class=p>,</span>  <span class=c1># Use all auto-configured values</span>
</span><span id=__span-17-11><a id=__codelineno-17-11 name=__codelineno-17-11 href=#__codelineno-17-11></a>    <span class=n>silent</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-17-12><a id=__codelineno-17-12 name=__codelineno-17-12 href=#__codelineno-17-12></a><span class=p>)</span>
</span></code></pre></div> <h3 id=manual-override>Manual Override<a class=headerlink href=#manual-override title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-18-1><a id=__codelineno-18-1 name=__codelineno-18-1 href=#__codelineno-18-1></a><span class=c1># Start with auto-config</span>
</span><span id=__span-18-2><a id=__codelineno-18-2 name=__codelineno-18-2 href=#__codelineno-18-2></a><span class=n>settings</span> <span class=o>=</span> <span class=n>auto_configure_for_model</span><span class=p>(</span><span class=n>Path</span><span class=p>(</span><span class=s2>&quot;model.gguf&quot;</span><span class=p>))</span>
</span><span id=__span-18-3><a id=__codelineno-18-3 name=__codelineno-18-3 href=#__codelineno-18-3></a>
</span><span id=__span-18-4><a id=__codelineno-18-4 name=__codelineno-18-4 href=#__codelineno-18-4></a><span class=c1># Override specific settings</span>
</span><span id=__span-18-5><a id=__codelineno-18-5 name=__codelineno-18-5 href=#__codelineno-18-5></a><span class=n>settings</span><span class=p>[</span><span class=s1>&#39;ctx_size&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=mi>4096</span>  <span class=c1># Use longer context</span>
</span><span id=__span-18-6><a id=__codelineno-18-6 name=__codelineno-18-6 href=#__codelineno-18-6></a><span class=n>settings</span><span class=p>[</span><span class=s1>&#39;n_parallel&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=mi>4</span>   <span class=c1># Handle more requests</span>
</span><span id=__span-18-7><a id=__codelineno-18-7 name=__codelineno-18-7 href=#__codelineno-18-7></a>
</span><span id=__span-18-8><a id=__codelineno-18-8 name=__codelineno-18-8 href=#__codelineno-18-8></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=s2>&quot;model.gguf&quot;</span><span class=p>,</span> <span class=o>**</span><span class=n>settings</span><span class=p>,</span> <span class=n>silent</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></code></pre></div> <hr> <h2 id=model-selection-for-performance>Model Selection for Performance<a class=headerlink href=#model-selection-for-performance title="Permanent link">&para;</a></h2> <h3 id=size-vs-speed-trade-off>Size vs Speed Trade-off<a class=headerlink href=#size-vs-speed-trade-off title="Permanent link">&para;</a></h3> <table> <thead> <tr> <th>Model Size</th> <th>Tokens/sec (T4)</th> <th>VRAM</th> <th>Best For</th> </tr> </thead> <tbody> <tr> <td>1B</td> <td>134</td> <td>1.2 GB</td> <td>✅ Interactive, production</td> </tr> <tr> <td>3B</td> <td>48</td> <td>2.0 GB</td> <td>Balanced quality/speed</td> </tr> <tr> <td>7B</td> <td>21</td> <td>5.0 GB</td> <td>Quality-focused</td> </tr> <tr> <td>13B</td> <td>12</td> <td>9.0 GB</td> <td>Maximum quality</td> </tr> </tbody> </table> <p><strong>Recommendation:</strong> For T4, use 1B models for best performance.</p> <h3 id=popular-high-performance-models>Popular High-Performance Models<a class=headerlink href=#popular-high-performance-models title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-19-1><a id=__codelineno-19-1 name=__codelineno-19-1 href=#__codelineno-19-1></a><span class=c1># Fastest: Gemma 3-1B (134 tok/s)</span>
</span><span id=__span-19-2><a id=__codelineno-19-2 name=__codelineno-19-2 href=#__codelineno-19-2></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-19-3><a id=__codelineno-19-3 name=__codelineno-19-3 href=#__codelineno-19-3></a>    <span class=s2>&quot;unsloth/gemma-3-1b-it-GGUF:gemma-3-1b-it-Q4_K_M.gguf&quot;</span><span class=p>,</span>
</span><span id=__span-19-4><a id=__codelineno-19-4 name=__codelineno-19-4 href=#__codelineno-19-4></a>    <span class=n>silent</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-19-5><a id=__codelineno-19-5 name=__codelineno-19-5 href=#__codelineno-19-5></a><span class=p>)</span>
</span><span id=__span-19-6><a id=__codelineno-19-6 name=__codelineno-19-6 href=#__codelineno-19-6></a>
</span><span id=__span-19-7><a id=__codelineno-19-7 name=__codelineno-19-7 href=#__codelineno-19-7></a><span class=c1># Balanced: Llama 3.2-3B (48 tok/s)</span>
</span><span id=__span-19-8><a id=__codelineno-19-8 name=__codelineno-19-8 href=#__codelineno-19-8></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-19-9><a id=__codelineno-19-9 name=__codelineno-19-9 href=#__codelineno-19-9></a>    <span class=s2>&quot;unsloth/Llama-3.2-3B-Instruct-Q4_K_M-GGUF&quot;</span><span class=p>,</span>
</span><span id=__span-19-10><a id=__codelineno-19-10 name=__codelineno-19-10 href=#__codelineno-19-10></a>    <span class=n>silent</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-19-11><a id=__codelineno-19-11 name=__codelineno-19-11 href=#__codelineno-19-11></a><span class=p>)</span>
</span><span id=__span-19-12><a id=__codelineno-19-12 name=__codelineno-19-12 href=#__codelineno-19-12></a>
</span><span id=__span-19-13><a id=__codelineno-19-13 name=__codelineno-19-13 href=#__codelineno-19-13></a><span class=c1># Quality: Qwen 2.5-7B (21 tok/s)</span>
</span><span id=__span-19-14><a id=__codelineno-19-14 name=__codelineno-19-14 href=#__codelineno-19-14></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-19-15><a id=__codelineno-19-15 name=__codelineno-19-15 href=#__codelineno-19-15></a>    <span class=s2>&quot;Qwen/Qwen2.5-7B-Instruct-GGUF:Q4_K_M&quot;</span><span class=p>,</span>
</span><span id=__span-19-16><a id=__codelineno-19-16 name=__codelineno-19-16 href=#__codelineno-19-16></a>    <span class=n>silent</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-19-17><a id=__codelineno-19-17 name=__codelineno-19-17 href=#__codelineno-19-17></a><span class=p>)</span>
</span></code></pre></div> <hr> <h2 id=generation-parameter-tuning>Generation Parameter Tuning<a class=headerlink href=#generation-parameter-tuning title="Permanent link">&para;</a></h2> <h3 id=speed-vs-quality>Speed vs Quality<a class=headerlink href=#speed-vs-quality title="Permanent link">&para;</a></h3> <p><strong>Fastest (Deterministic):</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-20-1><a id=__codelineno-20-1 name=__codelineno-20-1 href=#__codelineno-20-1></a><span class=n>result</span> <span class=o>=</span> <span class=n>engine</span><span class=o>.</span><span class=n>infer</span><span class=p>(</span>
</span><span id=__span-20-2><a id=__codelineno-20-2 name=__codelineno-20-2 href=#__codelineno-20-2></a>    <span class=n>prompt</span><span class=p>,</span>
</span><span id=__span-20-3><a id=__codelineno-20-3 name=__codelineno-20-3 href=#__codelineno-20-3></a>    <span class=n>max_tokens</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span>
</span><span id=__span-20-4><a id=__codelineno-20-4 name=__codelineno-20-4 href=#__codelineno-20-4></a>    <span class=n>temperature</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span>
</span><span id=__span-20-5><a id=__codelineno-20-5 name=__codelineno-20-5 href=#__codelineno-20-5></a>    <span class=n>top_k</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span>
</span><span id=__span-20-6><a id=__codelineno-20-6 name=__codelineno-20-6 href=#__codelineno-20-6></a>    <span class=n>top_p</span><span class=o>=</span><span class=mf>0.9</span>
</span><span id=__span-20-7><a id=__codelineno-20-7 name=__codelineno-20-7 href=#__codelineno-20-7></a><span class=p>)</span>
</span><span id=__span-20-8><a id=__codelineno-20-8 name=__codelineno-20-8 href=#__codelineno-20-8></a><span class=c1># ~140 tok/s</span>
</span></code></pre></div></p> <p><strong>Balanced:</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-21-1><a id=__codelineno-21-1 name=__codelineno-21-1 href=#__codelineno-21-1></a><span class=n>result</span> <span class=o>=</span> <span class=n>engine</span><span class=o>.</span><span class=n>infer</span><span class=p>(</span>
</span><span id=__span-21-2><a id=__codelineno-21-2 name=__codelineno-21-2 href=#__codelineno-21-2></a>    <span class=n>prompt</span><span class=p>,</span>
</span><span id=__span-21-3><a id=__codelineno-21-3 name=__codelineno-21-3 href=#__codelineno-21-3></a>    <span class=n>max_tokens</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span>
</span><span id=__span-21-4><a id=__codelineno-21-4 name=__codelineno-21-4 href=#__codelineno-21-4></a>    <span class=n>temperature</span><span class=o>=</span><span class=mf>0.7</span><span class=p>,</span>
</span><span id=__span-21-5><a id=__codelineno-21-5 name=__codelineno-21-5 href=#__codelineno-21-5></a>    <span class=n>top_k</span><span class=o>=</span><span class=mi>40</span><span class=p>,</span>
</span><span id=__span-21-6><a id=__codelineno-21-6 name=__codelineno-21-6 href=#__codelineno-21-6></a>    <span class=n>top_p</span><span class=o>=</span><span class=mf>0.9</span>
</span><span id=__span-21-7><a id=__codelineno-21-7 name=__codelineno-21-7 href=#__codelineno-21-7></a><span class=p>)</span>
</span><span id=__span-21-8><a id=__codelineno-21-8 name=__codelineno-21-8 href=#__codelineno-21-8></a><span class=c1># ~134 tok/s</span>
</span></code></pre></div></p> <p><strong>Creative (Slower):</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-22-1><a id=__codelineno-22-1 name=__codelineno-22-1 href=#__codelineno-22-1></a><span class=n>result</span> <span class=o>=</span> <span class=n>engine</span><span class=o>.</span><span class=n>infer</span><span class=p>(</span>
</span><span id=__span-22-2><a id=__codelineno-22-2 name=__codelineno-22-2 href=#__codelineno-22-2></a>    <span class=n>prompt</span><span class=p>,</span>
</span><span id=__span-22-3><a id=__codelineno-22-3 name=__codelineno-22-3 href=#__codelineno-22-3></a>    <span class=n>max_tokens</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span>
</span><span id=__span-22-4><a id=__codelineno-22-4 name=__codelineno-22-4 href=#__codelineno-22-4></a>    <span class=n>temperature</span><span class=o>=</span><span class=mf>1.5</span><span class=p>,</span>
</span><span id=__span-22-5><a id=__codelineno-22-5 name=__codelineno-22-5 href=#__codelineno-22-5></a>    <span class=n>top_k</span><span class=o>=</span><span class=mi>200</span><span class=p>,</span>
</span><span id=__span-22-6><a id=__codelineno-22-6 name=__codelineno-22-6 href=#__codelineno-22-6></a>    <span class=n>top_p</span><span class=o>=</span><span class=mf>0.95</span>
</span><span id=__span-22-7><a id=__codelineno-22-7 name=__codelineno-22-7 href=#__codelineno-22-7></a><span class=p>)</span>
</span><span id=__span-22-8><a id=__codelineno-22-8 name=__codelineno-22-8 href=#__codelineno-22-8></a><span class=c1># ~118 tok/s</span>
</span></code></pre></div></p> <h3 id=parameter-impact>Parameter Impact<a class=headerlink href=#parameter-impact title="Permanent link">&para;</a></h3> <table> <thead> <tr> <th>Parameter</th> <th>Low Value</th> <th>High Value</th> <th>Speed Impact</th> </tr> </thead> <tbody> <tr> <td>temperature</td> <td>Faster</td> <td>Slower</td> <td>5-12%</td> </tr> <tr> <td>top_k</td> <td>Faster</td> <td>Slower</td> <td>2-5%</td> </tr> <tr> <td>top_p</td> <td>Minimal</td> <td>Minimal</td> <td>&lt; 1%</td> </tr> </tbody> </table> <hr> <h2 id=multi-gpu-configuration>Multi-GPU Configuration<a class=headerlink href=#multi-gpu-configuration title="Permanent link">&para;</a></h2> <h3 id=select-specific-gpu>Select Specific GPU<a class=headerlink href=#select-specific-gpu title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-23-1><a id=__codelineno-23-1 name=__codelineno-23-1 href=#__codelineno-23-1></a><span class=kn>import</span><span class=w> </span><span class=nn>os</span>
</span><span id=__span-23-2><a id=__codelineno-23-2 name=__codelineno-23-2 href=#__codelineno-23-2></a>
</span><span id=__span-23-3><a id=__codelineno-23-3 name=__codelineno-23-3 href=#__codelineno-23-3></a><span class=c1># Use GPU 1</span>
</span><span id=__span-23-4><a id=__codelineno-23-4 name=__codelineno-23-4 href=#__codelineno-23-4></a><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;CUDA_VISIBLE_DEVICES&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=s1>&#39;1&#39;</span>
</span><span id=__span-23-5><a id=__codelineno-23-5 name=__codelineno-23-5 href=#__codelineno-23-5></a>
</span><span id=__span-23-6><a id=__codelineno-23-6 name=__codelineno-23-6 href=#__codelineno-23-6></a><span class=kn>import</span><span class=w> </span><span class=nn>llcuda</span>
</span><span id=__span-23-7><a id=__codelineno-23-7 name=__codelineno-23-7 href=#__codelineno-23-7></a><span class=n>engine</span> <span class=o>=</span> <span class=n>llcuda</span><span class=o>.</span><span class=n>InferenceEngine</span><span class=p>()</span>
</span></code></pre></div> <h3 id=load-balance-across-gpus>Load Balance Across GPUs<a class=headerlink href=#load-balance-across-gpus title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-24-1><a id=__codelineno-24-1 name=__codelineno-24-1 href=#__codelineno-24-1></a><span class=c1># Use GPUs 0 and 1</span>
</span><span id=__span-24-2><a id=__codelineno-24-2 name=__codelineno-24-2 href=#__codelineno-24-2></a><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;CUDA_VISIBLE_DEVICES&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=s1>&#39;0,1&#39;</span>
</span><span id=__span-24-3><a id=__codelineno-24-3 name=__codelineno-24-3 href=#__codelineno-24-3></a>
</span><span id=__span-24-4><a id=__codelineno-24-4 name=__codelineno-24-4 href=#__codelineno-24-4></a><span class=c1># llama.cpp will distribute layers automatically</span>
</span><span id=__span-24-5><a id=__codelineno-24-5 name=__codelineno-24-5 href=#__codelineno-24-5></a><span class=kn>import</span><span class=w> </span><span class=nn>llcuda</span>
</span><span id=__span-24-6><a id=__codelineno-24-6 name=__codelineno-24-6 href=#__codelineno-24-6></a><span class=n>engine</span> <span class=o>=</span> <span class=n>llcuda</span><span class=o>.</span><span class=n>InferenceEngine</span><span class=p>()</span>
</span><span id=__span-24-7><a id=__codelineno-24-7 name=__codelineno-24-7 href=#__codelineno-24-7></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=n>model_path</span><span class=p>,</span> <span class=n>gpu_layers</span><span class=o>=</span><span class=mi>99</span><span class=p>,</span> <span class=n>silent</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></code></pre></div> <hr> <h2 id=benchmarking-your-setup>Benchmarking Your Setup<a class=headerlink href=#benchmarking-your-setup title="Permanent link">&para;</a></h2> <h3 id=quick-benchmark>Quick Benchmark<a class=headerlink href=#quick-benchmark title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-25-1><a id=__codelineno-25-1 name=__codelineno-25-1 href=#__codelineno-25-1></a><span class=kn>import</span><span class=w> </span><span class=nn>llcuda</span>
</span><span id=__span-25-2><a id=__codelineno-25-2 name=__codelineno-25-2 href=#__codelineno-25-2></a><span class=kn>import</span><span class=w> </span><span class=nn>time</span>
</span><span id=__span-25-3><a id=__codelineno-25-3 name=__codelineno-25-3 href=#__codelineno-25-3></a>
</span><span id=__span-25-4><a id=__codelineno-25-4 name=__codelineno-25-4 href=#__codelineno-25-4></a><span class=c1># Setup</span>
</span><span id=__span-25-5><a id=__codelineno-25-5 name=__codelineno-25-5 href=#__codelineno-25-5></a><span class=n>engine</span> <span class=o>=</span> <span class=n>llcuda</span><span class=o>.</span><span class=n>InferenceEngine</span><span class=p>()</span>
</span><span id=__span-25-6><a id=__codelineno-25-6 name=__codelineno-25-6 href=#__codelineno-25-6></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=s2>&quot;model.gguf&quot;</span><span class=p>,</span> <span class=n>silent</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-25-7><a id=__codelineno-25-7 name=__codelineno-25-7 href=#__codelineno-25-7></a>
</span><span id=__span-25-8><a id=__codelineno-25-8 name=__codelineno-25-8 href=#__codelineno-25-8></a><span class=c1># Warmup</span>
</span><span id=__span-25-9><a id=__codelineno-25-9 name=__codelineno-25-9 href=#__codelineno-25-9></a><span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>3</span><span class=p>):</span>
</span><span id=__span-25-10><a id=__codelineno-25-10 name=__codelineno-25-10 href=#__codelineno-25-10></a>    <span class=n>engine</span><span class=o>.</span><span class=n>infer</span><span class=p>(</span><span class=s2>&quot;Warmup&quot;</span><span class=p>,</span> <span class=n>max_tokens</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>
</span><span id=__span-25-11><a id=__codelineno-25-11 name=__codelineno-25-11 href=#__codelineno-25-11></a>
</span><span id=__span-25-12><a id=__codelineno-25-12 name=__codelineno-25-12 href=#__codelineno-25-12></a><span class=c1># Benchmark</span>
</span><span id=__span-25-13><a id=__codelineno-25-13 name=__codelineno-25-13 href=#__codelineno-25-13></a><span class=n>engine</span><span class=o>.</span><span class=n>reset_metrics</span><span class=p>()</span>
</span><span id=__span-25-14><a id=__codelineno-25-14 name=__codelineno-25-14 href=#__codelineno-25-14></a><span class=n>start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span><span id=__span-25-15><a id=__codelineno-25-15 name=__codelineno-25-15 href=#__codelineno-25-15></a>
</span><span id=__span-25-16><a id=__codelineno-25-16 name=__codelineno-25-16 href=#__codelineno-25-16></a><span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10</span><span class=p>):</span>
</span><span id=__span-25-17><a id=__codelineno-25-17 name=__codelineno-25-17 href=#__codelineno-25-17></a>    <span class=n>engine</span><span class=o>.</span><span class=n>infer</span><span class=p>(</span><span class=s2>&quot;Test prompt&quot;</span><span class=p>,</span> <span class=n>max_tokens</span><span class=o>=</span><span class=mi>100</span><span class=p>)</span>
</span><span id=__span-25-18><a id=__codelineno-25-18 name=__codelineno-25-18 href=#__codelineno-25-18></a>
</span><span id=__span-25-19><a id=__codelineno-25-19 name=__codelineno-25-19 href=#__codelineno-25-19></a><span class=n>elapsed</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=n>start</span>
</span><span id=__span-25-20><a id=__codelineno-25-20 name=__codelineno-25-20 href=#__codelineno-25-20></a><span class=n>metrics</span> <span class=o>=</span> <span class=n>engine</span><span class=o>.</span><span class=n>get_metrics</span><span class=p>()</span>
</span><span id=__span-25-21><a id=__codelineno-25-21 name=__codelineno-25-21 href=#__codelineno-25-21></a>
</span><span id=__span-25-22><a id=__codelineno-25-22 name=__codelineno-25-22 href=#__codelineno-25-22></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Throughput: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;throughput&#39;</span><span class=p>][</span><span class=s1>&#39;tokens_per_sec&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2> tok/s&quot;</span><span class=p>)</span>
</span><span id=__span-25-23><a id=__codelineno-25-23 name=__codelineno-25-23 href=#__codelineno-25-23></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Latency: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;latency&#39;</span><span class=p>][</span><span class=s1>&#39;mean_ms&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.0f</span><span class=si>}</span><span class=s2>ms&quot;</span><span class=p>)</span>
</span><span id=__span-25-24><a id=__codelineno-25-24 name=__codelineno-25-24 href=#__codelineno-25-24></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Total time: </span><span class=si>{</span><span class=n>elapsed</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>s&quot;</span><span class=p>)</span>
</span></code></pre></div> <h3 id=compare-configurations>Compare Configurations<a class=headerlink href=#compare-configurations title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-26-1><a id=__codelineno-26-1 name=__codelineno-26-1 href=#__codelineno-26-1></a><span class=n>configs</span> <span class=o>=</span> <span class=p>[</span>
</span><span id=__span-26-2><a id=__codelineno-26-2 name=__codelineno-26-2 href=#__codelineno-26-2></a>    <span class=p>{</span><span class=s2>&quot;ctx_size&quot;</span><span class=p>:</span> <span class=mi>1024</span><span class=p>,</span> <span class=s2>&quot;batch_size&quot;</span><span class=p>:</span> <span class=mi>256</span><span class=p>},</span>
</span><span id=__span-26-3><a id=__codelineno-26-3 name=__codelineno-26-3 href=#__codelineno-26-3></a>    <span class=p>{</span><span class=s2>&quot;ctx_size&quot;</span><span class=p>:</span> <span class=mi>2048</span><span class=p>,</span> <span class=s2>&quot;batch_size&quot;</span><span class=p>:</span> <span class=mi>512</span><span class=p>},</span>
</span><span id=__span-26-4><a id=__codelineno-26-4 name=__codelineno-26-4 href=#__codelineno-26-4></a>    <span class=p>{</span><span class=s2>&quot;ctx_size&quot;</span><span class=p>:</span> <span class=mi>4096</span><span class=p>,</span> <span class=s2>&quot;batch_size&quot;</span><span class=p>:</span> <span class=mi>1024</span><span class=p>},</span>
</span><span id=__span-26-5><a id=__codelineno-26-5 name=__codelineno-26-5 href=#__codelineno-26-5></a><span class=p>]</span>
</span><span id=__span-26-6><a id=__codelineno-26-6 name=__codelineno-26-6 href=#__codelineno-26-6></a>
</span><span id=__span-26-7><a id=__codelineno-26-7 name=__codelineno-26-7 href=#__codelineno-26-7></a><span class=k>for</span> <span class=n>config</span> <span class=ow>in</span> <span class=n>configs</span><span class=p>:</span>
</span><span id=__span-26-8><a id=__codelineno-26-8 name=__codelineno-26-8 href=#__codelineno-26-8></a>    <span class=n>engine</span> <span class=o>=</span> <span class=n>llcuda</span><span class=o>.</span><span class=n>InferenceEngine</span><span class=p>()</span>
</span><span id=__span-26-9><a id=__codelineno-26-9 name=__codelineno-26-9 href=#__codelineno-26-9></a>    <span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=s2>&quot;model.gguf&quot;</span><span class=p>,</span> <span class=o>**</span><span class=n>config</span><span class=p>,</span> <span class=n>silent</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span><span id=__span-26-10><a id=__codelineno-26-10 name=__codelineno-26-10 href=#__codelineno-26-10></a>
</span><span id=__span-26-11><a id=__codelineno-26-11 name=__codelineno-26-11 href=#__codelineno-26-11></a>    <span class=c1># Warmup</span>
</span><span id=__span-26-12><a id=__codelineno-26-12 name=__codelineno-26-12 href=#__codelineno-26-12></a>    <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>3</span><span class=p>):</span>
</span><span id=__span-26-13><a id=__codelineno-26-13 name=__codelineno-26-13 href=#__codelineno-26-13></a>        <span class=n>engine</span><span class=o>.</span><span class=n>infer</span><span class=p>(</span><span class=s2>&quot;Warmup&quot;</span><span class=p>,</span> <span class=n>max_tokens</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>
</span><span id=__span-26-14><a id=__codelineno-26-14 name=__codelineno-26-14 href=#__codelineno-26-14></a>
</span><span id=__span-26-15><a id=__codelineno-26-15 name=__codelineno-26-15 href=#__codelineno-26-15></a>    <span class=c1># Benchmark</span>
</span><span id=__span-26-16><a id=__codelineno-26-16 name=__codelineno-26-16 href=#__codelineno-26-16></a>    <span class=n>engine</span><span class=o>.</span><span class=n>reset_metrics</span><span class=p>()</span>
</span><span id=__span-26-17><a id=__codelineno-26-17 name=__codelineno-26-17 href=#__codelineno-26-17></a>    <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10</span><span class=p>):</span>
</span><span id=__span-26-18><a id=__codelineno-26-18 name=__codelineno-26-18 href=#__codelineno-26-18></a>        <span class=n>engine</span><span class=o>.</span><span class=n>infer</span><span class=p>(</span><span class=s2>&quot;Test&quot;</span><span class=p>,</span> <span class=n>max_tokens</span><span class=o>=</span><span class=mi>100</span><span class=p>)</span>
</span><span id=__span-26-19><a id=__codelineno-26-19 name=__codelineno-26-19 href=#__codelineno-26-19></a>
</span><span id=__span-26-20><a id=__codelineno-26-20 name=__codelineno-26-20 href=#__codelineno-26-20></a>    <span class=n>metrics</span> <span class=o>=</span> <span class=n>engine</span><span class=o>.</span><span class=n>get_metrics</span><span class=p>()</span>
</span><span id=__span-26-21><a id=__codelineno-26-21 name=__codelineno-26-21 href=#__codelineno-26-21></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Config </span><span class=si>{</span><span class=n>config</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>metrics</span><span class=p>[</span><span class=s1>&#39;throughput&#39;</span><span class=p>][</span><span class=s1>&#39;tokens_per_sec&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2> tok/s&quot;</span><span class=p>)</span>
</span><span id=__span-26-22><a id=__codelineno-26-22 name=__codelineno-26-22 href=#__codelineno-26-22></a>
</span><span id=__span-26-23><a id=__codelineno-26-23 name=__codelineno-26-23 href=#__codelineno-26-23></a>    <span class=n>engine</span><span class=o>.</span><span class=n>unload_model</span><span class=p>()</span>
</span></code></pre></div> <hr> <h2 id=optimization-checklist>Optimization Checklist<a class=headerlink href=#optimization-checklist title="Permanent link">&para;</a></h2> <h3 id=pre-deployment-checklist>Pre-Deployment Checklist<a class=headerlink href=#pre-deployment-checklist title="Permanent link">&para;</a></h3> <ul class=task-list> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled><span class=task-list-indicator></span></label> Use Q4_K_M quantization (best balance)</li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled><span class=task-list-indicator></span></label> Enable full GPU offload (<code>gpu_layers=99</code>)</li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled><span class=task-list-indicator></span></label> Set optimal context size (2048 for most cases)</li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled><span class=task-list-indicator></span></label> Configure batch sizes (512/128 for T4)</li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled><span class=task-list-indicator></span></label> Enable FlashAttention for long contexts</li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled><span class=task-list-indicator></span></label> Test with warmup runs</li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled><span class=task-list-indicator></span></label> Benchmark your specific use case</li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled><span class=task-list-indicator></span></label> Monitor VRAM usage</li> <li class=task-list-item><label class=task-list-control><input type=checkbox disabled><span class=task-list-indicator></span></label> Profile latency distribution (P50, P95, P99)</li> </ul> <h3 id=production-settings>Production Settings<a class=headerlink href=#production-settings title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-27-1><a id=__codelineno-27-1 name=__codelineno-27-1 href=#__codelineno-27-1></a><span class=kn>import</span><span class=w> </span><span class=nn>llcuda</span>
</span><span id=__span-27-2><a id=__codelineno-27-2 name=__codelineno-27-2 href=#__codelineno-27-2></a><span class=kn>from</span><span class=w> </span><span class=nn>llcuda.utils</span><span class=w> </span><span class=kn>import</span> <span class=n>auto_configure_for_model</span>
</span><span id=__span-27-3><a id=__codelineno-27-3 name=__codelineno-27-3 href=#__codelineno-27-3></a><span class=kn>from</span><span class=w> </span><span class=nn>pathlib</span><span class=w> </span><span class=kn>import</span> <span class=n>Path</span>
</span><span id=__span-27-4><a id=__codelineno-27-4 name=__codelineno-27-4 href=#__codelineno-27-4></a>
</span><span id=__span-27-5><a id=__codelineno-27-5 name=__codelineno-27-5 href=#__codelineno-27-5></a><span class=c1># Step 1: Verify GPU</span>
</span><span id=__span-27-6><a id=__codelineno-27-6 name=__codelineno-27-6 href=#__codelineno-27-6></a><span class=n>compat</span> <span class=o>=</span> <span class=n>llcuda</span><span class=o>.</span><span class=n>check_gpu_compatibility</span><span class=p>()</span>
</span><span id=__span-27-7><a id=__codelineno-27-7 name=__codelineno-27-7 href=#__codelineno-27-7></a><span class=k>assert</span> <span class=n>compat</span><span class=p>[</span><span class=s1>&#39;compatible&#39;</span><span class=p>],</span> <span class=s2>&quot;GPU not compatible&quot;</span>
</span><span id=__span-27-8><a id=__codelineno-27-8 name=__codelineno-27-8 href=#__codelineno-27-8></a>
</span><span id=__span-27-9><a id=__codelineno-27-9 name=__codelineno-27-9 href=#__codelineno-27-9></a><span class=c1># Step 2: Auto-configure</span>
</span><span id=__span-27-10><a id=__codelineno-27-10 name=__codelineno-27-10 href=#__codelineno-27-10></a><span class=n>model_path</span> <span class=o>=</span> <span class=n>Path</span><span class=p>(</span><span class=s2>&quot;model.gguf&quot;</span><span class=p>)</span>
</span><span id=__span-27-11><a id=__codelineno-27-11 name=__codelineno-27-11 href=#__codelineno-27-11></a><span class=n>settings</span> <span class=o>=</span> <span class=n>auto_configure_for_model</span><span class=p>(</span><span class=n>model_path</span><span class=p>)</span>
</span><span id=__span-27-12><a id=__codelineno-27-12 name=__codelineno-27-12 href=#__codelineno-27-12></a>
</span><span id=__span-27-13><a id=__codelineno-27-13 name=__codelineno-27-13 href=#__codelineno-27-13></a><span class=c1># Step 3: Override for production</span>
</span><span id=__span-27-14><a id=__codelineno-27-14 name=__codelineno-27-14 href=#__codelineno-27-14></a><span class=n>settings</span><span class=p>[</span><span class=s1>&#39;n_parallel&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=mi>4</span>      <span class=c1># Handle concurrent requests</span>
</span><span id=__span-27-15><a id=__codelineno-27-15 name=__codelineno-27-15 href=#__codelineno-27-15></a><span class=n>settings</span><span class=p>[</span><span class=s1>&#39;silent&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=kc>True</span>       <span class=c1># Clean logs</span>
</span><span id=__span-27-16><a id=__codelineno-27-16 name=__codelineno-27-16 href=#__codelineno-27-16></a>
</span><span id=__span-27-17><a id=__codelineno-27-17 name=__codelineno-27-17 href=#__codelineno-27-17></a><span class=c1># Step 4: Load</span>
</span><span id=__span-27-18><a id=__codelineno-27-18 name=__codelineno-27-18 href=#__codelineno-27-18></a><span class=n>engine</span> <span class=o>=</span> <span class=n>llcuda</span><span class=o>.</span><span class=n>InferenceEngine</span><span class=p>()</span>
</span><span id=__span-27-19><a id=__codelineno-27-19 name=__codelineno-27-19 href=#__codelineno-27-19></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=nb>str</span><span class=p>(</span><span class=n>model_path</span><span class=p>),</span> <span class=o>**</span><span class=n>settings</span><span class=p>)</span>
</span><span id=__span-27-20><a id=__codelineno-27-20 name=__codelineno-27-20 href=#__codelineno-27-20></a>
</span><span id=__span-27-21><a id=__codelineno-27-21 name=__codelineno-27-21 href=#__codelineno-27-21></a><span class=c1># Step 5: Warmup</span>
</span><span id=__span-27-22><a id=__codelineno-27-22 name=__codelineno-27-22 href=#__codelineno-27-22></a><span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>5</span><span class=p>):</span>
</span><span id=__span-27-23><a id=__codelineno-27-23 name=__codelineno-27-23 href=#__codelineno-27-23></a>    <span class=n>engine</span><span class=o>.</span><span class=n>infer</span><span class=p>(</span><span class=s2>&quot;Warmup&quot;</span><span class=p>,</span> <span class=n>max_tokens</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>
</span><span id=__span-27-24><a id=__codelineno-27-24 name=__codelineno-27-24 href=#__codelineno-27-24></a>
</span><span id=__span-27-25><a id=__codelineno-27-25 name=__codelineno-27-25 href=#__codelineno-27-25></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;✅ Production deployment ready!&quot;</span><span class=p>)</span>
</span></code></pre></div> <hr> <h2 id=common-optimization-pitfalls>Common Optimization Pitfalls<a class=headerlink href=#common-optimization-pitfalls title="Permanent link">&para;</a></h2> <h3 id=dont-do-this>❌ Don't Do This<a class=headerlink href=#dont-do-this title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-28-1><a id=__codelineno-28-1 name=__codelineno-28-1 href=#__codelineno-28-1></a><span class=c1># TOO SMALL: Limits performance</span>
</span><span id=__span-28-2><a id=__codelineno-28-2 name=__codelineno-28-2 href=#__codelineno-28-2></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=n>model_path</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>64</span><span class=p>,</span> <span class=n>ubatch_size</span><span class=o>=</span><span class=mi>16</span><span class=p>)</span>
</span><span id=__span-28-3><a id=__codelineno-28-3 name=__codelineno-28-3 href=#__codelineno-28-3></a>
</span><span id=__span-28-4><a id=__codelineno-28-4 name=__codelineno-28-4 href=#__codelineno-28-4></a><span class=c1># TOO LARGE: Wastes VRAM</span>
</span><span id=__span-28-5><a id=__codelineno-28-5 name=__codelineno-28-5 href=#__codelineno-28-5></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=n>model_path</span><span class=p>,</span> <span class=n>ctx_size</span><span class=o>=</span><span class=mi>32768</span><span class=p>)</span>
</span><span id=__span-28-6><a id=__codelineno-28-6 name=__codelineno-28-6 href=#__codelineno-28-6></a>
</span><span id=__span-28-7><a id=__codelineno-28-7 name=__codelineno-28-7 href=#__codelineno-28-7></a><span class=c1># PARTIAL OFFLOAD: When full offload possible</span>
</span><span id=__span-28-8><a id=__codelineno-28-8 name=__codelineno-28-8 href=#__codelineno-28-8></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=n>model_path</span><span class=p>,</span> <span class=n>gpu_layers</span><span class=o>=</span><span class=mi>20</span><span class=p>)</span>  <span class=c1># Use 99 instead</span>
</span><span id=__span-28-9><a id=__codelineno-28-9 name=__codelineno-28-9 href=#__codelineno-28-9></a>
</span><span id=__span-28-10><a id=__codelineno-28-10 name=__codelineno-28-10 href=#__codelineno-28-10></a><span class=c1># NO WARMUP: First inference is slow</span>
</span><span id=__span-28-11><a id=__codelineno-28-11 name=__codelineno-28-11 href=#__codelineno-28-11></a><span class=n>result</span> <span class=o>=</span> <span class=n>engine</span><span class=o>.</span><span class=n>infer</span><span class=p>(</span><span class=n>prompt</span><span class=p>)</span>  <span class=c1># Add warmup first</span>
</span></code></pre></div> <h3 id=do-this-instead>✅ Do This Instead<a class=headerlink href=#do-this-instead title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-29-1><a id=__codelineno-29-1 name=__codelineno-29-1 href=#__codelineno-29-1></a><span class=c1># Optimal settings</span>
</span><span id=__span-29-2><a id=__codelineno-29-2 name=__codelineno-29-2 href=#__codelineno-29-2></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-29-3><a id=__codelineno-29-3 name=__codelineno-29-3 href=#__codelineno-29-3></a>    <span class=n>model_path</span><span class=p>,</span>
</span><span id=__span-29-4><a id=__codelineno-29-4 name=__codelineno-29-4 href=#__codelineno-29-4></a>    <span class=n>gpu_layers</span><span class=o>=</span><span class=mi>99</span><span class=p>,</span>
</span><span id=__span-29-5><a id=__codelineno-29-5 name=__codelineno-29-5 href=#__codelineno-29-5></a>    <span class=n>ctx_size</span><span class=o>=</span><span class=mi>2048</span><span class=p>,</span>
</span><span id=__span-29-6><a id=__codelineno-29-6 name=__codelineno-29-6 href=#__codelineno-29-6></a>    <span class=n>batch_size</span><span class=o>=</span><span class=mi>512</span><span class=p>,</span>
</span><span id=__span-29-7><a id=__codelineno-29-7 name=__codelineno-29-7 href=#__codelineno-29-7></a>    <span class=n>ubatch_size</span><span class=o>=</span><span class=mi>128</span><span class=p>,</span>
</span><span id=__span-29-8><a id=__codelineno-29-8 name=__codelineno-29-8 href=#__codelineno-29-8></a>    <span class=n>silent</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-29-9><a id=__codelineno-29-9 name=__codelineno-29-9 href=#__codelineno-29-9></a><span class=p>)</span>
</span><span id=__span-29-10><a id=__codelineno-29-10 name=__codelineno-29-10 href=#__codelineno-29-10></a>
</span><span id=__span-29-11><a id=__codelineno-29-11 name=__codelineno-29-11 href=#__codelineno-29-11></a><span class=c1># Warmup</span>
</span><span id=__span-29-12><a id=__codelineno-29-12 name=__codelineno-29-12 href=#__codelineno-29-12></a><span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>3</span><span class=p>):</span>
</span><span id=__span-29-13><a id=__codelineno-29-13 name=__codelineno-29-13 href=#__codelineno-29-13></a>    <span class=n>engine</span><span class=o>.</span><span class=n>infer</span><span class=p>(</span><span class=s2>&quot;Warmup&quot;</span><span class=p>,</span> <span class=n>max_tokens</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>
</span><span id=__span-29-14><a id=__codelineno-29-14 name=__codelineno-29-14 href=#__codelineno-29-14></a>
</span><span id=__span-29-15><a id=__codelineno-29-15 name=__codelineno-29-15 href=#__codelineno-29-15></a><span class=c1># Production inference</span>
</span><span id=__span-29-16><a id=__codelineno-29-16 name=__codelineno-29-16 href=#__codelineno-29-16></a><span class=n>result</span> <span class=o>=</span> <span class=n>engine</span><span class=o>.</span><span class=n>infer</span><span class=p>(</span><span class=n>prompt</span><span class=p>,</span> <span class=n>max_tokens</span><span class=o>=</span><span class=mi>200</span><span class=p>)</span>
</span></code></pre></div> <hr> <h2 id=see-also>See Also<a class=headerlink href=#see-also title="Permanent link">&para;</a></h2> <ul> <li><a href=../benchmarks/ >Benchmarks</a> - Performance data</li> <li><a href=../t4-results/ >T4 Results</a> - Detailed T4 analysis</li> <li><a href=../../guides/model-selection/ >Model Selection</a> - Choosing models</li> <li><a href=../../api/device/ >Device API</a> - GPU management</li> <li><a href=../../guides/troubleshooting/ >Troubleshooting</a> - Common issues</li> </ul> <form class=md-feedback name=feedback hidden> <fieldset> <legend class=md-feedback__title> Was this page helpful? </legend> <div class=md-feedback__inner> <div class=md-feedback__list> <button class="md-feedback__icon md-icon" type=submit title="This page was helpful" data-md-value=1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m7 0c0 .8-.7 1.5-1.5 1.5S14 10.3 14 9.5 14.7 8 15.5 8s1.5.7 1.5 1.5m-5 7.73c-1.75 0-3.29-.73-4.19-1.81L9.23 14c.45.72 1.52 1.23 2.77 1.23s2.32-.51 2.77-1.23l1.42 1.42c-.9 1.08-2.44 1.81-4.19 1.81"/></svg> </button> <button class="md-feedback__icon md-icon" type=submit title="This page could be improved" data-md-value=0> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10m-6.5-4c.8 0 1.5.7 1.5 1.5s-.7 1.5-1.5 1.5-1.5-.7-1.5-1.5.7-1.5 1.5-1.5M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m2 4.5c1.75 0 3.29.72 4.19 1.81l-1.42 1.42C14.32 16.5 13.25 16 12 16s-2.32.5-2.77 1.23l-1.42-1.42C8.71 14.72 10.25 14 12 14"/></svg> </button> </div> <div class=md-feedback__note> <div data-md-value=1 hidden> Thanks for your feedback! </div> <div data-md-value=0 hidden> Thanks for your feedback! Help us improve by <a href=https://github.com/waqasm86/llcuda/issues/new target=_blank rel=noopener>opening an issue</a>. </div> </div> </div> </fieldset> </form> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../t4-results/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Tesla T4 Results"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Tesla T4 Results </div> </div> </a> <a href=../../guides/model-selection/ class="md-footer__link md-footer__link--next" aria-label="Next: Model Selection"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Model Selection </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2024-2026 Waqas Muhammad </div> </div> <div class=md-social> <a href=https://github.com/waqasm86 target=_blank rel=noopener title="GitHub - waqasm86" class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=mailto:waqasm86@gmail.com target=_blank rel=noopener title="Email - waqasm86@gmail.com" class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M48 64C21.5 64 0 85.5 0 112c0 15.1 7.1 29.3 19.2 38.4l208 156a48 48 0 0 0 57.6 0l208-156c12.1-9.1 19.2-23.3 19.2-38.4 0-26.5-21.5-48-48-48zM0 196v188c0 35.3 28.7 64 64 64h384c35.3 0 64-28.7 64-64V196L313.6 344.8c-34.1 25.6-81.1 25.6-115.2 0z"/></svg> </a> <a href=https://www.linkedin.com/in/waqasm86 target=_blank rel=noopener title="LinkedIn - Waqas Muhammad" class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <div class=md-consent data-md-component=consent id=__consent hidden> <div class=md-consent__overlay></div> <aside class=md-consent__inner> <form class="md-consent__form md-grid md-typeset" name=consent> <h4>Cookie consent</h4> <p>We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they're searching for. With your consent, you're helping us to make our documentation better.</p> <input class=md-toggle type=checkbox id=__settings> <div class=md-consent__settings> <ul class=task-list> <li class=task-list-item> <label class=task-list-control> <input type=checkbox name=analytics checked> <span class=task-list-indicator></span> Google Analytics </label> </li> <li class=task-list-item> <label class=task-list-control> <input type=checkbox name=github checked> <span class=task-list-indicator></span> GitHub </label> </li> </ul> </div> <div class=md-consent__controls> <button class="md-button md-button--primary">Accept</button> <label class=md-button for=__settings>Manage settings</label> </div> </form> </aside> </div> <script>var consent=__md_get("__consent");if(consent)for(var input of document.forms.consent.elements)input.name&&(input.checked=consent[input.name]||!1);else"file:"!==location.protocol&&setTimeout((function(){document.querySelector("[data-md-component=consent]").hidden=!1}),250);var form=document.forms.consent;for(var action of["submit","reset"])form.addEventListener(action,(function(e){if(e.preventDefault(),"reset"===e.type)for(var n of document.forms.consent.elements)n.name&&(n.checked=!1);__md_set("__consent",Object.fromEntries(Array.from(new FormData(form).keys()).map((function(e){return[e,!0]})))),location.hash="",location.reload()}))</script> <script id=__config type=application/json>{"annotate": null, "base": "../..", "features": ["announce.dismiss", "content.code.annotate", "content.code.copy", "content.tabs.link", "content.tooltips", "header.autohide", "navigation.expand", "navigation.footer", "navigation.indexes", "navigation.instant", "navigation.instant.prefetch", "navigation.instant.progress", "navigation.path", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow", "toc.integrate"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": "latest", "provider": "mike"}}</script> <script src=../../assets/javascripts/bundle.79ae519e.min.js></script> <script src=../../javascripts/mathjax.js></script> <script src=../../javascripts/schema.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>