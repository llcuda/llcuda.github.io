<!doctype html><html lang=en class=no-js> <head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="Fast LLM inference on Tesla T4 GPUs with CUDA 12. Complete Unsloth integration, 29 quantization formats, CUDA Graphs, Triton kernels, FlashAttention. Verified 134 tokens/sec on Gemma 3-1B. Perfect for Google Colab and production deployment."><meta name=author content="Waqas Muhammad"><link href=https://llcuda.github.io/api/device/ rel=canonical><link href=../models/ rel=prev><link href=../examples/ rel=next><link rel=icon href=../../assets/images/logo.svg><meta name=generator content="mkdocs-1.6.1, mkdocs-material-9.7.1"><title>GPU & Device - llcuda v2.1.0 - Tesla T4 CUDA Inference</title><link rel=stylesheet href=../../assets/stylesheets/main.484c7ddc.min.css><link rel=stylesheet href=../../assets/stylesheets/palette.ab4e12ef.min.css><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link rel=stylesheet href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback"><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><link rel=stylesheet href=../../stylesheets/extra.css><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script><script id=__analytics>function __md_analytics(){function e(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],e("js",new Date),e("config","G-XXXXXXXXXX"),document.addEventListener("DOMContentLoaded",(function(){document.forms.search&&document.forms.search.query.addEventListener("blur",(function(){this.value&&e("event","search",{search_term:this.value})}));document$.subscribe((function(){var t=document.forms.feedback;if(void 0!==t)for(var a of t.querySelectorAll("[type=submit]"))a.addEventListener("click",(function(a){a.preventDefault();var n=document.location.pathname,d=this.getAttribute("data-md-value");e("event","feedback",{page:n,data:d}),t.firstElementChild.disabled=!0;var r=t.querySelector(".md-feedback__note [data-md-value='"+d+"']");r&&(r.hidden=!1)})),t.hidden=!1})),location$.subscribe((function(t){e("config","G-XXXXXXXXXX",{page_path:t.pathname})}))}));var t=document.createElement("script");t.async=!0,t.src="https://www.googletagmanager.com/gtag/js?id=G-XXXXXXXXXX",document.getElementById("__analytics").insertAdjacentElement("afterEnd",t)}</script><script>if("undefined"!=typeof __md_analytics){var consent=__md_get("__consent");consent&&consent.analytics&&__md_analytics()}</script></head> <body dir=ltr data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=deep-purple> <input class=md-toggle data-md-toggle=drawer type=checkbox id=__drawer autocomplete=off> <input class=md-toggle data-md-toggle=search type=checkbox id=__search autocomplete=off> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a href=#gpu-device-management class=md-skip> Skip to content </a> </div> <div data-md-component=announce> </div> <div data-md-color-scheme=default data-md-component=outdated hidden> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav class="md-header__inner md-grid" aria-label=Header> <a href=../.. title="llcuda v2.1.0 - Tesla T4 CUDA Inference" class="md-header__button md-logo" aria-label="llcuda v2.1.0 - Tesla T4 CUDA Inference" data-md-component=logo> <img src=../../assets/images/logo.svg alt=logo> </a> <label class="md-header__button md-icon" for=__drawer> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"/></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> llcuda v2.1.0 - Tesla T4 CUDA Inference </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> GPU & Device </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input class=md-option data-md-color-media data-md-color-scheme=default data-md-color-primary=indigo data-md-color-accent=deep-purple aria-label="Switch to dark mode" type=radio name=__palette id=__palette_0> <label class="md-header__button md-icon" title="Switch to dark mode" for=__palette_1 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> <input class=md-option data-md-color-media data-md-color-scheme=slate data-md-color-primary=indigo data-md-color-accent=deep-purple aria-label="Switch to light mode" type=radio name=__palette id=__palette_1> <label class="md-header__button md-icon" title="Switch to light mode" for=__palette_0 hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"/></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <label class="md-header__button md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input type=text class=md-search__input name=query aria-label=Search placeholder=Search autocapitalize=off autocorrect=off autocomplete=off spellcheck=false data-md-component=search-query required> <label class="md-search__icon md-icon" for=__search> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"/></svg> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </label> <nav class=md-search__options aria-label=Search> <a href=javascript:void(0) class="md-search__icon md-icon" title=Share aria-label=Share data-clipboard data-clipboard-text data-md-component=search-share tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"/></svg> </a> <button type=reset class="md-search__icon md-icon" title=Clear aria-label=Clear tabindex=-1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"/></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap tabindex=0 data-md-scrollfix> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a href=https://github.com/waqasm86/llcuda title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> waqasm86/llcuda </div> </a> </div> </nav> <nav class=md-tabs aria-label=Tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=../.. class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a href=../../guides/quickstart/ class=md-tabs__link> Getting Started </a> </li> <li class=md-tabs__item> <a href=../../tutorials/gemma-3-1b-colab/ class=md-tabs__link> Tutorials </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a href=../overview/ class=md-tabs__link> API Reference </a> </li> <li class=md-tabs__item> <a href=../../performance/benchmarks/ class=md-tabs__link> Performance </a> </li> <li class=md-tabs__item> <a href=../../guides/model-selection/ class=md-tabs__link> Guides </a> </li> <li class=md-tabs__item> <a href=../../notebooks/ class=md-tabs__link> Notebooks </a> </li> <li class=md-tabs__item> <a href=https://github.com/waqasm86/llcuda class=md-tabs__link> Links </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav class="md-nav md-nav--primary md-nav--lifted md-nav--integrated" aria-label=Navigation data-md-level=0> <label class=md-nav__title for=__drawer> <a href=../.. title="llcuda v2.1.0 - Tesla T4 CUDA Inference" class="md-nav__button md-logo" aria-label="llcuda v2.1.0 - Tesla T4 CUDA Inference" data-md-component=logo> <img src=../../assets/images/logo.svg alt=logo> </a> llcuda v2.1.0 - Tesla T4 CUDA Inference </label> <div class=md-nav__source> <a href=https://github.com/waqasm86/llcuda title="Go to repository" class=md-source data-md-component=source> <div class="md-source__icon md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M439.6 236.1 244 40.5c-5.4-5.5-12.8-8.5-20.4-8.5s-15 3-20.4 8.4L162.5 81l51.5 51.5c27.1-9.1 52.7 16.8 43.4 43.7l49.7 49.7c34.2-11.8 61.2 31 35.5 56.7-26.5 26.5-70.2-2.9-56-37.3L240.3 199v121.9c25.3 12.5 22.3 41.8 9.1 55-6.4 6.4-15.2 10.1-24.3 10.1s-17.8-3.6-24.3-10.1c-17.6-17.6-11.1-46.9 11.2-56v-123c-20.8-8.5-24.6-30.7-18.6-45L142.6 101 8.5 235.1C3 240.6 0 247.9 0 255.5s3 15 8.5 20.4l195.6 195.7c5.4 5.4 12.7 8.4 20.4 8.4s15-3 20.4-8.4l194.7-194.7c5.4-5.4 8.4-12.8 8.4-20.4s-3-15-8.4-20.4"/></svg> </div> <div class=md-source__repository> waqasm86/llcuda </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../.. class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_2> <label class=md-nav__link for=__nav_2 id=__nav_2_label tabindex=0> <span class=md-ellipsis> Getting Started </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_2_label aria-expanded=false> <label class=md-nav__title for=__nav_2> <span class="md-nav__icon md-icon"></span> Getting Started </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../guides/quickstart/ class=md-nav__link> <span class=md-ellipsis> Quick Start </span> </a> </li> <li class=md-nav__item> <a href=../../guides/installation/ class=md-nav__link> <span class=md-ellipsis> Installation </span> </a> </li> <li class=md-nav__item> <a href=../../guides/first-steps/ class=md-nav__link> <span class=md-ellipsis> First Steps </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex=0> <span class=md-ellipsis> Tutorials </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_3_label aria-expanded=false> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Tutorials </label> <ul class=md-nav__list data-md-scrollfix> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_3_1> <label class=md-nav__link for=__nav_3_1 id=__nav_3_1_label tabindex=0> <span class=md-ellipsis> Google Colab </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=2 aria-labelledby=__nav_3_1_label aria-expanded=false> <label class=md-nav__title for=__nav_3_1> <span class="md-nav__icon md-icon"></span> Google Colab </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../tutorials/gemma-3-1b-colab/ class=md-nav__link> <span class=md-ellipsis> Gemma 3-1B Tutorial </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/gemma-3-1b-executed/ class=md-nav__link> <span class=md-ellipsis> Executed Example </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/build-binaries/ class=md-nav__link> <span class=md-ellipsis> Build Binaries </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../../tutorials/unsloth-integration/ class=md-nav__link> <span class=md-ellipsis> Unsloth Integration </span> </a> </li> <li class=md-nav__item> <a href=../../tutorials/performance/ class=md-nav__link> <span class=md-ellipsis> Performance Optimization </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input class="md-nav__toggle md-toggle " type=checkbox id=__nav_4 checked> <label class=md-nav__link for=__nav_4 id=__nav_4_label tabindex> <span class=md-ellipsis> API Reference </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_4_label aria-expanded=true> <label class=md-nav__title for=__nav_4> <span class="md-nav__icon md-icon"></span> API Reference </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../overview/ class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class=md-nav__item> <a href=../new-apis/ class=md-nav__link> <span class=md-ellipsis> New v2.1+ APIs </span> </a> </li> <li class=md-nav__item> <a href=../inference-engine/ class=md-nav__link> <span class=md-ellipsis> InferenceEngine </span> </a> </li> <li class=md-nav__item> <a href=../models/ class=md-nav__link> <span class=md-ellipsis> Models & GGUF </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" type=checkbox id=__toc> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> GPU & Device </span> <span class="md-nav__icon md-icon"></span> </label> <a href=./ class="md-nav__link md-nav__link--active"> <span class=md-ellipsis> GPU & Device </span> </a> <nav class="md-nav md-nav--secondary" aria-label="On this page"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> On this page </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a href=#overview class=md-nav__link> <span class=md-ellipsis> Overview </span> </a> </li> <li class=md-nav__item> <a href=#core-functions class=md-nav__link> <span class=md-ellipsis> Core Functions </span> </a> <nav class=md-nav aria-label="Core Functions"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#check_gpu_compatibility class=md-nav__link> <span class=md-ellipsis> check_gpu_compatibility() </span> </a> </li> <li class=md-nav__item> <a href=#detect_cuda class=md-nav__link> <span class=md-ellipsis> detect_cuda() </span> </a> </li> <li class=md-nav__item> <a href=#get_cuda_device_info class=md-nav__link> <span class=md-ellipsis> get_cuda_device_info() </span> </a> </li> <li class=md-nav__item> <a href=#check_cuda_available class=md-nav__link> <span class=md-ellipsis> check_cuda_available() </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#supported-gpus class=md-nav__link> <span class=md-ellipsis> Supported GPUs </span> </a> <nav class=md-nav aria-label="Supported GPUs"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#architecture-support class=md-nav__link> <span class=md-ellipsis> Architecture Support </span> </a> </li> <li class=md-nav__item> <a href=#popular-gpus class=md-nav__link> <span class=md-ellipsis> Popular GPUs </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#vram-management class=md-nav__link> <span class=md-ellipsis> VRAM Management </span> </a> <nav class=md-nav aria-label="VRAM Management"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#get-available-vram class=md-nav__link> <span class=md-ellipsis> Get Available VRAM </span> </a> </li> <li class=md-nav__item> <a href=#vram-recommendations class=md-nav__link> <span class=md-ellipsis> VRAM Recommendations </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#auto-configuration class=md-nav__link> <span class=md-ellipsis> Auto-Configuration </span> </a> <nav class=md-nav aria-label=Auto-Configuration> <ul class=md-nav__list> <li class=md-nav__item> <a href=#auto_configure_for_model class=md-nav__link> <span class=md-ellipsis> auto_configure_for_model() </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#platform-detection class=md-nav__link> <span class=md-ellipsis> Platform Detection </span> </a> </li> <li class=md-nav__item> <a href=#multi-gpu-support class=md-nav__link> <span class=md-ellipsis> Multi-GPU Support </span> </a> <nav class=md-nav aria-label="Multi-GPU Support"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#selecting-specific-gpu class=md-nav__link> <span class=md-ellipsis> Selecting Specific GPU </span> </a> </li> <li class=md-nav__item> <a href=#checking-multiple-gpus class=md-nav__link> <span class=md-ellipsis> Checking Multiple GPUs </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#environment-setup class=md-nav__link> <span class=md-ellipsis> Environment Setup </span> </a> <nav class=md-nav aria-label="Environment Setup"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#setup_environment class=md-nav__link> <span class=md-ellipsis> setup_environment() </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#system-information class=md-nav__link> <span class=md-ellipsis> System Information </span> </a> <nav class=md-nav aria-label="System Information"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#print_system_info class=md-nav__link> <span class=md-ellipsis> print_system_info() </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#common-patterns class=md-nav__link> <span class=md-ellipsis> Common Patterns </span> </a> <nav class=md-nav aria-label="Common Patterns"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#complete-gpu-verification class=md-nav__link> <span class=md-ellipsis> Complete GPU Verification </span> </a> </li> <li class=md-nav__item> <a href=#auto-configure-and-load class=md-nav__link> <span class=md-ellipsis> Auto-Configure and Load </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#error-handling class=md-nav__link> <span class=md-ellipsis> Error Handling </span> </a> <nav class=md-nav aria-label="Error Handling"> <ul class=md-nav__list> <li class=md-nav__item> <a href=#handle-no-gpu class=md-nav__link> <span class=md-ellipsis> Handle No GPU </span> </a> </li> <li class=md-nav__item> <a href=#handle-insufficient-vram class=md-nav__link> <span class=md-ellipsis> Handle Insufficient VRAM </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=#see-also class=md-nav__link> <span class=md-ellipsis> See Also </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a href=../examples/ class=md-nav__link> <span class=md-ellipsis> Examples </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_5> <label class=md-nav__link for=__nav_5 id=__nav_5_label tabindex=0> <span class=md-ellipsis> Performance </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_5_label aria-expanded=false> <label class=md-nav__title for=__nav_5> <span class="md-nav__icon md-icon"></span> Performance </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../performance/benchmarks/ class=md-nav__link> <span class=md-ellipsis> Benchmarks </span> </a> </li> <li class=md-nav__item> <a href=../../performance/t4-results/ class=md-nav__link> <span class=md-ellipsis> Tesla T4 Results </span> </a> </li> <li class=md-nav__item> <a href=../../performance/optimization/ class=md-nav__link> <span class=md-ellipsis> Optimization Guide </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_6> <label class=md-nav__link for=__nav_6 id=__nav_6_label tabindex=0> <span class=md-ellipsis> Guides </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_6_label aria-expanded=false> <label class=md-nav__title for=__nav_6> <span class="md-nav__icon md-icon"></span> Guides </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../guides/model-selection/ class=md-nav__link> <span class=md-ellipsis> Model Selection </span> </a> </li> <li class=md-nav__item> <a href=../../guides/gguf-format/ class=md-nav__link> <span class=md-ellipsis> GGUF Format </span> </a> </li> <li class=md-nav__item> <a href=../../guides/troubleshooting/ class=md-nav__link> <span class=md-ellipsis> Troubleshooting </span> </a> </li> <li class=md-nav__item> <a href=../../guides/faq/ class=md-nav__link> <span class=md-ellipsis> FAQ </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_7> <div class="md-nav__link md-nav__container"> <a href=../../notebooks/ class="md-nav__link "> <span class=md-ellipsis> Notebooks </span> </a> <label class="md-nav__link " for=__nav_7 id=__nav_7_label tabindex=0> <span class="md-nav__icon md-icon"></span> </label> </div> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_7_label aria-expanded=false> <label class=md-nav__title for=__nav_7> <span class="md-nav__icon md-icon"></span> Notebooks </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=../../notebooks/colab/ class=md-nav__link> <span class=md-ellipsis> Colab Notebooks </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--nested"> <input class="md-nav__toggle md-toggle md-toggle--indeterminate" type=checkbox id=__nav_8> <label class=md-nav__link for=__nav_8 id=__nav_8_label tabindex=0> <span class=md-ellipsis> Links </span> <span class="md-nav__icon md-icon"></span> </label> <nav class=md-nav data-md-level=1 aria-labelledby=__nav_8_label aria-expanded=false> <label class=md-nav__title for=__nav_8> <span class="md-nav__icon md-icon"></span> Links </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=https://github.com/waqasm86/llcuda class=md-nav__link> <span class=md-ellipsis> GitHub Repository </span> </a> </li> <li class=md-nav__item> <a href=https://github.com/waqasm86/llcuda/releases class=md-nav__link> <span class=md-ellipsis> GitHub Releases </span> </a> </li> <li class=md-nav__item> <a href=https://github.com/waqasm86/llcuda/issues class=md-nav__link> <span class=md-ellipsis> Issues & Support </span> </a> </li> <li class=md-nav__item> <a href=https://github.com/waqasm86/llcuda/blob/main/CHANGELOG.md class=md-nav__link> <span class=md-ellipsis> Changelog </span> </a> </li> </ul> </nav> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <nav class=md-path aria-label=Navigation> <ol class=md-path__list> <li class=md-path__item> <a href=../.. class=md-path__link> <span class=md-ellipsis> Home </span> </a> </li> <li class=md-path__item> <a href=../overview/ class=md-path__link> <span class=md-ellipsis> API Reference </span> </a> </li> </ol> </nav> <article class="md-content__inner md-typeset"> <h1 id=gpu-device-management>GPU Device Management<a class=headerlink href=#gpu-device-management title="Permanent link">&para;</a></h1> <p>Complete API for GPU device detection, compatibility checking, and CUDA management in llcuda v2.1.0.</p> <h2 id=overview>Overview<a class=headerlink href=#overview title="Permanent link">&para;</a></h2> <p>llcuda provides comprehensive GPU device management functions to help you:</p> <ul> <li>Detect CUDA-capable GPUs</li> <li>Check compatibility with llcuda binaries</li> <li>Get device properties and VRAM information</li> <li>Configure optimal inference settings</li> <li>Handle multi-GPU environments</li> </ul> <h2 id=core-functions>Core Functions<a class=headerlink href=#core-functions title="Permanent link">&para;</a></h2> <h3 id=check_gpu_compatibility><code>check_gpu_compatibility()</code><a class=headerlink href=#check_gpu_compatibility title="Permanent link">&para;</a></h3> <p>Check if your GPU is compatible with llcuda binaries.</p> <p><strong>Signature:</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-0-1><a id=__codelineno-0-1 name=__codelineno-0-1 href=#__codelineno-0-1></a><span class=k>def</span><span class=w> </span><span class=nf>check_gpu_compatibility</span><span class=p>(</span><span class=n>min_compute_cap</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>5.0</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]</span>
</span></code></pre></div></p> <p><strong>Parameters:</strong> - <code>min_compute_cap</code> (float, optional): Minimum compute capability required. Default: 5.0</p> <p><strong>Returns:</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-1-1><a id=__codelineno-1-1 name=__codelineno-1-1 href=#__codelineno-1-1></a><span class=p>{</span>
</span><span id=__span-1-2><a id=__codelineno-1-2 name=__codelineno-1-2 href=#__codelineno-1-2></a>    <span class=s1>&#39;compatible&#39;</span><span class=p>:</span> <span class=nb>bool</span><span class=p>,</span>              <span class=c1># Whether GPU is compatible</span>
</span><span id=__span-1-3><a id=__codelineno-1-3 name=__codelineno-1-3 href=#__codelineno-1-3></a>    <span class=s1>&#39;compute_capability&#39;</span><span class=p>:</span> <span class=nb>float</span><span class=p>,</span>     <span class=c1># GPU compute capability (e.g., 7.5)</span>
</span><span id=__span-1-4><a id=__codelineno-1-4 name=__codelineno-1-4 href=#__codelineno-1-4></a>    <span class=s1>&#39;gpu_name&#39;</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>                 <span class=c1># GPU name (e.g., &quot;Tesla T4&quot;)</span>
</span><span id=__span-1-5><a id=__codelineno-1-5 name=__codelineno-1-5 href=#__codelineno-1-5></a>    <span class=s1>&#39;reason&#39;</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>                   <span class=c1># Explanation if not compatible</span>
</span><span id=__span-1-6><a id=__codelineno-1-6 name=__codelineno-1-6 href=#__codelineno-1-6></a>    <span class=s1>&#39;platform&#39;</span><span class=p>:</span> <span class=nb>str</span>                  <span class=c1># Detected platform (local/colab/kaggle)</span>
</span><span id=__span-1-7><a id=__codelineno-1-7 name=__codelineno-1-7 href=#__codelineno-1-7></a><span class=p>}</span>
</span></code></pre></div></p> <p><strong>Example:</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-2-1><a id=__codelineno-2-1 name=__codelineno-2-1 href=#__codelineno-2-1></a><span class=kn>import</span><span class=w> </span><span class=nn>llcuda</span>
</span><span id=__span-2-2><a id=__codelineno-2-2 name=__codelineno-2-2 href=#__codelineno-2-2></a>
</span><span id=__span-2-3><a id=__codelineno-2-3 name=__codelineno-2-3 href=#__codelineno-2-3></a><span class=c1># Check GPU compatibility</span>
</span><span id=__span-2-4><a id=__codelineno-2-4 name=__codelineno-2-4 href=#__codelineno-2-4></a><span class=n>compat</span> <span class=o>=</span> <span class=n>llcuda</span><span class=o>.</span><span class=n>check_gpu_compatibility</span><span class=p>()</span>
</span><span id=__span-2-5><a id=__codelineno-2-5 name=__codelineno-2-5 href=#__codelineno-2-5></a>
</span><span id=__span-2-6><a id=__codelineno-2-6 name=__codelineno-2-6 href=#__codelineno-2-6></a><span class=k>if</span> <span class=n>compat</span><span class=p>[</span><span class=s1>&#39;compatible&#39;</span><span class=p>]:</span>
</span><span id=__span-2-7><a id=__codelineno-2-7 name=__codelineno-2-7 href=#__codelineno-2-7></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;✅ </span><span class=si>{</span><span class=n>compat</span><span class=p>[</span><span class=s1>&#39;gpu_name&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2> is compatible!&quot;</span><span class=p>)</span>
</span><span id=__span-2-8><a id=__codelineno-2-8 name=__codelineno-2-8 href=#__codelineno-2-8></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;   Compute Capability: </span><span class=si>{</span><span class=n>compat</span><span class=p>[</span><span class=s1>&#39;compute_capability&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-2-9><a id=__codelineno-2-9 name=__codelineno-2-9 href=#__codelineno-2-9></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;   Platform: </span><span class=si>{</span><span class=n>compat</span><span class=p>[</span><span class=s1>&#39;platform&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-2-10><a id=__codelineno-2-10 name=__codelineno-2-10 href=#__codelineno-2-10></a><span class=k>else</span><span class=p>:</span>
</span><span id=__span-2-11><a id=__codelineno-2-11 name=__codelineno-2-11 href=#__codelineno-2-11></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;⚠️ </span><span class=si>{</span><span class=n>compat</span><span class=p>[</span><span class=s1>&#39;gpu_name&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2> is not compatible&quot;</span><span class=p>)</span>
</span><span id=__span-2-12><a id=__codelineno-2-12 name=__codelineno-2-12 href=#__codelineno-2-12></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;   Reason: </span><span class=si>{</span><span class=n>compat</span><span class=p>[</span><span class=s1>&#39;reason&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div></p> <p><strong>Output on Tesla T4:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-3-1><a id=__codelineno-3-1 name=__codelineno-3-1 href=#__codelineno-3-1></a>✅ Tesla T4 is compatible!
</span><span id=__span-3-2><a id=__codelineno-3-2 name=__codelineno-3-2 href=#__codelineno-3-2></a>   Compute Capability: 7.5
</span><span id=__span-3-3><a id=__codelineno-3-3 name=__codelineno-3-3 href=#__codelineno-3-3></a>   Platform: colab
</span></code></pre></div></p> <hr> <h3 id=detect_cuda><code>detect_cuda()</code><a class=headerlink href=#detect_cuda title="Permanent link">&para;</a></h3> <p>Detect CUDA installation and get detailed GPU information.</p> <p><strong>Signature:</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-4-1><a id=__codelineno-4-1 name=__codelineno-4-1 href=#__codelineno-4-1></a><span class=k>def</span><span class=w> </span><span class=nf>detect_cuda</span><span class=p>()</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]</span>
</span></code></pre></div></p> <p><strong>Returns:</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-5-1><a id=__codelineno-5-1 name=__codelineno-5-1 href=#__codelineno-5-1></a><span class=p>{</span>
</span><span id=__span-5-2><a id=__codelineno-5-2 name=__codelineno-5-2 href=#__codelineno-5-2></a>    <span class=s1>&#39;available&#39;</span><span class=p>:</span> <span class=nb>bool</span><span class=p>,</span>     <span class=c1># Whether CUDA is available</span>
</span><span id=__span-5-3><a id=__codelineno-5-3 name=__codelineno-5-3 href=#__codelineno-5-3></a>    <span class=s1>&#39;version&#39;</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>        <span class=c1># CUDA version (e.g., &quot;12.2&quot;)</span>
</span><span id=__span-5-4><a id=__codelineno-5-4 name=__codelineno-5-4 href=#__codelineno-5-4></a>    <span class=s1>&#39;gpus&#39;</span><span class=p>:</span> <span class=p>[</span>              <span class=c1># List of GPU information</span>
</span><span id=__span-5-5><a id=__codelineno-5-5 name=__codelineno-5-5 href=#__codelineno-5-5></a>        <span class=p>{</span>
</span><span id=__span-5-6><a id=__codelineno-5-6 name=__codelineno-5-6 href=#__codelineno-5-6></a>            <span class=s1>&#39;name&#39;</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>                  <span class=c1># GPU name</span>
</span><span id=__span-5-7><a id=__codelineno-5-7 name=__codelineno-5-7 href=#__codelineno-5-7></a>            <span class=s1>&#39;memory&#39;</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>                <span class=c1># Total VRAM (e.g., &quot;15360 MiB&quot;)</span>
</span><span id=__span-5-8><a id=__codelineno-5-8 name=__codelineno-5-8 href=#__codelineno-5-8></a>            <span class=s1>&#39;driver_version&#39;</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>        <span class=c1># NVIDIA driver version</span>
</span><span id=__span-5-9><a id=__codelineno-5-9 name=__codelineno-5-9 href=#__codelineno-5-9></a>            <span class=s1>&#39;compute_capability&#39;</span><span class=p>:</span> <span class=nb>str</span>     <span class=c1># Compute capability</span>
</span><span id=__span-5-10><a id=__codelineno-5-10 name=__codelineno-5-10 href=#__codelineno-5-10></a>        <span class=p>}</span>
</span><span id=__span-5-11><a id=__codelineno-5-11 name=__codelineno-5-11 href=#__codelineno-5-11></a>    <span class=p>]</span>
</span><span id=__span-5-12><a id=__codelineno-5-12 name=__codelineno-5-12 href=#__codelineno-5-12></a><span class=p>}</span>
</span></code></pre></div></p> <p><strong>Example:</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-6-1><a id=__codelineno-6-1 name=__codelineno-6-1 href=#__codelineno-6-1></a><span class=kn>import</span><span class=w> </span><span class=nn>llcuda</span>
</span><span id=__span-6-2><a id=__codelineno-6-2 name=__codelineno-6-2 href=#__codelineno-6-2></a>
</span><span id=__span-6-3><a id=__codelineno-6-3 name=__codelineno-6-3 href=#__codelineno-6-3></a><span class=n>cuda_info</span> <span class=o>=</span> <span class=n>llcuda</span><span class=o>.</span><span class=n>detect_cuda</span><span class=p>()</span>
</span><span id=__span-6-4><a id=__codelineno-6-4 name=__codelineno-6-4 href=#__codelineno-6-4></a>
</span><span id=__span-6-5><a id=__codelineno-6-5 name=__codelineno-6-5 href=#__codelineno-6-5></a><span class=k>if</span> <span class=n>cuda_info</span><span class=p>[</span><span class=s1>&#39;available&#39;</span><span class=p>]:</span>
</span><span id=__span-6-6><a id=__codelineno-6-6 name=__codelineno-6-6 href=#__codelineno-6-6></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;CUDA Version: </span><span class=si>{</span><span class=n>cuda_info</span><span class=p>[</span><span class=s1>&#39;version&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-6-7><a id=__codelineno-6-7 name=__codelineno-6-7 href=#__codelineno-6-7></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Number of GPUs: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>cuda_info</span><span class=p>[</span><span class=s1>&#39;gpus&#39;</span><span class=p>])</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-6-8><a id=__codelineno-6-8 name=__codelineno-6-8 href=#__codelineno-6-8></a>
</span><span id=__span-6-9><a id=__codelineno-6-9 name=__codelineno-6-9 href=#__codelineno-6-9></a>    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>gpu</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>cuda_info</span><span class=p>[</span><span class=s1>&#39;gpus&#39;</span><span class=p>]):</span>
</span><span id=__span-6-10><a id=__codelineno-6-10 name=__codelineno-6-10 href=#__codelineno-6-10></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>GPU </span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s2>:&quot;</span><span class=p>)</span>
</span><span id=__span-6-11><a id=__codelineno-6-11 name=__codelineno-6-11 href=#__codelineno-6-11></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Name: </span><span class=si>{</span><span class=n>gpu</span><span class=p>[</span><span class=s1>&#39;name&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-6-12><a id=__codelineno-6-12 name=__codelineno-6-12 href=#__codelineno-6-12></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  VRAM: </span><span class=si>{</span><span class=n>gpu</span><span class=p>[</span><span class=s1>&#39;memory&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-6-13><a id=__codelineno-6-13 name=__codelineno-6-13 href=#__codelineno-6-13></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Driver: </span><span class=si>{</span><span class=n>gpu</span><span class=p>[</span><span class=s1>&#39;driver_version&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-6-14><a id=__codelineno-6-14 name=__codelineno-6-14 href=#__codelineno-6-14></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Compute Capability: </span><span class=si>{</span><span class=n>gpu</span><span class=p>[</span><span class=s1>&#39;compute_capability&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-6-15><a id=__codelineno-6-15 name=__codelineno-6-15 href=#__codelineno-6-15></a><span class=k>else</span><span class=p>:</span>
</span><span id=__span-6-16><a id=__codelineno-6-16 name=__codelineno-6-16 href=#__codelineno-6-16></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;CUDA is not available&quot;</span><span class=p>)</span>
</span></code></pre></div></p> <p><strong>Output:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-7-1><a id=__codelineno-7-1 name=__codelineno-7-1 href=#__codelineno-7-1></a>CUDA Version: 12.2
</span><span id=__span-7-2><a id=__codelineno-7-2 name=__codelineno-7-2 href=#__codelineno-7-2></a>Number of GPUs: 1
</span><span id=__span-7-3><a id=__codelineno-7-3 name=__codelineno-7-3 href=#__codelineno-7-3></a>
</span><span id=__span-7-4><a id=__codelineno-7-4 name=__codelineno-7-4 href=#__codelineno-7-4></a>GPU 0:
</span><span id=__span-7-5><a id=__codelineno-7-5 name=__codelineno-7-5 href=#__codelineno-7-5></a>  Name: Tesla T4
</span><span id=__span-7-6><a id=__codelineno-7-6 name=__codelineno-7-6 href=#__codelineno-7-6></a>  VRAM: 15360 MiB
</span><span id=__span-7-7><a id=__codelineno-7-7 name=__codelineno-7-7 href=#__codelineno-7-7></a>  Driver: 535.104.05
</span><span id=__span-7-8><a id=__codelineno-7-8 name=__codelineno-7-8 href=#__codelineno-7-8></a>  Compute Capability: 7.5
</span></code></pre></div></p> <hr> <h3 id=get_cuda_device_info><code>get_cuda_device_info()</code><a class=headerlink href=#get_cuda_device_info title="Permanent link">&para;</a></h3> <p>Get simplified CUDA device information.</p> <p><strong>Signature:</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-8-1><a id=__codelineno-8-1 name=__codelineno-8-1 href=#__codelineno-8-1></a><span class=k>def</span><span class=w> </span><span class=nf>get_cuda_device_info</span><span class=p>()</span> <span class=o>-&gt;</span> <span class=n>Optional</span><span class=p>[</span><span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]]</span>
</span></code></pre></div></p> <p><strong>Returns:</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-9-1><a id=__codelineno-9-1 name=__codelineno-9-1 href=#__codelineno-9-1></a><span class=p>{</span>
</span><span id=__span-9-2><a id=__codelineno-9-2 name=__codelineno-9-2 href=#__codelineno-9-2></a>    <span class=s1>&#39;cuda_version&#39;</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span>   <span class=c1># CUDA version</span>
</span><span id=__span-9-3><a id=__codelineno-9-3 name=__codelineno-9-3 href=#__codelineno-9-3></a>    <span class=s1>&#39;gpus&#39;</span><span class=p>:</span> <span class=nb>list</span>          <span class=c1># List of GPU dictionaries</span>
</span><span id=__span-9-4><a id=__codelineno-9-4 name=__codelineno-9-4 href=#__codelineno-9-4></a><span class=p>}</span>
</span><span id=__span-9-5><a id=__codelineno-9-5 name=__codelineno-9-5 href=#__codelineno-9-5></a><span class=c1># Returns None if CUDA is not available</span>
</span></code></pre></div></p> <p><strong>Example:</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-10-1><a id=__codelineno-10-1 name=__codelineno-10-1 href=#__codelineno-10-1></a><span class=kn>import</span><span class=w> </span><span class=nn>llcuda</span>
</span><span id=__span-10-2><a id=__codelineno-10-2 name=__codelineno-10-2 href=#__codelineno-10-2></a>
</span><span id=__span-10-3><a id=__codelineno-10-3 name=__codelineno-10-3 href=#__codelineno-10-3></a><span class=n>device_info</span> <span class=o>=</span> <span class=n>llcuda</span><span class=o>.</span><span class=n>get_cuda_device_info</span><span class=p>()</span>
</span><span id=__span-10-4><a id=__codelineno-10-4 name=__codelineno-10-4 href=#__codelineno-10-4></a>
</span><span id=__span-10-5><a id=__codelineno-10-5 name=__codelineno-10-5 href=#__codelineno-10-5></a><span class=k>if</span> <span class=n>device_info</span><span class=p>:</span>
</span><span id=__span-10-6><a id=__codelineno-10-6 name=__codelineno-10-6 href=#__codelineno-10-6></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;CUDA: </span><span class=si>{</span><span class=n>device_info</span><span class=p>[</span><span class=s1>&#39;cuda_version&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-10-7><a id=__codelineno-10-7 name=__codelineno-10-7 href=#__codelineno-10-7></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;GPUs detected: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>device_info</span><span class=p>[</span><span class=s1>&#39;gpus&#39;</span><span class=p>])</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-10-8><a id=__codelineno-10-8 name=__codelineno-10-8 href=#__codelineno-10-8></a><span class=k>else</span><span class=p>:</span>
</span><span id=__span-10-9><a id=__codelineno-10-9 name=__codelineno-10-9 href=#__codelineno-10-9></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;No CUDA devices found&quot;</span><span class=p>)</span>
</span></code></pre></div></p> <hr> <h3 id=check_cuda_available><code>check_cuda_available()</code><a class=headerlink href=#check_cuda_available title="Permanent link">&para;</a></h3> <p>Quick check if CUDA is available.</p> <p><strong>Signature:</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-11-1><a id=__codelineno-11-1 name=__codelineno-11-1 href=#__codelineno-11-1></a><span class=k>def</span><span class=w> </span><span class=nf>check_cuda_available</span><span class=p>()</span> <span class=o>-&gt;</span> <span class=nb>bool</span>
</span></code></pre></div></p> <p><strong>Returns:</strong> - <code>True</code> if CUDA is available, <code>False</code> otherwise</p> <p><strong>Example:</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-12-1><a id=__codelineno-12-1 name=__codelineno-12-1 href=#__codelineno-12-1></a><span class=kn>import</span><span class=w> </span><span class=nn>llcuda</span>
</span><span id=__span-12-2><a id=__codelineno-12-2 name=__codelineno-12-2 href=#__codelineno-12-2></a>
</span><span id=__span-12-3><a id=__codelineno-12-3 name=__codelineno-12-3 href=#__codelineno-12-3></a><span class=k>if</span> <span class=n>llcuda</span><span class=o>.</span><span class=n>check_cuda_available</span><span class=p>():</span>
</span><span id=__span-12-4><a id=__codelineno-12-4 name=__codelineno-12-4 href=#__codelineno-12-4></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;✅ CUDA is available&quot;</span><span class=p>)</span>
</span><span id=__span-12-5><a id=__codelineno-12-5 name=__codelineno-12-5 href=#__codelineno-12-5></a>    <span class=c1># Proceed with GPU inference</span>
</span><span id=__span-12-6><a id=__codelineno-12-6 name=__codelineno-12-6 href=#__codelineno-12-6></a><span class=k>else</span><span class=p>:</span>
</span><span id=__span-12-7><a id=__codelineno-12-7 name=__codelineno-12-7 href=#__codelineno-12-7></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;❌ CUDA not available - CPU mode only&quot;</span><span class=p>)</span>
</span></code></pre></div></p> <hr> <h2 id=supported-gpus>Supported GPUs<a class=headerlink href=#supported-gpus title="Permanent link">&para;</a></h2> <p>llcuda binaries support NVIDIA GPUs with compute capability 5.0 and higher:</p> <h3 id=architecture-support>Architecture Support<a class=headerlink href=#architecture-support title="Permanent link">&para;</a></h3> <table> <thead> <tr> <th>Architecture</th> <th>Compute Cap</th> <th>Examples</th> <th>Status</th> </tr> </thead> <tbody> <tr> <td><strong>Maxwell</strong></td> <td>5.0 - 5.3</td> <td>GTX 900, Tesla M40</td> <td>✅ Supported</td> </tr> <tr> <td><strong>Pascal</strong></td> <td>6.0 - 6.2</td> <td>GTX 10xx, Tesla P100</td> <td>✅ Supported</td> </tr> <tr> <td><strong>Volta</strong></td> <td>7.0</td> <td>Tesla V100</td> <td>✅ Supported</td> </tr> <tr> <td><strong>Turing</strong></td> <td>7.5</td> <td>RTX 20xx, <strong>Tesla T4</strong>, GTX 16xx</td> <td>✅ Verified</td> </tr> <tr> <td><strong>Ampere</strong></td> <td>8.0 - 8.6</td> <td>RTX 30xx, A100</td> <td>✅ Supported</td> </tr> <tr> <td><strong>Ada Lovelace</strong></td> <td>8.9</td> <td>RTX 40xx</td> <td>✅ Supported</td> </tr> <tr> <td><strong>Hopper</strong></td> <td>9.0</td> <td>H100</td> <td>✅ Supported</td> </tr> </tbody> </table> <h3 id=popular-gpus>Popular GPUs<a class=headerlink href=#popular-gpus title="Permanent link">&para;</a></h3> <table> <thead> <tr> <th>GPU Model</th> <th>VRAM</th> <th>Compute Cap</th> <th>Recommended Model Size</th> </tr> </thead> <tbody> <tr> <td><strong>Tesla T4</strong></td> <td>15 GB</td> <td>7.5</td> <td>Up to 7B (Q4_K_M)</td> </tr> <tr> <td>RTX 3060</td> <td>12 GB</td> <td>8.6</td> <td>Up to 7B (Q4_K_M)</td> </tr> <tr> <td>RTX 3070</td> <td>8 GB</td> <td>8.6</td> <td>Up to 3B (Q4_K_M)</td> </tr> <tr> <td>RTX 3080</td> <td>10 GB</td> <td>8.6</td> <td>Up to 7B (Q4_K_M)</td> </tr> <tr> <td>RTX 3090</td> <td>24 GB</td> <td>8.6</td> <td>Up to 13B (Q4_K_M)</td> </tr> <tr> <td>RTX 4070</td> <td>12 GB</td> <td>8.9</td> <td>Up to 7B (Q4_K_M)</td> </tr> <tr> <td>RTX 4090</td> <td>24 GB</td> <td>8.9</td> <td>Up to 13B (Q4_K_M)</td> </tr> <tr> <td>A100</td> <td>40 GB</td> <td>8.0</td> <td>Up to 30B (Q4_K_M)</td> </tr> <tr> <td>A100</td> <td>80 GB</td> <td>8.0</td> <td>Up to 70B (Q4_K_M)</td> </tr> </tbody> </table> <hr> <h2 id=vram-management>VRAM Management<a class=headerlink href=#vram-management title="Permanent link">&para;</a></h2> <h3 id=get-available-vram>Get Available VRAM<a class=headerlink href=#get-available-vram title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-13-1><a id=__codelineno-13-1 name=__codelineno-13-1 href=#__codelineno-13-1></a><span class=kn>import</span><span class=w> </span><span class=nn>llcuda</span>
</span><span id=__span-13-2><a id=__codelineno-13-2 name=__codelineno-13-2 href=#__codelineno-13-2></a>
</span><span id=__span-13-3><a id=__codelineno-13-3 name=__codelineno-13-3 href=#__codelineno-13-3></a><span class=n>cuda_info</span> <span class=o>=</span> <span class=n>llcuda</span><span class=o>.</span><span class=n>detect_cuda</span><span class=p>()</span>
</span><span id=__span-13-4><a id=__codelineno-13-4 name=__codelineno-13-4 href=#__codelineno-13-4></a>
</span><span id=__span-13-5><a id=__codelineno-13-5 name=__codelineno-13-5 href=#__codelineno-13-5></a><span class=k>if</span> <span class=n>cuda_info</span><span class=p>[</span><span class=s1>&#39;available&#39;</span><span class=p>]</span> <span class=ow>and</span> <span class=n>cuda_info</span><span class=p>[</span><span class=s1>&#39;gpus&#39;</span><span class=p>]:</span>
</span><span id=__span-13-6><a id=__codelineno-13-6 name=__codelineno-13-6 href=#__codelineno-13-6></a>    <span class=n>gpu</span> <span class=o>=</span> <span class=n>cuda_info</span><span class=p>[</span><span class=s1>&#39;gpus&#39;</span><span class=p>][</span><span class=mi>0</span><span class=p>]</span>
</span><span id=__span-13-7><a id=__codelineno-13-7 name=__codelineno-13-7 href=#__codelineno-13-7></a>    <span class=n>vram_str</span> <span class=o>=</span> <span class=n>gpu</span><span class=p>[</span><span class=s1>&#39;memory&#39;</span><span class=p>]</span>
</span><span id=__span-13-8><a id=__codelineno-13-8 name=__codelineno-13-8 href=#__codelineno-13-8></a>
</span><span id=__span-13-9><a id=__codelineno-13-9 name=__codelineno-13-9 href=#__codelineno-13-9></a>    <span class=c1># Parse VRAM</span>
</span><span id=__span-13-10><a id=__codelineno-13-10 name=__codelineno-13-10 href=#__codelineno-13-10></a>    <span class=k>if</span> <span class=s1>&#39;GiB&#39;</span> <span class=ow>in</span> <span class=n>vram_str</span><span class=p>:</span>
</span><span id=__span-13-11><a id=__codelineno-13-11 name=__codelineno-13-11 href=#__codelineno-13-11></a>        <span class=n>vram_gb</span> <span class=o>=</span> <span class=nb>float</span><span class=p>(</span><span class=n>vram_str</span><span class=o>.</span><span class=n>split</span><span class=p>()[</span><span class=mi>0</span><span class=p>])</span>
</span><span id=__span-13-12><a id=__codelineno-13-12 name=__codelineno-13-12 href=#__codelineno-13-12></a>    <span class=k>elif</span> <span class=s1>&#39;MiB&#39;</span> <span class=ow>in</span> <span class=n>vram_str</span><span class=p>:</span>
</span><span id=__span-13-13><a id=__codelineno-13-13 name=__codelineno-13-13 href=#__codelineno-13-13></a>        <span class=n>vram_mb</span> <span class=o>=</span> <span class=nb>float</span><span class=p>(</span><span class=n>vram_str</span><span class=o>.</span><span class=n>split</span><span class=p>()[</span><span class=mi>0</span><span class=p>])</span>
</span><span id=__span-13-14><a id=__codelineno-13-14 name=__codelineno-13-14 href=#__codelineno-13-14></a>        <span class=n>vram_gb</span> <span class=o>=</span> <span class=n>vram_mb</span> <span class=o>/</span> <span class=mi>1024</span>
</span><span id=__span-13-15><a id=__codelineno-13-15 name=__codelineno-13-15 href=#__codelineno-13-15></a>
</span><span id=__span-13-16><a id=__codelineno-13-16 name=__codelineno-13-16 href=#__codelineno-13-16></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Available VRAM: </span><span class=si>{</span><span class=n>vram_gb</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2> GB&quot;</span><span class=p>)</span>
</span></code></pre></div> <h3 id=vram-recommendations>VRAM Recommendations<a class=headerlink href=#vram-recommendations title="Permanent link">&para;</a></h3> <p>Get recommended settings based on available VRAM:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-14-1><a id=__codelineno-14-1 name=__codelineno-14-1 href=#__codelineno-14-1></a><span class=kn>from</span><span class=w> </span><span class=nn>llcuda.utils</span><span class=w> </span><span class=kn>import</span> <span class=n>get_recommended_gpu_layers</span>
</span><span id=__span-14-2><a id=__codelineno-14-2 name=__codelineno-14-2 href=#__codelineno-14-2></a>
</span><span id=__span-14-3><a id=__codelineno-14-3 name=__codelineno-14-3 href=#__codelineno-14-3></a><span class=c1># For a 1.2 GB model with 15 GB VRAM</span>
</span><span id=__span-14-4><a id=__codelineno-14-4 name=__codelineno-14-4 href=#__codelineno-14-4></a><span class=n>gpu_layers</span> <span class=o>=</span> <span class=n>get_recommended_gpu_layers</span><span class=p>(</span>
</span><span id=__span-14-5><a id=__codelineno-14-5 name=__codelineno-14-5 href=#__codelineno-14-5></a>    <span class=n>model_size_gb</span><span class=o>=</span><span class=mf>1.2</span><span class=p>,</span>
</span><span id=__span-14-6><a id=__codelineno-14-6 name=__codelineno-14-6 href=#__codelineno-14-6></a>    <span class=n>vram_gb</span><span class=o>=</span><span class=mf>15.0</span>
</span><span id=__span-14-7><a id=__codelineno-14-7 name=__codelineno-14-7 href=#__codelineno-14-7></a><span class=p>)</span>
</span><span id=__span-14-8><a id=__codelineno-14-8 name=__codelineno-14-8 href=#__codelineno-14-8></a>
</span><span id=__span-14-9><a id=__codelineno-14-9 name=__codelineno-14-9 href=#__codelineno-14-9></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Recommended GPU layers: </span><span class=si>{</span><span class=n>gpu_layers</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-14-10><a id=__codelineno-14-10 name=__codelineno-14-10 href=#__codelineno-14-10></a><span class=c1># Output: 99 (full GPU offload)</span>
</span></code></pre></div> <p><strong>VRAM to GPU Layers Mapping:</strong></p> <table> <thead> <tr> <th>Available VRAM</th> <th>Model Size</th> <th>Recommended Layers</th> </tr> </thead> <tbody> <tr> <td>&gt;= 1.2x model</td> <td>Any</td> <td>99 (full offload)</td> </tr> <tr> <td>&gt;= 0.8x model</td> <td>Any</td> <td>40 (most layers)</td> </tr> <tr> <td>&gt;= 0.6x model</td> <td>Any</td> <td>30 (many layers)</td> </tr> <tr> <td>&gt;= 0.4x model</td> <td>Any</td> <td>20 (some layers)</td> </tr> <tr> <td>&gt;= 0.2x model</td> <td>Any</td> <td>10 (few layers)</td> </tr> <tr> <td>&lt; 0.2x model</td> <td>Any</td> <td>0 (CPU only)</td> </tr> </tbody> </table> <hr> <h2 id=auto-configuration>Auto-Configuration<a class=headerlink href=#auto-configuration title="Permanent link">&para;</a></h2> <h3 id=auto_configure_for_model><code>auto_configure_for_model()</code><a class=headerlink href=#auto_configure_for_model title="Permanent link">&para;</a></h3> <p>Automatically configure optimal settings for your GPU and model.</p> <p><strong>Signature:</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-15-1><a id=__codelineno-15-1 name=__codelineno-15-1 href=#__codelineno-15-1></a><span class=kn>from</span><span class=w> </span><span class=nn>llcuda.utils</span><span class=w> </span><span class=kn>import</span> <span class=n>auto_configure_for_model</span>
</span><span id=__span-15-2><a id=__codelineno-15-2 name=__codelineno-15-2 href=#__codelineno-15-2></a><span class=kn>from</span><span class=w> </span><span class=nn>pathlib</span><span class=w> </span><span class=kn>import</span> <span class=n>Path</span>
</span><span id=__span-15-3><a id=__codelineno-15-3 name=__codelineno-15-3 href=#__codelineno-15-3></a>
</span><span id=__span-15-4><a id=__codelineno-15-4 name=__codelineno-15-4 href=#__codelineno-15-4></a><span class=k>def</span><span class=w> </span><span class=nf>auto_configure_for_model</span><span class=p>(</span>
</span><span id=__span-15-5><a id=__codelineno-15-5 name=__codelineno-15-5 href=#__codelineno-15-5></a>    <span class=n>model_path</span><span class=p>:</span> <span class=n>Path</span><span class=p>,</span>
</span><span id=__span-15-6><a id=__codelineno-15-6 name=__codelineno-15-6 href=#__codelineno-15-6></a>    <span class=n>vram_gb</span><span class=p>:</span> <span class=n>Optional</span><span class=p>[</span><span class=nb>float</span><span class=p>]</span> <span class=o>=</span> <span class=kc>None</span>
</span><span id=__span-15-7><a id=__codelineno-15-7 name=__codelineno-15-7 href=#__codelineno-15-7></a><span class=p>)</span> <span class=o>-&gt;</span> <span class=n>Dict</span><span class=p>[</span><span class=nb>str</span><span class=p>,</span> <span class=n>Any</span><span class=p>]</span>
</span></code></pre></div></p> <p><strong>Parameters:</strong> - <code>model_path</code> (Path): Path to GGUF model file - <code>vram_gb</code> (float, optional): VRAM in GB (auto-detected if not provided)</p> <p><strong>Returns:</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-16-1><a id=__codelineno-16-1 name=__codelineno-16-1 href=#__codelineno-16-1></a><span class=p>{</span>
</span><span id=__span-16-2><a id=__codelineno-16-2 name=__codelineno-16-2 href=#__codelineno-16-2></a>    <span class=s1>&#39;gpu_layers&#39;</span><span class=p>:</span> <span class=nb>int</span><span class=p>,</span>      <span class=c1># Number of layers to offload</span>
</span><span id=__span-16-3><a id=__codelineno-16-3 name=__codelineno-16-3 href=#__codelineno-16-3></a>    <span class=s1>&#39;ctx_size&#39;</span><span class=p>:</span> <span class=nb>int</span><span class=p>,</span>        <span class=c1># Context window size</span>
</span><span id=__span-16-4><a id=__codelineno-16-4 name=__codelineno-16-4 href=#__codelineno-16-4></a>    <span class=s1>&#39;batch_size&#39;</span><span class=p>:</span> <span class=nb>int</span><span class=p>,</span>      <span class=c1># Batch size for processing</span>
</span><span id=__span-16-5><a id=__codelineno-16-5 name=__codelineno-16-5 href=#__codelineno-16-5></a>    <span class=s1>&#39;ubatch_size&#39;</span><span class=p>:</span> <span class=nb>int</span><span class=p>,</span>     <span class=c1># Micro-batch size</span>
</span><span id=__span-16-6><a id=__codelineno-16-6 name=__codelineno-16-6 href=#__codelineno-16-6></a>    <span class=s1>&#39;n_parallel&#39;</span><span class=p>:</span> <span class=nb>int</span>       <span class=c1># Parallel sequences</span>
</span><span id=__span-16-7><a id=__codelineno-16-7 name=__codelineno-16-7 href=#__codelineno-16-7></a><span class=p>}</span>
</span></code></pre></div></p> <p><strong>Example:</strong> <div class="language-python highlight"><pre><span></span><code><span id=__span-17-1><a id=__codelineno-17-1 name=__codelineno-17-1 href=#__codelineno-17-1></a><span class=kn>from</span><span class=w> </span><span class=nn>llcuda.utils</span><span class=w> </span><span class=kn>import</span> <span class=n>auto_configure_for_model</span>
</span><span id=__span-17-2><a id=__codelineno-17-2 name=__codelineno-17-2 href=#__codelineno-17-2></a><span class=kn>from</span><span class=w> </span><span class=nn>pathlib</span><span class=w> </span><span class=kn>import</span> <span class=n>Path</span>
</span><span id=__span-17-3><a id=__codelineno-17-3 name=__codelineno-17-3 href=#__codelineno-17-3></a>
</span><span id=__span-17-4><a id=__codelineno-17-4 name=__codelineno-17-4 href=#__codelineno-17-4></a><span class=c1># Auto-configure for model</span>
</span><span id=__span-17-5><a id=__codelineno-17-5 name=__codelineno-17-5 href=#__codelineno-17-5></a><span class=n>model_path</span> <span class=o>=</span> <span class=n>Path</span><span class=p>(</span><span class=s2>&quot;/path/to/model.gguf&quot;</span><span class=p>)</span>
</span><span id=__span-17-6><a id=__codelineno-17-6 name=__codelineno-17-6 href=#__codelineno-17-6></a><span class=n>settings</span> <span class=o>=</span> <span class=n>auto_configure_for_model</span><span class=p>(</span><span class=n>model_path</span><span class=p>)</span>
</span><span id=__span-17-7><a id=__codelineno-17-7 name=__codelineno-17-7 href=#__codelineno-17-7></a>
</span><span id=__span-17-8><a id=__codelineno-17-8 name=__codelineno-17-8 href=#__codelineno-17-8></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Recommended settings:&quot;</span><span class=p>)</span>
</span><span id=__span-17-9><a id=__codelineno-17-9 name=__codelineno-17-9 href=#__codelineno-17-9></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  GPU Layers: </span><span class=si>{</span><span class=n>settings</span><span class=p>[</span><span class=s1>&#39;gpu_layers&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-17-10><a id=__codelineno-17-10 name=__codelineno-17-10 href=#__codelineno-17-10></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Context Size: </span><span class=si>{</span><span class=n>settings</span><span class=p>[</span><span class=s1>&#39;ctx_size&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-17-11><a id=__codelineno-17-11 name=__codelineno-17-11 href=#__codelineno-17-11></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Batch Size: </span><span class=si>{</span><span class=n>settings</span><span class=p>[</span><span class=s1>&#39;batch_size&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-17-12><a id=__codelineno-17-12 name=__codelineno-17-12 href=#__codelineno-17-12></a><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Micro-batch Size: </span><span class=si>{</span><span class=n>settings</span><span class=p>[</span><span class=s1>&#39;ubatch_size&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-17-13><a id=__codelineno-17-13 name=__codelineno-17-13 href=#__codelineno-17-13></a>
</span><span id=__span-17-14><a id=__codelineno-17-14 name=__codelineno-17-14 href=#__codelineno-17-14></a><span class=c1># Use settings with InferenceEngine</span>
</span><span id=__span-17-15><a id=__codelineno-17-15 name=__codelineno-17-15 href=#__codelineno-17-15></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-17-16><a id=__codelineno-17-16 name=__codelineno-17-16 href=#__codelineno-17-16></a>    <span class=nb>str</span><span class=p>(</span><span class=n>model_path</span><span class=p>),</span>
</span><span id=__span-17-17><a id=__codelineno-17-17 name=__codelineno-17-17 href=#__codelineno-17-17></a>    <span class=n>gpu_layers</span><span class=o>=</span><span class=n>settings</span><span class=p>[</span><span class=s1>&#39;gpu_layers&#39;</span><span class=p>],</span>
</span><span id=__span-17-18><a id=__codelineno-17-18 name=__codelineno-17-18 href=#__codelineno-17-18></a>    <span class=n>ctx_size</span><span class=o>=</span><span class=n>settings</span><span class=p>[</span><span class=s1>&#39;ctx_size&#39;</span><span class=p>],</span>
</span><span id=__span-17-19><a id=__codelineno-17-19 name=__codelineno-17-19 href=#__codelineno-17-19></a>    <span class=n>batch_size</span><span class=o>=</span><span class=n>settings</span><span class=p>[</span><span class=s1>&#39;batch_size&#39;</span><span class=p>],</span>
</span><span id=__span-17-20><a id=__codelineno-17-20 name=__codelineno-17-20 href=#__codelineno-17-20></a>    <span class=n>ubatch_size</span><span class=o>=</span><span class=n>settings</span><span class=p>[</span><span class=s1>&#39;ubatch_size&#39;</span><span class=p>]</span>
</span><span id=__span-17-21><a id=__codelineno-17-21 name=__codelineno-17-21 href=#__codelineno-17-21></a><span class=p>)</span>
</span></code></pre></div></p> <p><strong>Output on Tesla T4 (15 GB):</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-18-1><a id=__codelineno-18-1 name=__codelineno-18-1 href=#__codelineno-18-1></a>✓ Auto-configured for 15.0 GB VRAM
</span><span id=__span-18-2><a id=__codelineno-18-2 name=__codelineno-18-2 href=#__codelineno-18-2></a>  GPU Layers: 99
</span><span id=__span-18-3><a id=__codelineno-18-3 name=__codelineno-18-3 href=#__codelineno-18-3></a>  Context Size: 4096
</span><span id=__span-18-4><a id=__codelineno-18-4 name=__codelineno-18-4 href=#__codelineno-18-4></a>  Batch Size: 2048
</span><span id=__span-18-5><a id=__codelineno-18-5 name=__codelineno-18-5 href=#__codelineno-18-5></a>  Micro-batch Size: 512
</span></code></pre></div></p> <hr> <h2 id=platform-detection>Platform Detection<a class=headerlink href=#platform-detection title="Permanent link">&para;</a></h2> <p>llcuda automatically detects the execution environment:</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-19-1><a id=__codelineno-19-1 name=__codelineno-19-1 href=#__codelineno-19-1></a><span class=kn>import</span><span class=w> </span><span class=nn>llcuda</span>
</span><span id=__span-19-2><a id=__codelineno-19-2 name=__codelineno-19-2 href=#__codelineno-19-2></a>
</span><span id=__span-19-3><a id=__codelineno-19-3 name=__codelineno-19-3 href=#__codelineno-19-3></a><span class=n>compat</span> <span class=o>=</span> <span class=n>llcuda</span><span class=o>.</span><span class=n>check_gpu_compatibility</span><span class=p>()</span>
</span><span id=__span-19-4><a id=__codelineno-19-4 name=__codelineno-19-4 href=#__codelineno-19-4></a><span class=n>platform</span> <span class=o>=</span> <span class=n>compat</span><span class=p>[</span><span class=s1>&#39;platform&#39;</span><span class=p>]</span>
</span><span id=__span-19-5><a id=__codelineno-19-5 name=__codelineno-19-5 href=#__codelineno-19-5></a>
</span><span id=__span-19-6><a id=__codelineno-19-6 name=__codelineno-19-6 href=#__codelineno-19-6></a><span class=k>if</span> <span class=n>platform</span> <span class=o>==</span> <span class=s1>&#39;colab&#39;</span><span class=p>:</span>
</span><span id=__span-19-7><a id=__codelineno-19-7 name=__codelineno-19-7 href=#__codelineno-19-7></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Running on Google Colab&quot;</span><span class=p>)</span>
</span><span id=__span-19-8><a id=__codelineno-19-8 name=__codelineno-19-8 href=#__codelineno-19-8></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Expected GPU: Tesla T4&quot;</span><span class=p>)</span>
</span><span id=__span-19-9><a id=__codelineno-19-9 name=__codelineno-19-9 href=#__codelineno-19-9></a><span class=k>elif</span> <span class=n>platform</span> <span class=o>==</span> <span class=s1>&#39;kaggle&#39;</span><span class=p>:</span>
</span><span id=__span-19-10><a id=__codelineno-19-10 name=__codelineno-19-10 href=#__codelineno-19-10></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Running on Kaggle&quot;</span><span class=p>)</span>
</span><span id=__span-19-11><a id=__codelineno-19-11 name=__codelineno-19-11 href=#__codelineno-19-11></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Expected GPU: Tesla P100 or T4&quot;</span><span class=p>)</span>
</span><span id=__span-19-12><a id=__codelineno-19-12 name=__codelineno-19-12 href=#__codelineno-19-12></a><span class=k>else</span><span class=p>:</span>
</span><span id=__span-19-13><a id=__codelineno-19-13 name=__codelineno-19-13 href=#__codelineno-19-13></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Running on local machine&quot;</span><span class=p>)</span>
</span></code></pre></div> <p><strong>Detected Platforms:</strong></p> <ul> <li><code>colab</code> - Google Colab</li> <li><code>kaggle</code> - Kaggle Notebooks</li> <li><code>local</code> - Local machine or other cloud</li> </ul> <hr> <h2 id=multi-gpu-support>Multi-GPU Support<a class=headerlink href=#multi-gpu-support title="Permanent link">&para;</a></h2> <h3 id=selecting-specific-gpu>Selecting Specific GPU<a class=headerlink href=#selecting-specific-gpu title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-20-1><a id=__codelineno-20-1 name=__codelineno-20-1 href=#__codelineno-20-1></a><span class=kn>import</span><span class=w> </span><span class=nn>os</span>
</span><span id=__span-20-2><a id=__codelineno-20-2 name=__codelineno-20-2 href=#__codelineno-20-2></a>
</span><span id=__span-20-3><a id=__codelineno-20-3 name=__codelineno-20-3 href=#__codelineno-20-3></a><span class=c1># Use GPU 0 only</span>
</span><span id=__span-20-4><a id=__codelineno-20-4 name=__codelineno-20-4 href=#__codelineno-20-4></a><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;CUDA_VISIBLE_DEVICES&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=s1>&#39;0&#39;</span>
</span><span id=__span-20-5><a id=__codelineno-20-5 name=__codelineno-20-5 href=#__codelineno-20-5></a>
</span><span id=__span-20-6><a id=__codelineno-20-6 name=__codelineno-20-6 href=#__codelineno-20-6></a><span class=c1># Use GPU 1 only</span>
</span><span id=__span-20-7><a id=__codelineno-20-7 name=__codelineno-20-7 href=#__codelineno-20-7></a><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;CUDA_VISIBLE_DEVICES&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=s1>&#39;1&#39;</span>
</span><span id=__span-20-8><a id=__codelineno-20-8 name=__codelineno-20-8 href=#__codelineno-20-8></a>
</span><span id=__span-20-9><a id=__codelineno-20-9 name=__codelineno-20-9 href=#__codelineno-20-9></a><span class=c1># Use GPUs 0 and 2</span>
</span><span id=__span-20-10><a id=__codelineno-20-10 name=__codelineno-20-10 href=#__codelineno-20-10></a><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s1>&#39;CUDA_VISIBLE_DEVICES&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=s1>&#39;0,2&#39;</span>
</span><span id=__span-20-11><a id=__codelineno-20-11 name=__codelineno-20-11 href=#__codelineno-20-11></a>
</span><span id=__span-20-12><a id=__codelineno-20-12 name=__codelineno-20-12 href=#__codelineno-20-12></a><span class=c1># Then import llcuda</span>
</span><span id=__span-20-13><a id=__codelineno-20-13 name=__codelineno-20-13 href=#__codelineno-20-13></a><span class=kn>import</span><span class=w> </span><span class=nn>llcuda</span>
</span></code></pre></div> <h3 id=checking-multiple-gpus>Checking Multiple GPUs<a class=headerlink href=#checking-multiple-gpus title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-21-1><a id=__codelineno-21-1 name=__codelineno-21-1 href=#__codelineno-21-1></a><span class=kn>import</span><span class=w> </span><span class=nn>llcuda</span>
</span><span id=__span-21-2><a id=__codelineno-21-2 name=__codelineno-21-2 href=#__codelineno-21-2></a>
</span><span id=__span-21-3><a id=__codelineno-21-3 name=__codelineno-21-3 href=#__codelineno-21-3></a><span class=n>cuda_info</span> <span class=o>=</span> <span class=n>llcuda</span><span class=o>.</span><span class=n>detect_cuda</span><span class=p>()</span>
</span><span id=__span-21-4><a id=__codelineno-21-4 name=__codelineno-21-4 href=#__codelineno-21-4></a>
</span><span id=__span-21-5><a id=__codelineno-21-5 name=__codelineno-21-5 href=#__codelineno-21-5></a><span class=k>if</span> <span class=n>cuda_info</span><span class=p>[</span><span class=s1>&#39;available&#39;</span><span class=p>]:</span>
</span><span id=__span-21-6><a id=__codelineno-21-6 name=__codelineno-21-6 href=#__codelineno-21-6></a>    <span class=n>num_gpus</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=n>cuda_info</span><span class=p>[</span><span class=s1>&#39;gpus&#39;</span><span class=p>])</span>
</span><span id=__span-21-7><a id=__codelineno-21-7 name=__codelineno-21-7 href=#__codelineno-21-7></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Detected </span><span class=si>{</span><span class=n>num_gpus</span><span class=si>}</span><span class=s2> GPU(s)&quot;</span><span class=p>)</span>
</span><span id=__span-21-8><a id=__codelineno-21-8 name=__codelineno-21-8 href=#__codelineno-21-8></a>
</span><span id=__span-21-9><a id=__codelineno-21-9 name=__codelineno-21-9 href=#__codelineno-21-9></a>    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>gpu</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>cuda_info</span><span class=p>[</span><span class=s1>&#39;gpus&#39;</span><span class=p>]):</span>
</span><span id=__span-21-10><a id=__codelineno-21-10 name=__codelineno-21-10 href=#__codelineno-21-10></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>GPU </span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>gpu</span><span class=p>[</span><span class=s1>&#39;name&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-21-11><a id=__codelineno-21-11 name=__codelineno-21-11 href=#__codelineno-21-11></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  VRAM: </span><span class=si>{</span><span class=n>gpu</span><span class=p>[</span><span class=s1>&#39;memory&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-21-12><a id=__codelineno-21-12 name=__codelineno-21-12 href=#__codelineno-21-12></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  Compute: </span><span class=si>{</span><span class=n>gpu</span><span class=p>[</span><span class=s1>&#39;compute_capability&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <hr> <h2 id=environment-setup>Environment Setup<a class=headerlink href=#environment-setup title="Permanent link">&para;</a></h2> <h3 id=setup_environment><code>setup_environment()</code><a class=headerlink href=#setup_environment title="Permanent link">&para;</a></h3> <p>Automatically configure environment variables for optimal performance.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-22-1><a id=__codelineno-22-1 name=__codelineno-22-1 href=#__codelineno-22-1></a><span class=kn>from</span><span class=w> </span><span class=nn>llcuda.utils</span><span class=w> </span><span class=kn>import</span> <span class=n>setup_environment</span>
</span><span id=__span-22-2><a id=__codelineno-22-2 name=__codelineno-22-2 href=#__codelineno-22-2></a>
</span><span id=__span-22-3><a id=__codelineno-22-3 name=__codelineno-22-3 href=#__codelineno-22-3></a><span class=c1># Setup environment</span>
</span><span id=__span-22-4><a id=__codelineno-22-4 name=__codelineno-22-4 href=#__codelineno-22-4></a><span class=n>env_vars</span> <span class=o>=</span> <span class=n>setup_environment</span><span class=p>()</span>
</span><span id=__span-22-5><a id=__codelineno-22-5 name=__codelineno-22-5 href=#__codelineno-22-5></a>
</span><span id=__span-22-6><a id=__codelineno-22-6 name=__codelineno-22-6 href=#__codelineno-22-6></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Environment configured:&quot;</span><span class=p>)</span>
</span><span id=__span-22-7><a id=__codelineno-22-7 name=__codelineno-22-7 href=#__codelineno-22-7></a><span class=k>for</span> <span class=n>key</span><span class=p>,</span> <span class=n>value</span> <span class=ow>in</span> <span class=n>env_vars</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span><span id=__span-22-8><a id=__codelineno-22-8 name=__codelineno-22-8 href=#__codelineno-22-8></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;  </span><span class=si>{</span><span class=n>key</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>value</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span></code></pre></div> <p><strong>Configured Variables:</strong></p> <ul> <li><code>LD_LIBRARY_PATH</code> - Shared library path (Linux)</li> <li><code>CUDA_VISIBLE_DEVICES</code> - Visible GPUs</li> <li><code>LLAMA_CPP_DIR</code> - llama.cpp installation directory</li> </ul> <hr> <h2 id=system-information>System Information<a class=headerlink href=#system-information title="Permanent link">&para;</a></h2> <h3 id=print_system_info><code>print_system_info()</code><a class=headerlink href=#print_system_info title="Permanent link">&para;</a></h3> <p>Print comprehensive system information for debugging.</p> <div class="language-python highlight"><pre><span></span><code><span id=__span-23-1><a id=__codelineno-23-1 name=__codelineno-23-1 href=#__codelineno-23-1></a><span class=kn>from</span><span class=w> </span><span class=nn>llcuda.utils</span><span class=w> </span><span class=kn>import</span> <span class=n>print_system_info</span>
</span><span id=__span-23-2><a id=__codelineno-23-2 name=__codelineno-23-2 href=#__codelineno-23-2></a>
</span><span id=__span-23-3><a id=__codelineno-23-3 name=__codelineno-23-3 href=#__codelineno-23-3></a><span class=n>print_system_info</span><span class=p>()</span>
</span></code></pre></div> <p><strong>Output:</strong> <div class="language-text highlight"><pre><span></span><code><span id=__span-24-1><a id=__codelineno-24-1 name=__codelineno-24-1 href=#__codelineno-24-1></a>============================================================
</span><span id=__span-24-2><a id=__codelineno-24-2 name=__codelineno-24-2 href=#__codelineno-24-2></a>llcuda System Information
</span><span id=__span-24-3><a id=__codelineno-24-3 name=__codelineno-24-3 href=#__codelineno-24-3></a>============================================================
</span><span id=__span-24-4><a id=__codelineno-24-4 name=__codelineno-24-4 href=#__codelineno-24-4></a>
</span><span id=__span-24-5><a id=__codelineno-24-5 name=__codelineno-24-5 href=#__codelineno-24-5></a>Python:
</span><span id=__span-24-6><a id=__codelineno-24-6 name=__codelineno-24-6 href=#__codelineno-24-6></a>  Version: 3.10.12 (main, Nov 20 2023, 15:14:05)
</span><span id=__span-24-7><a id=__codelineno-24-7 name=__codelineno-24-7 href=#__codelineno-24-7></a>  Executable: /usr/bin/python3
</span><span id=__span-24-8><a id=__codelineno-24-8 name=__codelineno-24-8 href=#__codelineno-24-8></a>
</span><span id=__span-24-9><a id=__codelineno-24-9 name=__codelineno-24-9 href=#__codelineno-24-9></a>Operating System:
</span><span id=__span-24-10><a id=__codelineno-24-10 name=__codelineno-24-10 href=#__codelineno-24-10></a>  System: Linux
</span><span id=__span-24-11><a id=__codelineno-24-11 name=__codelineno-24-11 href=#__codelineno-24-11></a>  Release: 5.15.0-91-generic
</span><span id=__span-24-12><a id=__codelineno-24-12 name=__codelineno-24-12 href=#__codelineno-24-12></a>  Machine: x86_64
</span><span id=__span-24-13><a id=__codelineno-24-13 name=__codelineno-24-13 href=#__codelineno-24-13></a>
</span><span id=__span-24-14><a id=__codelineno-24-14 name=__codelineno-24-14 href=#__codelineno-24-14></a>CUDA:
</span><span id=__span-24-15><a id=__codelineno-24-15 name=__codelineno-24-15 href=#__codelineno-24-15></a>  Available: True
</span><span id=__span-24-16><a id=__codelineno-24-16 name=__codelineno-24-16 href=#__codelineno-24-16></a>  Version: 12.2
</span><span id=__span-24-17><a id=__codelineno-24-17 name=__codelineno-24-17 href=#__codelineno-24-17></a>  GPUs: 1
</span><span id=__span-24-18><a id=__codelineno-24-18 name=__codelineno-24-18 href=#__codelineno-24-18></a>    GPU 0: Tesla T4
</span><span id=__span-24-19><a id=__codelineno-24-19 name=__codelineno-24-19 href=#__codelineno-24-19></a>      Memory: 15360 MiB
</span><span id=__span-24-20><a id=__codelineno-24-20 name=__codelineno-24-20 href=#__codelineno-24-20></a>      Driver: 535.104.05
</span><span id=__span-24-21><a id=__codelineno-24-21 name=__codelineno-24-21 href=#__codelineno-24-21></a>      Compute: 7.5
</span><span id=__span-24-22><a id=__codelineno-24-22 name=__codelineno-24-22 href=#__codelineno-24-22></a>
</span><span id=__span-24-23><a id=__codelineno-24-23 name=__codelineno-24-23 href=#__codelineno-24-23></a>GGUF Models Found: 3
</span><span id=__span-24-24><a id=__codelineno-24-24 name=__codelineno-24-24 href=#__codelineno-24-24></a>  - gemma-3-1b-it-Q4_K_M.gguf (872.5 MB)
</span><span id=__span-24-25><a id=__codelineno-24-25 name=__codelineno-24-25 href=#__codelineno-24-25></a>  - llama-3.2-3b-Q4_K_M.gguf (1856.2 MB)
</span><span id=__span-24-26><a id=__codelineno-24-26 name=__codelineno-24-26 href=#__codelineno-24-26></a>  - qwen2.5-7b-Q4_K_M.gguf (4368.7 MB)
</span><span id=__span-24-27><a id=__codelineno-24-27 name=__codelineno-24-27 href=#__codelineno-24-27></a>
</span><span id=__span-24-28><a id=__codelineno-24-28 name=__codelineno-24-28 href=#__codelineno-24-28></a>============================================================
</span></code></pre></div></p> <hr> <h2 id=common-patterns>Common Patterns<a class=headerlink href=#common-patterns title="Permanent link">&para;</a></h2> <h3 id=complete-gpu-verification>Complete GPU Verification<a class=headerlink href=#complete-gpu-verification title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-25-1><a id=__codelineno-25-1 name=__codelineno-25-1 href=#__codelineno-25-1></a><span class=kn>import</span><span class=w> </span><span class=nn>llcuda</span>
</span><span id=__span-25-2><a id=__codelineno-25-2 name=__codelineno-25-2 href=#__codelineno-25-2></a>
</span><span id=__span-25-3><a id=__codelineno-25-3 name=__codelineno-25-3 href=#__codelineno-25-3></a><span class=k>def</span><span class=w> </span><span class=nf>verify_gpu_setup</span><span class=p>():</span>
</span><span id=__span-25-4><a id=__codelineno-25-4 name=__codelineno-25-4 href=#__codelineno-25-4></a><span class=w>    </span><span class=sd>&quot;&quot;&quot;Verify GPU setup before running inference.&quot;&quot;&quot;</span>
</span><span id=__span-25-5><a id=__codelineno-25-5 name=__codelineno-25-5 href=#__codelineno-25-5></a>
</span><span id=__span-25-6><a id=__codelineno-25-6 name=__codelineno-25-6 href=#__codelineno-25-6></a>    <span class=c1># Check CUDA availability</span>
</span><span id=__span-25-7><a id=__codelineno-25-7 name=__codelineno-25-7 href=#__codelineno-25-7></a>    <span class=k>if</span> <span class=ow>not</span> <span class=n>llcuda</span><span class=o>.</span><span class=n>check_cuda_available</span><span class=p>():</span>
</span><span id=__span-25-8><a id=__codelineno-25-8 name=__codelineno-25-8 href=#__codelineno-25-8></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;❌ CUDA not available&quot;</span><span class=p>)</span>
</span><span id=__span-25-9><a id=__codelineno-25-9 name=__codelineno-25-9 href=#__codelineno-25-9></a>        <span class=k>return</span> <span class=kc>False</span>
</span><span id=__span-25-10><a id=__codelineno-25-10 name=__codelineno-25-10 href=#__codelineno-25-10></a>
</span><span id=__span-25-11><a id=__codelineno-25-11 name=__codelineno-25-11 href=#__codelineno-25-11></a>    <span class=c1># Get detailed info</span>
</span><span id=__span-25-12><a id=__codelineno-25-12 name=__codelineno-25-12 href=#__codelineno-25-12></a>    <span class=n>cuda_info</span> <span class=o>=</span> <span class=n>llcuda</span><span class=o>.</span><span class=n>detect_cuda</span><span class=p>()</span>
</span><span id=__span-25-13><a id=__codelineno-25-13 name=__codelineno-25-13 href=#__codelineno-25-13></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;✅ CUDA </span><span class=si>{</span><span class=n>cuda_info</span><span class=p>[</span><span class=s1>&#39;version&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2> detected&quot;</span><span class=p>)</span>
</span><span id=__span-25-14><a id=__codelineno-25-14 name=__codelineno-25-14 href=#__codelineno-25-14></a>
</span><span id=__span-25-15><a id=__codelineno-25-15 name=__codelineno-25-15 href=#__codelineno-25-15></a>    <span class=c1># Check compatibility</span>
</span><span id=__span-25-16><a id=__codelineno-25-16 name=__codelineno-25-16 href=#__codelineno-25-16></a>    <span class=n>compat</span> <span class=o>=</span> <span class=n>llcuda</span><span class=o>.</span><span class=n>check_gpu_compatibility</span><span class=p>()</span>
</span><span id=__span-25-17><a id=__codelineno-25-17 name=__codelineno-25-17 href=#__codelineno-25-17></a>
</span><span id=__span-25-18><a id=__codelineno-25-18 name=__codelineno-25-18 href=#__codelineno-25-18></a>    <span class=k>if</span> <span class=ow>not</span> <span class=n>compat</span><span class=p>[</span><span class=s1>&#39;compatible&#39;</span><span class=p>]:</span>
</span><span id=__span-25-19><a id=__codelineno-25-19 name=__codelineno-25-19 href=#__codelineno-25-19></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;❌ </span><span class=si>{</span><span class=n>compat</span><span class=p>[</span><span class=s1>&#39;gpu_name&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2> is not compatible&quot;</span><span class=p>)</span>
</span><span id=__span-25-20><a id=__codelineno-25-20 name=__codelineno-25-20 href=#__codelineno-25-20></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;   </span><span class=si>{</span><span class=n>compat</span><span class=p>[</span><span class=s1>&#39;reason&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-25-21><a id=__codelineno-25-21 name=__codelineno-25-21 href=#__codelineno-25-21></a>        <span class=k>return</span> <span class=kc>False</span>
</span><span id=__span-25-22><a id=__codelineno-25-22 name=__codelineno-25-22 href=#__codelineno-25-22></a>
</span><span id=__span-25-23><a id=__codelineno-25-23 name=__codelineno-25-23 href=#__codelineno-25-23></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;✅ </span><span class=si>{</span><span class=n>compat</span><span class=p>[</span><span class=s1>&#39;gpu_name&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2> is compatible&quot;</span><span class=p>)</span>
</span><span id=__span-25-24><a id=__codelineno-25-24 name=__codelineno-25-24 href=#__codelineno-25-24></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;   Compute Capability: </span><span class=si>{</span><span class=n>compat</span><span class=p>[</span><span class=s1>&#39;compute_capability&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-25-25><a id=__codelineno-25-25 name=__codelineno-25-25 href=#__codelineno-25-25></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;   Platform: </span><span class=si>{</span><span class=n>compat</span><span class=p>[</span><span class=s1>&#39;platform&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-25-26><a id=__codelineno-25-26 name=__codelineno-25-26 href=#__codelineno-25-26></a>
</span><span id=__span-25-27><a id=__codelineno-25-27 name=__codelineno-25-27 href=#__codelineno-25-27></a>    <span class=c1># Get VRAM info</span>
</span><span id=__span-25-28><a id=__codelineno-25-28 name=__codelineno-25-28 href=#__codelineno-25-28></a>    <span class=n>gpu</span> <span class=o>=</span> <span class=n>cuda_info</span><span class=p>[</span><span class=s1>&#39;gpus&#39;</span><span class=p>][</span><span class=mi>0</span><span class=p>]</span>
</span><span id=__span-25-29><a id=__codelineno-25-29 name=__codelineno-25-29 href=#__codelineno-25-29></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;   VRAM: </span><span class=si>{</span><span class=n>gpu</span><span class=p>[</span><span class=s1>&#39;memory&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-25-30><a id=__codelineno-25-30 name=__codelineno-25-30 href=#__codelineno-25-30></a>
</span><span id=__span-25-31><a id=__codelineno-25-31 name=__codelineno-25-31 href=#__codelineno-25-31></a>    <span class=k>return</span> <span class=kc>True</span>
</span><span id=__span-25-32><a id=__codelineno-25-32 name=__codelineno-25-32 href=#__codelineno-25-32></a>
</span><span id=__span-25-33><a id=__codelineno-25-33 name=__codelineno-25-33 href=#__codelineno-25-33></a><span class=c1># Use it</span>
</span><span id=__span-25-34><a id=__codelineno-25-34 name=__codelineno-25-34 href=#__codelineno-25-34></a><span class=k>if</span> <span class=n>verify_gpu_setup</span><span class=p>():</span>
</span><span id=__span-25-35><a id=__codelineno-25-35 name=__codelineno-25-35 href=#__codelineno-25-35></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>🚀 Ready for inference!&quot;</span><span class=p>)</span>
</span><span id=__span-25-36><a id=__codelineno-25-36 name=__codelineno-25-36 href=#__codelineno-25-36></a>    <span class=c1># Proceed with model loading...</span>
</span><span id=__span-25-37><a id=__codelineno-25-37 name=__codelineno-25-37 href=#__codelineno-25-37></a><span class=k>else</span><span class=p>:</span>
</span><span id=__span-25-38><a id=__codelineno-25-38 name=__codelineno-25-38 href=#__codelineno-25-38></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;</span><span class=se>\n</span><span class=s2>⚠️ GPU setup incomplete&quot;</span><span class=p>)</span>
</span></code></pre></div> <h3 id=auto-configure-and-load>Auto-Configure and Load<a class=headerlink href=#auto-configure-and-load title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-26-1><a id=__codelineno-26-1 name=__codelineno-26-1 href=#__codelineno-26-1></a><span class=kn>import</span><span class=w> </span><span class=nn>llcuda</span>
</span><span id=__span-26-2><a id=__codelineno-26-2 name=__codelineno-26-2 href=#__codelineno-26-2></a><span class=kn>from</span><span class=w> </span><span class=nn>llcuda.utils</span><span class=w> </span><span class=kn>import</span> <span class=n>auto_configure_for_model</span>
</span><span id=__span-26-3><a id=__codelineno-26-3 name=__codelineno-26-3 href=#__codelineno-26-3></a><span class=kn>from</span><span class=w> </span><span class=nn>pathlib</span><span class=w> </span><span class=kn>import</span> <span class=n>Path</span>
</span><span id=__span-26-4><a id=__codelineno-26-4 name=__codelineno-26-4 href=#__codelineno-26-4></a>
</span><span id=__span-26-5><a id=__codelineno-26-5 name=__codelineno-26-5 href=#__codelineno-26-5></a><span class=c1># Verify GPU</span>
</span><span id=__span-26-6><a id=__codelineno-26-6 name=__codelineno-26-6 href=#__codelineno-26-6></a><span class=n>compat</span> <span class=o>=</span> <span class=n>llcuda</span><span class=o>.</span><span class=n>check_gpu_compatibility</span><span class=p>()</span>
</span><span id=__span-26-7><a id=__codelineno-26-7 name=__codelineno-26-7 href=#__codelineno-26-7></a><span class=k>if</span> <span class=ow>not</span> <span class=n>compat</span><span class=p>[</span><span class=s1>&#39;compatible&#39;</span><span class=p>]:</span>
</span><span id=__span-26-8><a id=__codelineno-26-8 name=__codelineno-26-8 href=#__codelineno-26-8></a>    <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;GPU not compatible: </span><span class=si>{</span><span class=n>compat</span><span class=p>[</span><span class=s1>&#39;reason&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-26-9><a id=__codelineno-26-9 name=__codelineno-26-9 href=#__codelineno-26-9></a>
</span><span id=__span-26-10><a id=__codelineno-26-10 name=__codelineno-26-10 href=#__codelineno-26-10></a><span class=c1># Auto-configure</span>
</span><span id=__span-26-11><a id=__codelineno-26-11 name=__codelineno-26-11 href=#__codelineno-26-11></a><span class=n>model_path</span> <span class=o>=</span> <span class=n>Path</span><span class=p>(</span><span class=s2>&quot;model.gguf&quot;</span><span class=p>)</span>
</span><span id=__span-26-12><a id=__codelineno-26-12 name=__codelineno-26-12 href=#__codelineno-26-12></a><span class=n>settings</span> <span class=o>=</span> <span class=n>auto_configure_for_model</span><span class=p>(</span><span class=n>model_path</span><span class=p>)</span>
</span><span id=__span-26-13><a id=__codelineno-26-13 name=__codelineno-26-13 href=#__codelineno-26-13></a>
</span><span id=__span-26-14><a id=__codelineno-26-14 name=__codelineno-26-14 href=#__codelineno-26-14></a><span class=c1># Create engine with optimal settings</span>
</span><span id=__span-26-15><a id=__codelineno-26-15 name=__codelineno-26-15 href=#__codelineno-26-15></a><span class=n>engine</span> <span class=o>=</span> <span class=n>llcuda</span><span class=o>.</span><span class=n>InferenceEngine</span><span class=p>()</span>
</span><span id=__span-26-16><a id=__codelineno-26-16 name=__codelineno-26-16 href=#__codelineno-26-16></a><span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span>
</span><span id=__span-26-17><a id=__codelineno-26-17 name=__codelineno-26-17 href=#__codelineno-26-17></a>    <span class=nb>str</span><span class=p>(</span><span class=n>model_path</span><span class=p>),</span>
</span><span id=__span-26-18><a id=__codelineno-26-18 name=__codelineno-26-18 href=#__codelineno-26-18></a>    <span class=o>**</span><span class=n>settings</span><span class=p>,</span>  <span class=c1># Use all auto-configured settings</span>
</span><span id=__span-26-19><a id=__codelineno-26-19 name=__codelineno-26-19 href=#__codelineno-26-19></a>    <span class=n>silent</span><span class=o>=</span><span class=kc>True</span>
</span><span id=__span-26-20><a id=__codelineno-26-20 name=__codelineno-26-20 href=#__codelineno-26-20></a><span class=p>)</span>
</span><span id=__span-26-21><a id=__codelineno-26-21 name=__codelineno-26-21 href=#__codelineno-26-21></a>
</span><span id=__span-26-22><a id=__codelineno-26-22 name=__codelineno-26-22 href=#__codelineno-26-22></a><span class=nb>print</span><span class=p>(</span><span class=s2>&quot;✅ Model loaded with optimal settings!&quot;</span><span class=p>)</span>
</span></code></pre></div> <hr> <h2 id=error-handling>Error Handling<a class=headerlink href=#error-handling title="Permanent link">&para;</a></h2> <h3 id=handle-no-gpu>Handle No GPU<a class=headerlink href=#handle-no-gpu title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-27-1><a id=__codelineno-27-1 name=__codelineno-27-1 href=#__codelineno-27-1></a><span class=kn>import</span><span class=w> </span><span class=nn>llcuda</span>
</span><span id=__span-27-2><a id=__codelineno-27-2 name=__codelineno-27-2 href=#__codelineno-27-2></a>
</span><span id=__span-27-3><a id=__codelineno-27-3 name=__codelineno-27-3 href=#__codelineno-27-3></a><span class=k>try</span><span class=p>:</span>
</span><span id=__span-27-4><a id=__codelineno-27-4 name=__codelineno-27-4 href=#__codelineno-27-4></a>    <span class=n>compat</span> <span class=o>=</span> <span class=n>llcuda</span><span class=o>.</span><span class=n>check_gpu_compatibility</span><span class=p>()</span>
</span><span id=__span-27-5><a id=__codelineno-27-5 name=__codelineno-27-5 href=#__codelineno-27-5></a>
</span><span id=__span-27-6><a id=__codelineno-27-6 name=__codelineno-27-6 href=#__codelineno-27-6></a>    <span class=k>if</span> <span class=ow>not</span> <span class=n>compat</span><span class=p>[</span><span class=s1>&#39;compatible&#39;</span><span class=p>]:</span>
</span><span id=__span-27-7><a id=__codelineno-27-7 name=__codelineno-27-7 href=#__codelineno-27-7></a>        <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span><span class=n>compat</span><span class=p>[</span><span class=s1>&#39;reason&#39;</span><span class=p>])</span>
</span><span id=__span-27-8><a id=__codelineno-27-8 name=__codelineno-27-8 href=#__codelineno-27-8></a>
</span><span id=__span-27-9><a id=__codelineno-27-9 name=__codelineno-27-9 href=#__codelineno-27-9></a>    <span class=c1># Proceed with GPU inference</span>
</span><span id=__span-27-10><a id=__codelineno-27-10 name=__codelineno-27-10 href=#__codelineno-27-10></a>    <span class=n>engine</span> <span class=o>=</span> <span class=n>llcuda</span><span class=o>.</span><span class=n>InferenceEngine</span><span class=p>()</span>
</span><span id=__span-27-11><a id=__codelineno-27-11 name=__codelineno-27-11 href=#__codelineno-27-11></a>    <span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=s2>&quot;model.gguf&quot;</span><span class=p>,</span> <span class=n>gpu_layers</span><span class=o>=</span><span class=mi>99</span><span class=p>)</span>
</span><span id=__span-27-12><a id=__codelineno-27-12 name=__codelineno-27-12 href=#__codelineno-27-12></a>
</span><span id=__span-27-13><a id=__codelineno-27-13 name=__codelineno-27-13 href=#__codelineno-27-13></a><span class=k>except</span> <span class=ne>RuntimeError</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span><span id=__span-27-14><a id=__codelineno-27-14 name=__codelineno-27-14 href=#__codelineno-27-14></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;GPU Error: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-27-15><a id=__codelineno-27-15 name=__codelineno-27-15 href=#__codelineno-27-15></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Falling back to CPU mode...&quot;</span><span class=p>)</span>
</span><span id=__span-27-16><a id=__codelineno-27-16 name=__codelineno-27-16 href=#__codelineno-27-16></a>
</span><span id=__span-27-17><a id=__codelineno-27-17 name=__codelineno-27-17 href=#__codelineno-27-17></a>    <span class=c1># Load with CPU</span>
</span><span id=__span-27-18><a id=__codelineno-27-18 name=__codelineno-27-18 href=#__codelineno-27-18></a>    <span class=n>engine</span> <span class=o>=</span> <span class=n>llcuda</span><span class=o>.</span><span class=n>InferenceEngine</span><span class=p>()</span>
</span><span id=__span-27-19><a id=__codelineno-27-19 name=__codelineno-27-19 href=#__codelineno-27-19></a>    <span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=s2>&quot;model.gguf&quot;</span><span class=p>,</span> <span class=n>gpu_layers</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></code></pre></div> <h3 id=handle-insufficient-vram>Handle Insufficient VRAM<a class=headerlink href=#handle-insufficient-vram title="Permanent link">&para;</a></h3> <div class="language-python highlight"><pre><span></span><code><span id=__span-28-1><a id=__codelineno-28-1 name=__codelineno-28-1 href=#__codelineno-28-1></a><span class=kn>import</span><span class=w> </span><span class=nn>llcuda</span>
</span><span id=__span-28-2><a id=__codelineno-28-2 name=__codelineno-28-2 href=#__codelineno-28-2></a><span class=kn>from</span><span class=w> </span><span class=nn>llcuda.utils</span><span class=w> </span><span class=kn>import</span> <span class=n>auto_configure_for_model</span>
</span><span id=__span-28-3><a id=__codelineno-28-3 name=__codelineno-28-3 href=#__codelineno-28-3></a><span class=kn>from</span><span class=w> </span><span class=nn>pathlib</span><span class=w> </span><span class=kn>import</span> <span class=n>Path</span>
</span><span id=__span-28-4><a id=__codelineno-28-4 name=__codelineno-28-4 href=#__codelineno-28-4></a>
</span><span id=__span-28-5><a id=__codelineno-28-5 name=__codelineno-28-5 href=#__codelineno-28-5></a><span class=n>model_path</span> <span class=o>=</span> <span class=n>Path</span><span class=p>(</span><span class=s2>&quot;large-model.gguf&quot;</span><span class=p>)</span>
</span><span id=__span-28-6><a id=__codelineno-28-6 name=__codelineno-28-6 href=#__codelineno-28-6></a>
</span><span id=__span-28-7><a id=__codelineno-28-7 name=__codelineno-28-7 href=#__codelineno-28-7></a><span class=k>try</span><span class=p>:</span>
</span><span id=__span-28-8><a id=__codelineno-28-8 name=__codelineno-28-8 href=#__codelineno-28-8></a>    <span class=c1># Try auto-configuration</span>
</span><span id=__span-28-9><a id=__codelineno-28-9 name=__codelineno-28-9 href=#__codelineno-28-9></a>    <span class=n>settings</span> <span class=o>=</span> <span class=n>auto_configure_for_model</span><span class=p>(</span><span class=n>model_path</span><span class=p>)</span>
</span><span id=__span-28-10><a id=__codelineno-28-10 name=__codelineno-28-10 href=#__codelineno-28-10></a>
</span><span id=__span-28-11><a id=__codelineno-28-11 name=__codelineno-28-11 href=#__codelineno-28-11></a>    <span class=k>if</span> <span class=n>settings</span><span class=p>[</span><span class=s1>&#39;gpu_layers&#39;</span><span class=p>]</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span><span id=__span-28-12><a id=__codelineno-28-12 name=__codelineno-28-12 href=#__codelineno-28-12></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;⚠️ Insufficient VRAM for GPU offload&quot;</span><span class=p>)</span>
</span><span id=__span-28-13><a id=__codelineno-28-13 name=__codelineno-28-13 href=#__codelineno-28-13></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;   Using CPU mode&quot;</span><span class=p>)</span>
</span><span id=__span-28-14><a id=__codelineno-28-14 name=__codelineno-28-14 href=#__codelineno-28-14></a>    <span class=k>elif</span> <span class=n>settings</span><span class=p>[</span><span class=s1>&#39;gpu_layers&#39;</span><span class=p>]</span> <span class=o>&lt;</span> <span class=mi>99</span><span class=p>:</span>
</span><span id=__span-28-15><a id=__codelineno-28-15 name=__codelineno-28-15 href=#__codelineno-28-15></a>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;⚠️ Partial GPU offload: </span><span class=si>{</span><span class=n>settings</span><span class=p>[</span><span class=s1>&#39;gpu_layers&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2> layers&quot;</span><span class=p>)</span>
</span><span id=__span-28-16><a id=__codelineno-28-16 name=__codelineno-28-16 href=#__codelineno-28-16></a>        <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;   Consider using a smaller model for better performance&quot;</span><span class=p>)</span>
</span><span id=__span-28-17><a id=__codelineno-28-17 name=__codelineno-28-17 href=#__codelineno-28-17></a>
</span><span id=__span-28-18><a id=__codelineno-28-18 name=__codelineno-28-18 href=#__codelineno-28-18></a>    <span class=c1># Load with recommended settings</span>
</span><span id=__span-28-19><a id=__codelineno-28-19 name=__codelineno-28-19 href=#__codelineno-28-19></a>    <span class=n>engine</span> <span class=o>=</span> <span class=n>llcuda</span><span class=o>.</span><span class=n>InferenceEngine</span><span class=p>()</span>
</span><span id=__span-28-20><a id=__codelineno-28-20 name=__codelineno-28-20 href=#__codelineno-28-20></a>    <span class=n>engine</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=nb>str</span><span class=p>(</span><span class=n>model_path</span><span class=p>),</span> <span class=o>**</span><span class=n>settings</span><span class=p>)</span>
</span><span id=__span-28-21><a id=__codelineno-28-21 name=__codelineno-28-21 href=#__codelineno-28-21></a>
</span><span id=__span-28-22><a id=__codelineno-28-22 name=__codelineno-28-22 href=#__codelineno-28-22></a><span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span><span id=__span-28-23><a id=__codelineno-28-23 name=__codelineno-28-23 href=#__codelineno-28-23></a>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&quot;Error: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&quot;</span><span class=p>)</span>
</span><span id=__span-28-24><a id=__codelineno-28-24 name=__codelineno-28-24 href=#__codelineno-28-24></a>    <span class=nb>print</span><span class=p>(</span><span class=s2>&quot;Try a smaller model or more aggressive quantization&quot;</span><span class=p>)</span>
</span></code></pre></div> <hr> <h2 id=see-also>See Also<a class=headerlink href=#see-also title="Permanent link">&para;</a></h2> <ul> <li><a href=../overview/ >API Overview</a> - Complete API reference</li> <li><a href=../inference-engine/ >InferenceEngine</a> - Inference API</li> <li><a href=../models/ >Models &amp; GGUF</a> - Model management</li> <li><a href=../../performance/optimization/ >Performance Guide</a> - Optimization techniques</li> <li><a href=../../guides/troubleshooting/ >Troubleshooting</a> - Common issues</li> </ul> <form class=md-feedback name=feedback hidden> <fieldset> <legend class=md-feedback__title> Was this page helpful? </legend> <div class=md-feedback__inner> <div class=md-feedback__list> <button class="md-feedback__icon md-icon" type=submit title="This page was helpful" data-md-value=1> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m7 0c0 .8-.7 1.5-1.5 1.5S14 10.3 14 9.5 14.7 8 15.5 8s1.5.7 1.5 1.5m-5 7.73c-1.75 0-3.29-.73-4.19-1.81L9.23 14c.45.72 1.52 1.23 2.77 1.23s2.32-.51 2.77-1.23l1.42 1.42c-.9 1.08-2.44 1.81-4.19 1.81"/></svg> </button> <button class="md-feedback__icon md-icon" type=submit title="This page could be improved" data-md-value=0> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 12a8 8 0 0 0-8-8 8 8 0 0 0-8 8 8 8 0 0 0 8 8 8 8 0 0 0 8-8m2 0a10 10 0 0 1-10 10A10 10 0 0 1 2 12 10 10 0 0 1 12 2a10 10 0 0 1 10 10m-6.5-4c.8 0 1.5.7 1.5 1.5s-.7 1.5-1.5 1.5-1.5-.7-1.5-1.5.7-1.5 1.5-1.5M10 9.5c0 .8-.7 1.5-1.5 1.5S7 10.3 7 9.5 7.7 8 8.5 8s1.5.7 1.5 1.5m2 4.5c1.75 0 3.29.72 4.19 1.81l-1.42 1.42C14.32 16.5 13.25 16 12 16s-2.32.5-2.77 1.23l-1.42-1.42C8.71 14.72 10.25 14 12 14"/></svg> </button> </div> <div class=md-feedback__note> <div data-md-value=1 hidden> Thanks for your feedback! </div> <div data-md-value=0 hidden> Thanks for your feedback! Help us improve by <a href=https://github.com/waqasm86/llcuda/issues/new target=_blank rel=noopener>opening an issue</a>. </div> </div> </div> </fieldset> </form> </article> </div> <script>var tabs=__md_get("__tabs");if(Array.isArray(tabs))e:for(var set of document.querySelectorAll(".tabbed-set")){var labels=set.querySelector(".tabbed-labels");for(var tab of tabs)for(var label of labels.getElementsByTagName("label"))if(label.innerText.trim()===tab){var input=document.getElementById(label.htmlFor);input.checked=!0;continue e}}</script> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button type=button class="md-top md-icon" data-md-component=top hidden> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"/></svg> Back to top </button> </main> <footer class=md-footer> <nav class="md-footer__inner md-grid" aria-label=Footer> <a href=../models/ class="md-footer__link md-footer__link--prev" aria-label="Previous: Models & GGUF"> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"/></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Models & GGUF </div> </div> </a> <a href=../examples/ class="md-footer__link md-footer__link--next" aria-label="Next: Examples"> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Examples </div> </div> <div class="md-footer__button md-icon"> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"/></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright &copy; 2024-2026 Waqas Muhammad </div> </div> <div class=md-social> <a href=https://github.com/waqasm86 target=_blank rel=noopener title="GitHub - waqasm86" class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M173.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M252.8 8C114.1 8 8 113.3 8 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C436.2 457.8 504 362.9 504 252 504 113.3 391.5 8 252.8 8M105.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"/></svg> </a> <a href=mailto:waqasm86@gmail.com target=_blank rel=noopener title="Email - waqasm86@gmail.com" class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 512 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M48 64C21.5 64 0 85.5 0 112c0 15.1 7.1 29.3 19.2 38.4l208 156a48 48 0 0 0 57.6 0l208-156c12.1-9.1 19.2-23.3 19.2-38.4 0-26.5-21.5-48-48-48zM0 196v188c0 35.3 28.7 64 64 64h384c35.3 0 64-28.7 64-64V196L313.6 344.8c-34.1 25.6-81.1 25.6-115.2 0z"/></svg> </a> <a href=https://www.linkedin.com/in/waqasm86 target=_blank rel=noopener title="LinkedIn - Waqas Muhammad" class=md-social__link> <svg xmlns=http://www.w3.org/2000/svg viewbox="0 0 448 512"><!-- Font Awesome Free 7.1.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2025 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3M135.4 416H69V202.2h66.5V416zM102.2 96a38.5 38.5 0 1 1 0 77 38.5 38.5 0 1 1 0-77m282.1 320h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9z"/></svg> </a> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <div class=md-progress data-md-component=progress role=progressbar></div> <div class=md-consent data-md-component=consent id=__consent hidden> <div class=md-consent__overlay></div> <aside class=md-consent__inner> <form class="md-consent__form md-grid md-typeset" name=consent> <h4>Cookie consent</h4> <p>We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they're searching for. With your consent, you're helping us to make our documentation better.</p> <input class=md-toggle type=checkbox id=__settings> <div class=md-consent__settings> <ul class=task-list> <li class=task-list-item> <label class=task-list-control> <input type=checkbox name=analytics checked> <span class=task-list-indicator></span> Google Analytics </label> </li> <li class=task-list-item> <label class=task-list-control> <input type=checkbox name=github checked> <span class=task-list-indicator></span> GitHub </label> </li> </ul> </div> <div class=md-consent__controls> <button class="md-button md-button--primary">Accept</button> <label class=md-button for=__settings>Manage settings</label> </div> </form> </aside> </div> <script>var consent=__md_get("__consent");if(consent)for(var input of document.forms.consent.elements)input.name&&(input.checked=consent[input.name]||!1);else"file:"!==location.protocol&&setTimeout((function(){document.querySelector("[data-md-component=consent]").hidden=!1}),250);var form=document.forms.consent;for(var action of["submit","reset"])form.addEventListener(action,(function(e){if(e.preventDefault(),"reset"===e.type)for(var n of document.forms.consent.elements)n.name&&(n.checked=!1);__md_set("__consent",Object.fromEntries(Array.from(new FormData(form).keys()).map((function(e){return[e,!0]})))),location.hash="",location.reload()}))</script> <script id=__config type=application/json>{"annotate": null, "base": "../..", "features": ["announce.dismiss", "content.code.annotate", "content.code.copy", "content.tabs.link", "content.tooltips", "header.autohide", "navigation.expand", "navigation.footer", "navigation.indexes", "navigation.instant", "navigation.instant.prefetch", "navigation.instant.progress", "navigation.path", "navigation.sections", "navigation.tabs", "navigation.tabs.sticky", "navigation.top", "navigation.tracking", "search.highlight", "search.share", "search.suggest", "toc.follow", "toc.integrate"], "search": "../../assets/javascripts/workers/search.2c215733.min.js", "tags": null, "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": "latest", "provider": "mike"}}</script> <script src=../../assets/javascripts/bundle.79ae519e.min.js></script> <script src=../../javascripts/mathjax.js></script> <script src=../../javascripts/schema.js></script> <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js></script> </body> </html>